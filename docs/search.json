[
  {
    "objectID": "index_dashboards.html",
    "href": "index_dashboards.html",
    "title": "Dashboards",
    "section": "",
    "text": "No matching items\n\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "NH증권 직무인터뷰를 읽고(트레이딩&빅데이터)\n\n\n\n직무분석\n\n\n\n\n\n\n\nKibok Park\n\n\n2024-04-28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[버크셔 해서웨이의 재탄생 읽고] 용어 정리\n\n\n\n경제/금융공부\n\n\n\n\n\n\n\nKibok Park\n\n\n2024-04-23\n\n\n\n\n\n\n\n\n\n\n\n\n[프로그래머스SQL] 가장 비싼 상품 구하기\n\n\n\n프로그래머스/SQL\n\n\n\n\n\n\n\nKibok Park\n\n\n2024-03-18\n\n\n\n\n\n\n\n\n\n\n\n\n[프로그래머스SQL] 평균 일일 대여 요금 구하기\n\n\n\n프로그래머스/SQL\n\n\n\n\n\n\n\nKibok Park\n\n\n2024-03-17\n\n\n\n\n\n\n\n\n\n\n\n\n[Scikit-learn] Kaggle 집값예측 실습\n\n\n\n파이썬\n\n\n머신러닝\n\n\n\n\n\n\n\nKibok Park\n\n\n2023-05-06\n\n\n\n\n\n\n\n\n\n\n\n\n[Pytorch] MNIST 실습\n\n\n\n파이썬\n\n\n머신러닝\n\n\n\n\n\n\n\nKibok Park\n\n\n2023-02-19\n\n\n\n\n\n\n\n\nNo matching items\n\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "index_miniprojects.html",
    "href": "index_miniprojects.html",
    "title": "Mini Projects",
    "section": "",
    "text": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool\n\n\n\nPython\n\n\nSAP Scripting\n\n\n\nPython, win32를 활용한 SAP Scripting\n\n\n\nKibok Park\n\n\n2024-03-06\n\n\n\n\n\n\n\n\n\n\n\n\n[Python] COO발급관리용 Tool\n\n\n\nPython\n\n\nwin11toast\n\n\nsqlite3\n\n\nstreamlit\n\n\npandas\n\n\nselenium\n\n\n\n[Python] selenium(웹스크레핑), sqlite3(db), win11toast(알림), streamlit(UI)\n\n\n\nKibok Park\n\n\n2024-02-20\n\n\n\n\n\n\n\n\n\n\n\n\n[Python] LocalL/C 관리용 Tool\n\n\n\nPython\n\n\nSAP Scripting\n\n\nStreamlit\n\n\nsqlite3\n\n\nBeautifulSoup\n\n\n\nPython, Streamlit을 활용한 업무자동화\n\n\n\nKibok Park\n\n\n2024-01-22\n\n\n\n\n\n\n\n\n\n\n\n\n[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록\n\n\n\nPython\n\n\nre\n\n\nxlwings\n\n\npandas\n\n\npdfminer\n\n\n\n[Python] re(regex), xlwings(암호화 Excel리딩), pdfminer(pdf리딩), pywin32(outlook)\n\n\n\nKibok Park\n\n\n2023-12-15\n\n\n\n\n\n\n\n\n\n\n\n\n[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩\n\n\n\nPython\n\n\ntabula\n\n\nxlwings\n\n\npathlib\n\n\npandas\n\n\n\n[Python] tabula(pdf리딩[표 형태], xlwings(암호화 Excel리딩)\n\n\n\nKibok Park\n\n\n2023-11-01\n\n\n\n\n\n\n\n\nNo matching items\n\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kibok Park",
    "section": "",
    "text": "I’m Kibok Park. Welcome to my blog. I’m not an expert in my favorites yet, but I’m working on becoming one. I hope you to have nice time with my blog.\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "about.html#hello",
    "href": "about.html#hello",
    "title": "Kibok Park",
    "section": "",
    "text": "I’m Kibok Park. Welcome to my blog. I’m not an expert in my favorites yet, but I’m working on becoming one. I hope you to have nice time with my blog."
  },
  {
    "objectID": "about.html#topics",
    "href": "about.html#topics",
    "title": "Kibok Park",
    "section": "Topics",
    "text": "Topics\nPython, Quantative trading"
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "",
    "text": "공부할 겸 혼자서 구글링하면서 용어 정리해보는 포스팅입니다\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#프롤로그",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#프롤로그",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "프롤로그",
    "text": "프롤로그\n\n경제적 해자(enonomic moat) : 성 외곽에서 성을 보호해주는 해자처럼 경쟁우위를 갖게 해주는 요소 (a business’s ability to maintain a competitive edge over its competitors)\n자본배분(capital allocation) : 경제적 자원들을 효율증대/이익극대화를 위해 분배/투자 하는 것 (distributing and investing a company’s financial resources in ways that will increase its efficiency, and maximize its profits) &gt; 자본배분을 알면 워런버핏 사례의 캐피털시티를 이해할 수 있다\n플로트(float, 책임준비금) : 보험회사가 보험금을 지급하기 위해 적립시키는 돈(은행과 달리 자산운용준칙에 따라 자율적으로 사용 가능)\n\n플로트라는 단어의 다른 뜻 : 일반 대중이 거래할 수 있게 발행한 보통주 (the regular shares a company has issued to the public that are available for investors to trade) &gt; 플로트를 알면 워런버핏 사례의 가이코를 이해할 수 있다 (내셔널 인뎀너티와 블루칩스탬프의 플로트를 활용한 투자법 등)\n\n재보험 : 보험계약상 책임의 전부 또는 일부를 다른 보험자에게 인수시킴 (위험의 분산과 인수능력의 극대화를 위해 필요, 위험 대비 자산이 충분치 않은 경우 재보험으로 보험금액의 전부 인수가능)\n영업이익(operating income/earnings) : 기업의 핵심사업(영업활동)으로 얻은 이익 (a measure of the amount of profit realized from a business’s core operations)\n연간 영업활동 순이익(operating earnings) : 영업활동에 필요한 차입금 등 부채의 이자비용도 차감한 이익(영업활동에서 발생한 순이익)\n\n일반 회계기준(GAAP, Generally Accepted Accounting Principles, GAAP)\n\n일반적으로 인정된 회계원칙. 회계규정 자체 또는 회계실무 지침 등 광범위하게 인정되는 회계기준 &gt; GAAP관련 추가로 알아보기\n\n\n**IFRS(International Financial Reporting Standards) : 국제회계기준위원회에서 공표한 회계기준. IFRS를 공부하면 IFRS를 차용한 국가의 회사 재무제표는 같은 형식으로 이해 가능\n\n규칙기반의 GAAP vs 원칙기반의 IFRS\n\nIFRS는 원칙에 따라 작성해 형태 차이가 거의 없으나, GAAP는 세부적인 사안에 대해 자세히 기술(IFRS도 주석 부분에 기술)\n\n\n내용을 세세하게 다루거나, 공정가치를 계산하지않아 IFRS보다 현재가치를 크게 하고 싶을때 GAAP사용\n\n\n\nNon-GAAP\n\n반복적으로 발생하지 않는 1회적 비용은 제외하고 회계처리. 비용이 줄어 순수익이 늘어남\n\n\n미국의 경우 Non-GAAP로 다양한 비용을 제외시켜 표시하는 것이 불법은 아님(기업에 유리) 참고한 링크"
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-섬유공장",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-섬유공장",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "1장. 섬유공장",
    "text": "1장. 섬유공장\n\n\n총자산이익률(ROA, Return on assets) : 순이익 / 총자산(자기자본 + 타인자본). 얼마나 순이익이 창출되는지 판단할 수 있음. ROA의 높고 낮음에 따라 주가의 높낮이도 따를 가능성이 큼 산업의 성숙기[성장/성숙/사양 등]에 따라 ROA는 달라질 수 있음\n자기자본이익률(ROE, Return on equity) : 순이익 / 자본총계(자산-부채) ROA가 높은 경우 적정 수준으로 부채확대를 통해 총자산 자체를 늘리면 ROE를 높일 수 있음 참고한 링크 참고한 링크\n\n\n\n운전자본(Working Capital, =유동자본?) : 회사를 운영하는데 들어가는 돈(매출채권, 선급금, 재고자산 등 유동자산과 매입채무, 선수금 등 유동부채가 해당함)\n순운전자본(Net Working Capital, 운전자본-총부채) : ?? (클럽 설명) 벤자민 그레이엄이 ’현명한 투자자’에서 주창한 투자 전략 즉시 현금화할 수 있는 자산과 비교함으로써 보수적인 기준에서 주가의 저(고)평가 여부를 판단하는 척도로 사용\n장부가치\n주가순자산배수(PBR, price to book value)\n주주환원\n자사주 매입\n감가상각비\n자산 대체원가\n무형자산상각비 차감 전 이익(EBITDA)\n투하자본이익률(ROIC, return on invested capital)\n배당의 이중과세 : 연간이익에 대한 기업의 법인세 + 배당금에 대한 주주의 소득세\n자사주 매입을 통한 주주의 세금 이연(은 주주이익에 도움)"
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-투자-1962-1965년",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-투자-1962-1965년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "2장. 투자: 1962-1965년",
    "text": "2장. 투자: 1962-1965년\n\n무한책임 파트너(general partner) : 펀드 운용에 관한 무한책임을 지는 출자자, 보통 운용자를 말함\n헤지펀드 :\n환매 :\n이월결손금\n손익계산서\n유동성소요\n**내재 사업가치(intrinsic business value)\n유한책임조합"
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-전환-1965-1967년",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-전환-1965-1967년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "3장. 전환: 1965-1967년",
    "text": "3장. 전환: 1965-1967년\n\n자본배분\n투하자본이익률\n매출원가\n특별항목 (’특별항목 반영 전 순이익’에서 사용된 의미, ’1964년 특별항목은 유휴설비비용 22만 달러를 포함했다’와 같이 사용)\n유휴설비비용(idle plant expense): 비영업용 제조설비의 유지보수 및 감가상각비\n**기대손실\n손상차손 write-down\n유형자산 손상차손\n이익잉여금\n총포괄손익\n총창출자본(total capital generated)"
  },
  {
    "objectID": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-인수-1967-1969년",
    "href": "posts/yyyymmdd-bk-BerkshireHathaway-1/index.html#장.-인수-1967-1969년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "4장. 인수: 1967-1969년",
    "text": "4장. 인수: 1967-1969년\n\n완전 소유 기업(wholly-owned-subsidiary) : 1개 기업이 단독 투자하여 100% 소유 지문을 가지는것\n상환청구권 :\n\n\n플로트(책임준비금) : + 지급준비금(lost reserve) + 손해사정비 준비금(lost adjustment expense reserve) + 미경과보험료 적립금(unearned premium reserve) - 대리점 미수금(agents’ balance) - 선급 신계약비(prepaid acquisition cost) - 출재보험 준비금(deferred charges applicable to assumed reinsurance)"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "",
    "text": "공부할 겸 혼자서 구글링하면서 용어 정리해보는 포스팅입니다\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#프롤로그",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#프롤로그",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "프롤로그",
    "text": "프롤로그\n\n경제적 해자(enonomic moat) : 성 외곽에서 성을 보호해주는 해자처럼 경쟁우위를 갖게 해주는 요소 (a business’s ability to maintain a competitive edge over its competitors)\n자본배분(capital allocation) : 경제적 자원들을 효율증대/이익극대화를 위해 분배/투자 하는 것 (distributing and investing a company’s financial resources in ways that will increase its efficiency, and maximize its profits) &gt; 자본배분을 알면 워런버핏 사례의 캐피털시티를 이해할 수 있다\n플로트(float, 책임준비금) : 보험회사가 보험금을 지급하기 위해 적립시키는 돈(은행과 달리 자산운용준칙에 따라 자율적으로 사용 가능)\n\n플로트라는 단어의 다른 뜻 : 일반 대중이 거래할 수 있게 발행한 보통주 (the regular shares a company has issued to the public that are available for investors to trade) &gt; 플로트를 알면 워런버핏 사례의 가이코를 이해할 수 있다 (내셔널 인뎀너티와 블루칩스탬프의 플로트를 활용한 투자법 등)\n\n재보험 : 보험계약상 책임의 전부 또는 일부를 다른 보험자에게 인수시킴 (위험의 분산과 인수능력의 극대화를 위해 필요, 위험 대비 자산이 충분치 않은 경우 재보험으로 보험금액의 전부 인수가능)\n영업이익(operating income/earnings) : 기업의 핵심사업(영업활동)으로 얻은 이익 (a measure of the amount of profit realized from a business’s core operations)\n연간 영업활동 순이익(operating earnings) : 영업활동에 필요한 차입금 등 부채의 이자비용도 차감한 이익(영업활동에서 발생한 순이익)\n\n일반 회계기준(GAAP, Generally Accepted Accounting Principles, GAAP)\n\n일반적으로 인정된 회계원칙. 회계규정 자체 또는 회계실무 지침 등 광범위하게 인정되는 회계기준 &gt; GAAP관련 추가로 알아보기\n\n\n**IFRS(International Financial Reporting Standards) : 국제회계기준위원회에서 공표한 회계기준. IFRS를 공부하면 IFRS를 차용한 국가의 회사 재무제표는 같은 형식으로 이해 가능\n\n규칙기반의 GAAP vs 원칙기반의 IFRS\n\nIFRS는 원칙에 따라 작성해 형태 차이가 거의 없으나, GAAP는 세부적인 사안에 대해 자세히 기술(IFRS도 주석 부분에 기술)\n\n\n내용을 세세하게 다루거나, 공정가치를 계산하지않아 IFRS보다 현재가치를 크게 하고 싶을때 GAAP사용\n\n\n\nNon-GAAP\n\n반복적으로 발생하지 않는 1회적 비용은 제외하고 회계처리. 비용이 줄어 순수익이 늘어남\n\n\n미국의 경우 Non-GAAP로 다양한 비용을 제외시켜 표시하는 것이 불법은 아님(기업에 유리) 참고한 링크"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-섬유공장",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-섬유공장",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "1장. 섬유공장",
    "text": "1장. 섬유공장\n\n\n총자산이익률(ROA, Return on assets) : 순이익 / 총자산(자기자본 + 타인자본). 얼마나 순이익이 창출되는지 판단할 수 있음. ROA의 높고 낮음에 따라 주가의 높낮이도 따를 가능성이 큼 산업의 성숙기[성장/성숙/사양 등]에 따라 ROA는 달라질 수 있음\n자기자본이익률(ROE, Return on equity) : 순이익 / 자본총계(자산-부채) ROA가 높은 경우 적정 수준으로 부채확대를 통해 총자산 자체를 늘리면 ROE를 높일 수 있음 참고한 링크 참고한 링크\n\n\n\n운전자본(Working Capital, =유동자본?) : 회사를 운영하는데 들어가는 돈(매출채권, 선급금, 재고자산 등 유동자산과 매입채무, 선수금 등 유동부채가 해당함)\n순운전자본(Net Working Capital, 운전자본-총부채) : ?? (클럽 설명) 벤자민 그레이엄이 ’현명한 투자자’에서 주창한 투자 전략 즉시 현금화할 수 있는 자산과 비교함으로써 보수적인 기준에서 주가의 저(고)평가 여부를 판단하는 척도로 사용\n장부가치\n주가순자산배수(PBR, price to book value)\n주주환원\n자사주 매입\n감가상각비\n자산 대체원가\n무형자산상각비 차감 전 이익(EBITDA)\n투하자본 : 영업활동(수익활동)에 투입한 자산\n투하자본이익률(ROIC, return on invested capital) : 영업활동(수익활동)에 투입한 자산으로 얻은 영업이익의 비율\n배당의 이중과세 : 연간이익에 대한 기업의 법인세 + 배당금에 대한 주주의 소득세\n자사주 매입을 통한 주주의 세금 이연(은 주주이익에 도움)"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-투자-1962-1965년",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-투자-1962-1965년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "2장. 투자: 1962-1965년",
    "text": "2장. 투자: 1962-1965년\n\n무한책임 파트너(general partner) : 펀드 운용에 관한 무한책임을 지는 출자자, 보통 운용자를 말함\n헤지펀드 :\n환매 :\n이월결손금\n손익계산서\n유동성소요\n**내재 사업가치(intrinsic business value)\n유한책임조합"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-전환-1965-1967년",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-전환-1965-1967년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "3장. 전환: 1965-1967년",
    "text": "3장. 전환: 1965-1967년\n\n자본배분\n투하자본이익률\n매출원가\n특별항목 (’특별항목 반영 전 순이익’에서 사용된 의미, ’1964년 특별항목은 유휴설비비용 22만 달러를 포함했다’와 같이 사용)\n유휴설비비용(idle plant expense): 비영업용 제조설비의 유지보수 및 감가상각비\n**기대손실\n손상차손 write-down\n유형자산 손상차손\n이익잉여금\n총포괄손익\n총창출자본(total capital generated)"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-인수-1967-1969년",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-인수-1967-1969년",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "4장. 인수: 1967-1969년",
    "text": "4장. 인수: 1967-1969년\n\n완전 소유 기업(wholly-owned-subsidiary) : 1개 기업이 단독 투자하여 100% 소유 지문을 가지는것\n상환청구권 :\n\n\n플로트(책임준비금) : + 지급준비금(lost reserve) + 손해사정비 준비금(lost adjustment expense reserve) + 미경과보험료 적립금(unearned premium reserve) - 대리점 미수금(agents’ balance) - 선급 신계약비(prepaid acquisition cost) - 출재보험 준비금(deferred charges applicable to assumed reinsurance) * 플로트 계산법은 분석대상 기업과 애널리스트에 따라 다름 * 기타자산과 기타부채를 처리하는 방법에서 차이가 발생함 * 정확한 플로트 값이 중요하지 않음(소수점 마지막까지 계산X) *\n\n\n합산비율(combined ratio) : 손해율 + 사업비율. 100%를 기준으로 높으면 손해 낮으면 이익\n손해율(loss ratio) : 보험료 수입 대비 보험금 지급 비율\n사업비율(expense ratio) : 보험료 수입 중 인건비, 마케팅비, 모집수수료, 중개비 등 비중\n경과보험료(earned premiums) : 1년단위/일시납이 기본인 손해보험업에서 더 유의미한 기준. 보험사의 회계연도 말을 기준으로 가입자의 전체 보험기간을 경과/미경과 기간으로 구분, 받은 보험료를 경과/미경과 보험료로 구분함\n레버리지 :\n영업 레버리지(operating leverage)\n재무 레버리지(financial leverage)\n유형순자산(tangible net worth)\n영업권(goodwill)\n원수보험료\n순원수보험료(net premiums written) : 원수보험료에서 수/출재보험료와 환급보험료를 가감한 값\n비연결자회사\n연결납세제도(consolidated tax return) : 모회사의 자회사 지분율이 80%이상이고 경제적으로 결합되어있을 때 하나의 과세단위로 해석함. 이에 따라 모회사-자회사간 배당을 과세하지 않을때가 있음. 한국에도 도입되어있지만 연결 요건이 엄격함\n예수부채\n요구불예금\n스핀오프 : 자회사 주식을 모회사 주주에게 배당(인적분할) + 기존 회사의 자회사화\n투자 영업이익 : 이자 및 배당수익 + 유가증권 추분이익"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-확장-1970년대",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-확장-1970년대",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "5장. 확장: 1970년대",
    "text": "5장. 확장: 1970년대\n\n투하자본\n매출채권\n부채자기자본비율(debt to equity)\n표면이자율\n일반사채(debenture:무담보회사채)\n이자비용 및 법인세 차감 전 이익(EBIT)\n주가매출액배수(price to sales, PSR) : 기업의 주가와 매출을 비교하는 가치평가 지표\n예상손해율(loss expectancy)\n보험영업 손실/이익\n듀레이션(duration, 듀레이션이 긴 재보험에서의 용례)"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-다른-기업들",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-다른-기업들",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "6장. 다른 기업들",
    "text": "6장. 다른 기업들\n\n공모채 : 불특정다수에게 발행하는 채권\n사용자본이익률(ROCE)\n최초 이익수익률(initial earnings yield)\n모기지(mortgate) : 주택 구매 등을 위해 돈을 빌리고, 갚지 못하는 경우 해당 주택을 대출 업체가 소유\n예대마진(spread) : 예금이자와 대출이자간 차이\n예수부채 : 불특정 다수를 상대로 조달한 자금\n차입인수(LBO, leverage buyout) : 인수할 회사의 자본 등을 담보로 자금을 확보하여 기업을 인수"
  },
  {
    "objectID": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-복합기업",
    "href": "posts/bk-BerkshireHathaway-20240423-terms/index.html#장.-복합기업",
    "title": "[버크셔 해서웨이의 재탄생 읽고] 용어 정리",
    "section": "7장. 복합기업",
    "text": "7장. 복합기업\n\n자본잉여금(paid-in surplus) : 주식 발행 등으로 발생하는 잉여금. 돈을 받고 주식을 발행하는 유상증자시 늘어나게 됨\n지배지분이익 : 지배 기업의 순이익에서 지분율만큼 반영한 이익\n매출총이익률 : 매출액 대비 매출총이익 비율\n\n매출총이익 : 매출액에서 (매출과 직접적으로 관계된)비용 차감"
  },
  {
    "objectID": "posts/vba-noname-yyyymmdd/index.html",
    "href": "posts/vba-noname-yyyymmdd/index.html",
    "title": "NH증권 직무인터뷰를 읽고(트레이딩&빅데이터)",
    "section": "",
    "text": "관심이 생겨서 관련 공고 등을 보고 있는데, 직무이해 겸 모르는 단어를 정리해봅니다.\n\n\n\n\n\n\n참고한 공고 (클릭해서 펼치기)\n\n\n\n\n\nNH투자증권 채용공고-Trading\nNH투자증권 채용공고-빅데이터 분석\nNH투자증권 직무인터뷰\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/vba-noname-yyyymmdd/index.html#참고한-공고-인터뷰-자료",
    "href": "posts/vba-noname-yyyymmdd/index.html#참고한-공고-인터뷰-자료",
    "title": "NH증권 직무인터뷰를 읽고(트레이딩&빅데이터)",
    "section": "",
    "text": "관심이 생겨서 관련 공고 등을 보고 있는데, 직무이해 겸 모르는 단어를 정리해봅니다.\n\n\n\n\n\n\n참고한 공고 (클릭해서 펼치기)\n\n\n\n\n\nNH투자증권 채용공고-Trading\nNH투자증권 채용공고-빅데이터 분석\nNH투자증권 직무인터뷰"
  },
  {
    "objectID": "posts/vba-noname-yyyymmdd/index.html#트레이딩-직무-단어정리",
    "href": "posts/vba-noname-yyyymmdd/index.html#트레이딩-직무-단어정리",
    "title": "NH증권 직무인터뷰를 읽고(트레이딩&빅데이터)",
    "section": "트레이딩 직무 단어정리",
    "text": "트레이딩 직무 단어정리\n\n프랍 트레이딩(Proprietary Trading) : 고객이 아닌 금융회사의 돈으로 주식이나 파생상품 등 금융상품을 거래하는 것 (=자기계정거래, 자기계좌거래, 고유계정거래, 고유계좌거래)\n\n\n프랍트레이딩은 통상 선물·옵션 등 파생상품 부문, 일반적 주식투자 같은 방향성 매매, 알고리즘에 따라 투자하는 시스템 매매, 채권투자, 부동산이나 인프라 등의 대체투자 등으로 나뉜다. 보통 자기매매 비중이 높은 중소형 증권사에는 많게는 50여명에 이르는 프랍트레이더들이 있다. 이 가운데 80% 이상이 파생 트레이더다.중소형 증권사들의 파생상품투자 비중이 높은 것은 비용이 싸기 때문이다. 증권사의 경우 선물·옵션 거래시 사후 증거금 제도가 적용된다. 장중 거래에는 증거금이 따로 필요 없고 장 마감 후 포지션 규모에 따라 증거금을 마련하면 된다. 따라서 장중에는 활발히 거래하고 장 마감 직전 파생상품을 보유하지 않았으면 증거금 부담은 없다. 하루 단위로 청산하는 경우 사실상 금융비용은 없다.\n상기내용 참고한 서울경제 기사링크 거래증거금vs위탁증거금 내용 참고할 수 있는 블로그\n\n\n장내거래 vs 장외거래 : 정규시장 외 체결되는 거래\n매크로 지식 : Macro economics지식 (↔︎ Micro economics)\n서킷브레이커(일시매매정지, Trading Curb) : 가격 변동이 지나친 경우 일시적으로 거래를 중단하는 것\n틱 : 체결량에 따른 단위 (5틱 = 체결 5회 기준)\n셀사이드(Sell-side|은행, 증권사 등) : 금융 서비스 등을 제공하여 수익 창출\n바이사이드(Buy-side|자산운용사, 연기금, 보험사, 헤지펀드 등) : 투자를 하여 수익 창출\n\n\n참고글:셀사이드와 바이사이드의 금융공학\n\n\n하우스 : 증권사, 금융사 등 단체를 칭함"
  },
  {
    "objectID": "posts/vba-noname-yyyymmdd/index.html#빅데이터-직무-단어정리",
    "href": "posts/vba-noname-yyyymmdd/index.html#빅데이터-직무-단어정리",
    "title": "NH증권 직무인터뷰를 읽고(트레이딩&빅데이터)",
    "section": "빅데이터 직무 단어정리",
    "text": "빅데이터 직무 단어정리\n\nMTS : Mobile Trading System (HTS : Home Trading System)\n원장 : 증권사가 고객계좌나 거래내역, 매매 등을 관리하는 프로그램"
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html",
    "href": "posts/coach-ml-20240505/index.html",
    "title": "[Pytorch] MNIST 실습",
    "section": "",
    "text": "파이토치로 MNIST 머신러닝 실습해본 코드 기록용으로 남깁니다.\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html#pytorch활용한-mnist-데이터셋-로딩",
    "href": "posts/coach-ml-20240505/index.html#pytorch활용한-mnist-데이터셋-로딩",
    "title": "[Pytorch] MNIST 실습",
    "section": "Pytorch활용한 MNIST 데이터셋 로딩",
    "text": "Pytorch활용한 MNIST 데이터셋 로딩\n\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nroot = './data'\nmnist_train = dset.MNIST (root=root, train=True, transform=transforms.ToTensor(), download=True )\nmnist_test = dset.MNIST (root=root, train=False, transform=transforms.ToTensor(), download=True)\n\n# Train용 / Test용 데이터셋\ntrain_loader = DataLoader(mnist_train, batch_size=10, shuffle=True)\ntest_loader = DataLoader(mnist_test, batch_size=10, shuffle=True)\n\n\nFigure 1"
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html#학습준비가중치-초기화-등",
    "href": "posts/coach-ml-20240505/index.html#학습준비가중치-초기화-등",
    "title": "[Pytorch] MNIST 실습",
    "section": "학습준비(가중치 초기화 등)",
    "text": "학습준비(가중치 초기화 등)\n\nMNIST의 크기 : 28 * 28\nLoss : Cross Entropy\nOptimizer - SGD(Stochastic Gradient Descent)\nLearning rate = 0.1\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 모델 구현 (28*28 = 784 / 0~9라서 10개 / 가중치 사용하므로 bias)\nlinear = torch.nn.Linear(784, 10, bias=True).to(device) \n\n# weight init 가중치 초기화\ntorch.nn.init.normal_(linear.weight)\n\n# Loss fn - Cross Entropy Loss\ncriterion = torch.nn.CrossEntropyLoss().to(device)\n\n# optimizer - SGD\noptimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html#모델-학습",
    "href": "posts/coach-ml-20240505/index.html#모델-학습",
    "title": "[Pytorch] MNIST 실습",
    "section": "모델 학습",
    "text": "모델 학습\n\ntraining_epochs = 20 # training 반복 횟수\n\nfor epoch in range(training_epochs):\n  for i, (imgs, labels) in enumerate(train_loader):\n    labels = labels.to(device)\n    imgs = imgs.view(-1, 28 * 28).to(device)\n\n    outputs = linear(imgs) \n    loss = criterion(outputs, labels) \n\n    optimizer.zero_grad()# optimzier zero grad\n\n    loss.backward() # loss backward\n    optimizer.step() # optimzier step\n\n    _,argmax = torch.max(outputs, 1)\n    accuracy = (labels == argmax).float().mean()\n\n  if (i+1) % 100 == 0:\n    print('Epoch [{}/{}], Step [{}/{}], Loss: {: .4f}, Accuracy: {: .2f}%'.format(\n    epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()* 100))\n\nEpoch [1/20], Step [6000/6000], Loss:  0.0273, Accuracy:  100.00%\nEpoch [2/20], Step [6000/6000], Loss:  0.0762, Accuracy:  100.00%\nEpoch [3/20], Step [6000/6000], Loss:  0.5928, Accuracy:  80.00%\nEpoch [4/20], Step [6000/6000], Loss:  0.2854, Accuracy:  90.00%\nEpoch [5/20], Step [6000/6000], Loss:  0.1373, Accuracy:  90.00%\nEpoch [6/20], Step [6000/6000], Loss:  0.0668, Accuracy:  100.00%\nEpoch [7/20], Step [6000/6000], Loss:  0.0253, Accuracy:  100.00%\nEpoch [8/20], Step [6000/6000], Loss:  0.0542, Accuracy:  100.00%\nEpoch [9/20], Step [6000/6000], Loss:  0.9203, Accuracy:  80.00%\nEpoch [10/20], Step [6000/6000], Loss:  0.1244, Accuracy:  90.00%\nEpoch [11/20], Step [6000/6000], Loss:  0.6108, Accuracy:  90.00%\nEpoch [12/20], Step [6000/6000], Loss:  0.1312, Accuracy:  100.00%\nEpoch [13/20], Step [6000/6000], Loss:  0.0705, Accuracy:  100.00%\nEpoch [14/20], Step [6000/6000], Loss:  1.6259, Accuracy:  70.00%\nEpoch [15/20], Step [6000/6000], Loss:  0.0538, Accuracy:  100.00%\nEpoch [16/20], Step [6000/6000], Loss:  0.2435, Accuracy:  80.00%\nEpoch [17/20], Step [6000/6000], Loss:  0.0061, Accuracy:  100.00%\nEpoch [18/20], Step [6000/6000], Loss:  0.1091, Accuracy:  100.00%\nEpoch [19/20], Step [6000/6000], Loss:  0.0157, Accuracy:  100.00%\nEpoch [20/20], Step [6000/6000], Loss:  0.1413, Accuracy:  90.00%"
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html#학습된-모델-테스트",
    "href": "posts/coach-ml-20240505/index.html#학습된-모델-테스트",
    "title": "[Pytorch] MNIST 실습",
    "section": "학습된 모델 테스트",
    "text": "학습된 모델 테스트\n\nlinear.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for i, (imgs, labels) in enumerate(test_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        imgs = imgs.view(-1, 28 * 28)\n\n        outputs = linear(imgs) # 구현\n\n        _, argmax = torch.max(outputs, 1) # max()를 통해 최종 출력이 가장 높은 class 선택\n        total += imgs.size(0)\n        correct += (labels == argmax). sum().item()\n\n    print('Test accuracy for {} images: {: .2f}%'.format(total, correct / total * 100))\n\nTest accuracy for 10000 images:  91.99%"
  },
  {
    "objectID": "posts/coach-ml-20240505/index.html#개요",
    "href": "posts/coach-ml-20240505/index.html#개요",
    "title": "[Pytorch] MNIST 실습",
    "section": "",
    "text": "파이토치로 MNIST 머신러닝 실습해본 코드 기록용으로 남깁니다."
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html",
    "href": "posts/coach-ml-kaggle-20230506/index.html",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "",
    "text": "Kaggle Korea - House price prediction 실습 기록용으로 남깁니다.\nKaggle 원문 링크\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#개요",
    "href": "posts/coach-ml-kaggle-20230506/index.html#개요",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "",
    "text": "Kaggle Korea - House price prediction 실습 기록용으로 남깁니다.\nKaggle 원문 링크"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#pytorch활용한-mnist-데이터셋-로딩",
    "href": "posts/coach-ml-kaggle-20230506/index.html#pytorch활용한-mnist-데이터셋-로딩",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "Pytorch활용한 MNIST 데이터셋 로딩",
    "text": "Pytorch활용한 MNIST 데이터셋 로딩\n\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\nroot = './data'\nmnist_train = dset.MNIST (root=root, train=True, transform=transforms.ToTensor(), download=True )\nmnist_test = dset.MNIST (root=root, train=False, transform=transforms.ToTensor(), download=True)\n\n# Train용 / Test용 데이터셋\ntrain_loader = DataLoader(mnist_train, batch_size=10, shuffle=True)\ntest_loader = DataLoader(mnist_test, batch_size=10, shuffle=True)\n\n\nFigure 1"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#학습준비가중치-초기화-등",
    "href": "posts/coach-ml-kaggle-20230506/index.html#학습준비가중치-초기화-등",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "학습준비(가중치 초기화 등)",
    "text": "학습준비(가중치 초기화 등)\n\nMNIST의 크기 : 28 * 28\nLoss : Cross Entropy\nOptimizer - SGD(Stochastic Gradient Descent)\nLearning rate = 0.1\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 모델 구현 (28*28 = 784 / 0~9라서 10개 / 가중치 사용하므로 bias)\nlinear = torch.nn.Linear(784, 10, bias=True).to(device) \n\n# weight init 가중치 초기화\ntorch.nn.init.normal_(linear.weight)\n\n# Loss fn - Cross Entropy Loss\ncriterion = torch.nn.CrossEntropyLoss().to(device)\n\n# optimizer - SGD\noptimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#모델-학습",
    "href": "posts/coach-ml-kaggle-20230506/index.html#모델-학습",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "모델 학습",
    "text": "모델 학습\n\ntraining_epochs = 20 # training 반복 횟수\n\nfor epoch in range(training_epochs):\n  for i, (imgs, labels) in enumerate(train_loader):\n    labels = labels.to(device)\n    imgs = imgs.view(-1, 28 * 28).to(device)\n\n    outputs = linear(imgs) \n    loss = criterion(outputs, labels) \n\n    optimizer.zero_grad()# optimzier zero grad\n\n    loss.backward() # loss backward\n    optimizer.step() # optimzier step\n\n    _,argmax = torch.max(outputs, 1)\n    accuracy = (labels == argmax).float().mean()\n\n  if (i+1) % 100 == 0:\n    print('Epoch [{}/{}], Step [{}/{}], Loss: {: .4f}, Accuracy: {: .2f}%'.format(\n    epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()* 100))\n\nEpoch [1/20], Step [6000/6000], Loss:  0.0273, Accuracy:  100.00%\nEpoch [2/20], Step [6000/6000], Loss:  0.0762, Accuracy:  100.00%\nEpoch [3/20], Step [6000/6000], Loss:  0.5928, Accuracy:  80.00%\nEpoch [4/20], Step [6000/6000], Loss:  0.2854, Accuracy:  90.00%\nEpoch [5/20], Step [6000/6000], Loss:  0.1373, Accuracy:  90.00%\nEpoch [6/20], Step [6000/6000], Loss:  0.0668, Accuracy:  100.00%\nEpoch [7/20], Step [6000/6000], Loss:  0.0253, Accuracy:  100.00%\nEpoch [8/20], Step [6000/6000], Loss:  0.0542, Accuracy:  100.00%\nEpoch [9/20], Step [6000/6000], Loss:  0.9203, Accuracy:  80.00%\nEpoch [10/20], Step [6000/6000], Loss:  0.1244, Accuracy:  90.00%\nEpoch [11/20], Step [6000/6000], Loss:  0.6108, Accuracy:  90.00%\nEpoch [12/20], Step [6000/6000], Loss:  0.1312, Accuracy:  100.00%\nEpoch [13/20], Step [6000/6000], Loss:  0.0705, Accuracy:  100.00%\nEpoch [14/20], Step [6000/6000], Loss:  1.6259, Accuracy:  70.00%\nEpoch [15/20], Step [6000/6000], Loss:  0.0538, Accuracy:  100.00%\nEpoch [16/20], Step [6000/6000], Loss:  0.2435, Accuracy:  80.00%\nEpoch [17/20], Step [6000/6000], Loss:  0.0061, Accuracy:  100.00%\nEpoch [18/20], Step [6000/6000], Loss:  0.1091, Accuracy:  100.00%\nEpoch [19/20], Step [6000/6000], Loss:  0.0157, Accuracy:  100.00%\nEpoch [20/20], Step [6000/6000], Loss:  0.1413, Accuracy:  90.00%"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#학습된-모델-테스트",
    "href": "posts/coach-ml-kaggle-20230506/index.html#학습된-모델-테스트",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "학습된 모델 테스트",
    "text": "학습된 모델 테스트\n\nlinear.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for i, (imgs, labels) in enumerate(test_loader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        imgs = imgs.view(-1, 28 * 28)\n\n        outputs = linear(imgs) # 구현\n\n        _, argmax = torch.max(outputs, 1) # max()를 통해 최종 출력이 가장 높은 class 선택\n        total += imgs.size(0)\n        correct += (labels == argmax). sum().item()\n\n    print('Test accuracy for {} images: {: .2f}%'.format(total, correct / total * 100))\n\nTest accuracy for 10000 images:  91.99%"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#개념",
    "href": "posts/coach-ml-kaggle-20230506/index.html#개념",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "개념",
    "text": "개념\nRMSE(Root Mean Squeare Error)\nRoot    (4)\nMean    (3)\nSquare  (2)\nError   (1)\n(1) 실제값에서 예측값을 뺀 '오차'를\n(2) 합했을 때 음수의 영향을 제거하기 위해 '제곱'하고\n(3) '평균'오차로 만든 후\n(4) '루트'를 씌워 값의 크기를 작게 한다 (값을 작게하여 연산속도에 이점이 있다)"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#파일-다운로드-및-알아보기",
    "href": "posts/coach-ml-kaggle-20230506/index.html#파일-다운로드-및-알아보기",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "파일 다운로드 및 알아보기",
    "text": "파일 다운로드 및 알아보기\nFile descriptions\ntrain.csv - 예측 모델을 만들기 위해 사용하는 학습 데이터입니다. \n    집의 정보와 예측할 변수인 가격(Price) 변수를 가지고 있습니다.\ntest.csv - 학습셋으로 만든 모델을 가지고 예측할 가격(Price) 변수를 제외한 집의 정보가\n    담긴 테스트 데이터 입니다.\nsample_submission.csv - 제출시 사용할 수 있는 예시 submission.csv 파일입니다.\nData fields\nID : 집을 구분하는 번호\ndate : 집을 구매한 날짜\nprice : 집의 가격(Target variable)\nbedrooms : 침실의 수\nbathrooms : 화장실의 수\nsqft_living : 주거 공간의 평방 피트(면적)\nsqft_lot : 부지의 평방 피트(면적)\nfloors : 집의 층 수\nwaterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\nview : 집이 얼마나 좋아 보이는지의 정도\ncondition : 집의 전반적인 상태\ngrade : King County grading 시스템 기준으로 매긴 집의 등급\nsqft_above : 지하실을 제외한 평방 피트(면적)\nsqft_basement : 지하실의 평방 피트(면적)\nyr_built : 지어진 년도\nyr_renovated : 집을 재건축한 년도\nzipcode : 우편번호\nlat : 위도\nlong : 경도\nsqft_living15 : 2015년 기준 주거 공간의 평방 피트(면적, 집을 재건축했다면, 변화가 있을 수 있음)\nsqft_lot15 : 2015년 기준 부지의 평방 피트(면적, 집을 재건축했다면, 변화가 있을 수 있음)"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#패키지-및-데이터-불러오기",
    "href": "posts/coach-ml-kaggle-20230506/index.html#패키지-및-데이터-불러오기",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "패키지 및 데이터 불러오기",
    "text": "패키지 및 데이터 불러오기\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_data_path = './data/train.csv'\ntest_data_path = './data/test.csv'\n\ndata = pd.read_csv(train_data_path)\ntest = pd.read_csv(test_data_path)\nprint('train data : {}'.format(data.shape))\nprint('test data : {}'.format(test.shape))\n\ntrain data : (15035, 21)\ntest data : (6555, 20)"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#데이터-전처리",
    "href": "posts/coach-ml-kaggle-20230506/index.html#데이터-전처리",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "데이터 전처리",
    "text": "데이터 전처리\n\n정답컬럼 분리\n\ntest데이터와 달리 train data에는 컬럼이 1개 더 있음 (정답컬럼인 price)\n별도의 정답 데이터(y)로 분리\n\n\nprint('컬럼 분리 전')\nprint(data.columns)\nprint(test.columns)\n\n컬럼 분리 전\nIndex(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\n\n\n\n# y라는 변수에 price(정답)을 옮기고, 전체데이터를 백업(data_backup에 할당)하고 price컬럼 삭제\ny = data['price'] \ndata_backup = data.copy()\ndata.drop('price',axis=1, inplace=True)\n\n\nprint('컬럼 분리 후')\nprint(data.columns)\nprint(test.columns)\nprint(y.name)\n\n컬럼 분리 후\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nprice\n\n\n\n\n결측치 확인 및 제거\n\ntrain, test 데이터를 합쳐서 한번에 확인\n\n\n# 합치기\ndf_chk_missing = pd.concat((data, test), axis=0)\n\n# 향후 분할을 대비한 행 수 저장\ntrain_length = len(data)\ntest_length = len(test)\n\nprint(train_length, test_length)\n\n15035 6555\n\n\n\n결측치 확인방법1(pandas)\n\nisna()로 결측치를 확인\n\n\nprint(df_chk_missing.isna().sum())\n\nid               0\ndate             0\nbedrooms         0\nbathrooms        0\nsqft_living      0\nsqft_lot         0\nfloors           0\nwaterfront       0\nview             0\ncondition        0\ngrade            0\nsqft_above       0\nsqft_basement    0\nyr_built         0\nyr_renovated     0\nzipcode          0\nlat              0\nlong             0\nsqft_living15    0\nsqft_lot15       0\ndtype: int64\n\n\n\n\n결측치 확인방법2(missingno)\n\nmissingno 패키지로 컬럼별 결측치 시각화\n\n\nimport missingno\n\nmissingno.matrix(df_chk_missing)\n\n\n\n\n\n\n\n\n\n\n결측치 확인방법3(ydata_profiling)\n\nydata_profiling 패키지로 결측치 및 다양한 값 확인 가능\n렌더링 용량 문제로 실행결과는 이미지로 대체(RangeError: Maximum call stack size exceeded)\n\n\nfrom ydata_profiling import ProfileReport\n\nprofile = ProfileReport(df_chk_missing, title=\"Profiling Report\")\nprofile\n\n\n\n\n실행결과 샘플\n\n\n\n결측치가 없으므로 다음 과정을 진행\n\n\n\n\n불필요한 변수 제거, 데이터 변환 등\n\n단순식별용 데이터 삭제\n\n가격과 관계없는 단순식별용 데이터인 id 삭제\n\n\nmain_id = df_chk_missing['id'][:train_length]\ntest_id = df_chk_missing['id'][train_length:]\ndel df_chk_missing['id']\n\n\n\n불필요한 데이터 삭제\n\n날짜 뒤에 T00000과 같이 시간데이터(로 추정됨)가 있는데, 모두 T00000으로만 되어있으므로 삭제\n\n\n# T000000으로 되어있는 값 세기\ndf_chk_missing['date'].str.contains('T000000').value_counts()\n\ndate\nTrue    21590\nName: count, dtype: int64\n\n\n\n# apply로 lambda함수를 사용하여, date컬럼의 앞자리만 저장\ndf_chk_missing['date'] = df_chk_missing['date'].apply(lambda x : str(x[:6]))\ndf_chk_missing.head()\n\n\n\n\n\n\n\n\n\ndate\nbedrooms\nbathrooms\nsqft_living\nsqft_lot\nfloors\nwaterfront\nview\ncondition\ngrade\nsqft_above\nsqft_basement\nyr_built\nyr_renovated\nzipcode\nlat\nlong\nsqft_living15\nsqft_lot15\n\n\n\n\n0\n201410\n3\n1.00\n1180\n5650\n1.0\n0\n0\n3\n7\n1180\n0\n1955\n0\n98178\n47.5112\n-122.257\n1340\n5650\n\n\n1\n201502\n2\n1.00\n770\n10000\n1.0\n0\n0\n3\n6\n770\n0\n1933\n0\n98028\n47.7379\n-122.233\n2720\n8062\n\n\n2\n201502\n3\n2.00\n1680\n8080\n1.0\n0\n0\n3\n8\n1680\n0\n1987\n0\n98074\n47.6168\n-122.045\n1800\n7503\n\n\n3\n201406\n3\n2.25\n1715\n6819\n2.0\n0\n0\n3\n7\n1715\n0\n1995\n0\n98003\n47.3097\n-122.327\n2238\n6819\n\n\n4\n201501\n3\n1.50\n1060\n9711\n1.0\n0\n0\n3\n7\n1060\n0\n1963\n0\n98198\n47.4095\n-122.315\n1650\n9711\n\n\n\n\n\n\n\n\n\n\n로그변환\n\n치우친 분포를 정규분포에 가깝게 만들기\n\n\n분포가 치우쳐져 있는 항목 찾기(시각화)\n\nrow_plot = 5\ncol_plot = 4\nfig, ax = plt.subplots(row_plot, col_plot, figsize=(24, 35)) \n\ncolumns = df_chk_missing.columns\ncolumns_idx = 1 # 첫 컬럼인 date(날짜)는 제외하기 위해 0이 아닌 1부터 시작\nfor row in range(row_plot):\n    for col in range(col_plot):\n        sns.kdeplot(data=df_chk_missing[columns[columns_idx]], ax=ax[row][col])\n        ax[row][col].set_title(columns[columns_idx])\n        columns_idx += 1\n        if columns_idx == len(columns) :\n            break\n\n\n\n\n\n\n\n\n\n아래의 항목들이 치우쳐져 있음\n\nsqft_living\nsqft_lot\nwaterfront (→유/무 지표로 0,1만 있는게 정상이므로 제외)\nsqft_above\nsqft_basement\nsqft_living15\nsqft_lot15\n\n\n\n# 변환대상 리스트에 저장\nskewed_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']\n\n# 그래프로 그리기 (변환 전/후 그래프를 함께 그릴 예정이므로 plot의 수는 두배)\nrow_plot = 6\ncol_plot = 2\nfig, ax = plt.subplots(row_plot, col_plot, figsize=(15, 35)) \n\ncolumns = skewed_columns\ncolumns_idx = 0\n\n\nfor row in range(row_plot):\n    # 로그변환 대상만 식별 후 진행\n    if columns[row] in skewed_columns:\n        # 기존 그래프 그리기\n        sns.kdeplot(data=df_chk_missing[columns[row]], ax=ax[row][0])\n        ax[row][0].set_title(columns[row])\n\n        # 로그변환\n        df_chk_missing[columns[row]] = np.log1p(df_chk_missing[columns[row]])\n\n        # 변환된 그래프 그리기\n        sns.kdeplot(data=df_chk_missing[columns[row]], ax=ax[row][1])\n        ax[row][1].set_title(columns[row]+'_log')\n\n\n\n\n\n\n\n\n\n\n\ntrain, test 데이터로 정리\n\npreprocessed_train = df_chk_missing[:train_length].copy()\npreprocessed_test = df_chk_missing[train_length:].copy()\nprice_train = y.copy()\n\n# date(날짜)의 타입을 int로 변경 (변경하지 않는 경우 object타입으로 인한 오류 발생)\npreprocessed_train['date'] = preprocessed_train['date'].astype(int)\npreprocessed_test['date'] = preprocessed_test['date'].astype(int)\n\nprint(preprocessed_train.shape)\nprint(preprocessed_test.shape)\n\n(15035, 19)\n(6555, 19)"
  },
  {
    "objectID": "posts/coach-ml-kaggle-20230506/index.html#scikit-learn-등-관련-패키지-불러오기",
    "href": "posts/coach-ml-kaggle-20230506/index.html#scikit-learn-등-관련-패키지-불러오기",
    "title": "[Scikit-learn] Kaggle 집값예측 실습",
    "section": "Scikit-learn 등 관련 패키지 불러오기",
    "text": "Scikit-learn 등 관련 패키지 불러오기\n\n본래 사용하는 패키지는 모두 최상단에서 불러오는게 맞음!\n\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold, cross_val_score\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\n모델 불러오고 Cross Validation으로 모델성능 측청\n\ngboost = GradientBoostingRegressor(random_state=1210)\nxgboost = xgb.XGBRegressor(random_state=1210)\nlightgbm = lgb.LGBMRegressor(random_state=1210)\n\nmodel_dict = {'GradientBoosting':gboost,\n              'XGBoost':xgboost,\n              'LigntGBM':lightgbm}\n\n# LightGBM의 메시지가 나오지 않도록 별도로 저장 후 출력\nmodel_cv_score = dict()\nfor model in model_dict.keys():\n    model_cv_score[model] = np.mean(cross_val_score(model_dict[model], X=preprocessed_train, y=price_train))\n\n\nfor model in model_dict.keys():\n    print(f'{model} : {model_cv_score[model]}')\n\nGradientBoosting : 0.8613647608814923\nXGBoost : 0.8762617283884332\nLigntGBM : 0.8818569800403846\n\n\n\n\n모델학습 및 예측\n\nScore가 가장 높았던 lightGBM으로 진행해보기\n\n\nmodel_dict['LigntGBM'].fit(preprocessed_train.values, y)\nprediction = model_dict['LigntGBM'].predict(preprocessed_test.values)\nprediction\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2338\n[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 19\n[LightGBM] [Info] Start training from score 540682.653143\n\n\narray([1296687.09405506,  311847.90404507,  806735.28228208, ...,\n       1726006.82963994,  395020.94053356,  333594.29000994])\n\n\n\n\n제출용 DataFrame 및 csv파일 생성\n\ndf_submission = pd.DataFrame({'id' : test_id, \n                              'price' : prediction})\ndf_submission\n\n\n\n\n\n\n\n\n\nid\nprice\n\n\n\n\n0\n15208\n1.296687e+06\n\n\n1\n15209\n3.118479e+05\n\n\n2\n15210\n8.067353e+05\n\n\n3\n15211\n2.098083e+05\n\n\n4\n15212\n4.343237e+05\n\n\n...\n...\n...\n\n\n6550\n21758\n4.230647e+05\n\n\n6551\n21759\n5.111171e+05\n\n\n6552\n21760\n1.726007e+06\n\n\n6553\n21761\n3.950209e+05\n\n\n6554\n21762\n3.335943e+05\n\n\n\n\n6555 rows × 2 columns\n\n\n\n\n\ndf_submission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "",
    "text": "모든 정보가 하나의 ERP에 있음에도, 기능 별로 메뉴가 구분되어 있어 비효율/불편함\n\n주요기능 : L/C수신, L/C등록, 세금계산서 조회, 물품수령증 조회, 은행네고\n\n모든 정보가 전자화되어있으나, 각 서류의 내용(주문번호 등)이 일치하는지 눈으로 확인중\n\n24자리 영문/숫자 혼합 등이 있으며, 틀리면 물품대금을 받지 못하므로 확인이 매우 중요함\n\n각 서류, 행위마다 관련된 법 조항이 있어 준수해야 함\n\nex) XX서류가 발행되고 N일 내에 YY서류 제출\n\nDashboard형태로 구성하여 한번에 정보조회를 하고, 주요정보 일치여부 확인을 자동화\n\n\n[용어설명] L/C : 물품주문서이자 대금청구시 사용될 은행계좌와 비슷한 역할 (Letter of Credit, 신용장) 물품수령증 : 고객이 물건을 정상수령하였다는 서류, 대금청구에 사용할 수 있다 은행네고 : 정상수령했다는 서류 등을 제출하여, 은행에 준비되어있는 물품대금을 받을 수 있다\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#개요",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#개요",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "",
    "text": "추진배경\n\n\n모든 정보가 하나의 ERP에 있음에도, 기능 별로 메뉴가 구분되어 있어 비효율/불편함 ↑\n\nL/C수신, L/C등록, 세금계산서 조회, 물품수령증 조회, 은행네고\n\n모든 정보가 전자화되어있으나, 각 서류의 내용(주문번호 등)이 일치하는지 눈으로 확인중\n\n24자리 영문/숫자 혼합 등이 있으며, 틀리면 물품대금을 받지 못하므로 확인이 매우 중요함\n\n[용어설명]\n**L/C** : **물품주문서**이자 **대금청구시 사용될 은행계좌**와 비슷한 역할\n    (Letter of Credit, 신용장)\n**물품수령증** : 고객이 물건을 정상수령하였다는 서류, 대금청구에 사용할 수 있다\n**은행네고** : 정상수령했다는 서류 등을 제출하여, 은행에서 물품대금을 받을 수 있다\n\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting, win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드 : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#개념",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#개념",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "개념",
    "text": "개념\nRMSE(Root Mean Squeare Error)\nRoot    (4)\nMean    (3)\nSquare  (2)\nError   (1)\n(1) 실제값에서 예측값을 뺀 '오차'를\n(2) 합했을 때 음수의 영향을 제거하기 위해 '제곱'하고\n(3) '평균'오차로 만든 후\n(4) '루트'를 씌워 값의 크기를 작게 한다 (값을 작게하여 연산속도에 이점이 있다)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#파일-다운로드-및-알아보기",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#파일-다운로드-및-알아보기",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "파일 다운로드 및 알아보기",
    "text": "파일 다운로드 및 알아보기\nFile descriptions\ntrain.csv - 예측 모델을 만들기 위해 사용하는 학습 데이터입니다. 집의 정보와 예측할 변수인 가격(Price) 변수를 가지고 있습니다.\ntest.csv - 학습셋으로 만든 모델을 가지고 예측할 가격(Price) 변수를 제외한 집의 정보가 담긴 테스트 데이터 입니다.\nsample_submission.csv - 제출시 사용할 수 있는 예시 submission.csv 파일입니다.\nData fields\nID : 집을 구분하는 번호\ndate : 집을 구매한 날짜\nprice : 집의 가격(Target variable)\nbedrooms : 침실의 수\nbathrooms : 화장실의 수\nsqft_living : 주거 공간의 평방 피트(면적)\nsqft_lot : 부지의 평방 피트(면적)\nfloors : 집의 층 수\nwaterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\nview : 집이 얼마나 좋아 보이는지의 정도\ncondition : 집의 전반적인 상태\ngrade : King County grading 시스템 기준으로 매긴 집의 등급\nsqft_above : 지하실을 제외한 평방 피트(면적)\nsqft_basement : 지하실의 평방 피트(면적)\nyr_built : 지어진 년도\nyr_renovated : 집을 재건축한 년도\nzipcode : 우편번호\nlat : 위도\nlong : 경도\nsqft_living15 : 2015년 기준 주거 공간의 평방 피트(면적, 집을 재건축했다면, 변화가 있을 수 있음)\nsqft_lot15 : 2015년 기준 부지의 평방 피트(면적, 집을 재건축했다면, 변화가 있을 수 있음)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#패키지-및-데이터-불러오기",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#패키지-및-데이터-불러오기",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "패키지 및 데이터 불러오기",
    "text": "패키지 및 데이터 불러오기\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_data_path = './data/train.csv'\ntest_data_path = './data/test.csv'\n\ndata = pd.read_csv(train_data_path)\ntest = pd.read_csv(test_data_path)\nprint('train data : {}'.format(data.shape))\nprint('test data : {}'.format(test.shape))\n\ntrain data : (15035, 21)\ntest data : (6555, 20)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#데이터-전처리",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#데이터-전처리",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "데이터 전처리",
    "text": "데이터 전처리\n\n정답컬럼 분리\n\ntest데이터와 달리 train data에는 컬럼이 1개 더 있음 (정답컬럼인 price)\n별도의 정답 데이터(y)로 분리\n\n\nprint('컬럼 분리 전')\nprint(data.columns)\nprint(test.columns)\n\n컬럼 분리 전\nIndex(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\n\n\n\n# y라는 변수에 price(정답)을 옮기고, 전체데이터를 백업(data_backup에 할당)하고 price컬럼 삭제\ny = data['price'] \ndata_backup = data.copy()\ndata.drop('price',axis=1, inplace=True)\n\n\nprint('컬럼 분리 후')\nprint(data.columns)\nprint(test.columns)\nprint(y.name)\n\n컬럼 분리 후\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nIndex(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n       'sqft_living15', 'sqft_lot15'],\n      dtype='object')\nprice\n\n\n\n\n결측치 확인 및 제거\n\ntrain, test 데이터를 합쳐서 한번에 확인\n\n\n# 합치기\ndf_chk_missing = pd.concat((data, test), axis=0)\n\n# 향후 분할을 대비한 행 수 저장\ntrain_length = len(data)\ntest_length = len(test)\n\nprint(train_length, test_length)\n\n15035 6555\n\n\n\n결측치 확인방법1(pandas)\n\nisna()로 결측치를 확인\n\n\nprint(df_chk_missing.isna().sum())\n\nid               0\ndate             0\nbedrooms         0\nbathrooms        0\nsqft_living      0\nsqft_lot         0\nfloors           0\nwaterfront       0\nview             0\ncondition        0\ngrade            0\nsqft_above       0\nsqft_basement    0\nyr_built         0\nyr_renovated     0\nzipcode          0\nlat              0\nlong             0\nsqft_living15    0\nsqft_lot15       0\ndtype: int64\n\n\n\n\n결측치 확인방법2(missingno)\n\nmissingno 패키지로 컬럼별 결측치 시각화\n\n\nimport missingno\n\nmissingno.matrix(df_chk_missing)\n\n\n\n\n\n\n\n\n\n\n결측치 확인방법3(ydata_profiling)\n\nydata_profiling 패키지로 결측치 및 다양한 값 확인 가능\n렌더링 용량 문제로 실행결과는 이미지로 대체(RangeError: Maximum call stack size exceeded)\n\n\nfrom ydata_profiling import ProfileReport\n\nprofile = ProfileReport(df_chk_missing, title=\"Profiling Report\")\nprofile\n\n\n\n\n실행결과 샘플\n\n\n\n결측치가 없으므로 다음 과정을 진행\n\n\n\n\n불필요한 변수 제거, 데이터 변환 등\n\n단순식별용 데이터 삭제\n\n가격과 관계없는 단순식별용 데이터인 id 삭제\n\n\nmain_id = df_chk_missing['id'][:train_length]\ntest_id = df_chk_missing['id'][train_length:]\ndel df_chk_missing['id']\n\n\n\n불필요한 데이터 삭제\n\n날짜 뒤에 T00000과 같이 시간데이터(로 추정됨)가 있는데, 모두 T00000으로만 되어있으므로 삭제\n\n\n# T000000으로 되어있는 값 세기\ndf_chk_missing['date'].str.contains('T000000').value_counts()\n\ndate\nTrue    21590\nName: count, dtype: int64\n\n\n\n# apply로 lambda함수를 사용하여, date컬럼의 앞자리만 저장\ndf_chk_missing['date'] = df_chk_missing['date'].apply(lambda x : str(x[:6]))\ndf_chk_missing.head()\n\n\n\n\n\n\n\n\n\ndate\nbedrooms\nbathrooms\nsqft_living\nsqft_lot\nfloors\nwaterfront\nview\ncondition\ngrade\nsqft_above\nsqft_basement\nyr_built\nyr_renovated\nzipcode\nlat\nlong\nsqft_living15\nsqft_lot15\n\n\n\n\n0\n201410\n3\n1.00\n1180\n5650\n1.0\n0\n0\n3\n7\n1180\n0\n1955\n0\n98178\n47.5112\n-122.257\n1340\n5650\n\n\n1\n201502\n2\n1.00\n770\n10000\n1.0\n0\n0\n3\n6\n770\n0\n1933\n0\n98028\n47.7379\n-122.233\n2720\n8062\n\n\n2\n201502\n3\n2.00\n1680\n8080\n1.0\n0\n0\n3\n8\n1680\n0\n1987\n0\n98074\n47.6168\n-122.045\n1800\n7503\n\n\n3\n201406\n3\n2.25\n1715\n6819\n2.0\n0\n0\n3\n7\n1715\n0\n1995\n0\n98003\n47.3097\n-122.327\n2238\n6819\n\n\n4\n201501\n3\n1.50\n1060\n9711\n1.0\n0\n0\n3\n7\n1060\n0\n1963\n0\n98198\n47.4095\n-122.315\n1650\n9711\n\n\n\n\n\n\n\n\n\n\n로그변환\n\n치우친 분포를 정규분포에 가깝게 만들기\n\n\n분포가 치우쳐져 있는 항목 찾기(시각화)\n\nrow_plot = 5\ncol_plot = 4\nfig, ax = plt.subplots(row_plot, col_plot, figsize=(24, 35)) \n\ncolumns = df_chk_missing.columns\ncolumns_idx = 1 # 첫 컬럼인 date(날짜)는 제외하기 위해 0이 아닌 1부터 시작\nfor row in range(row_plot):\n    for col in range(col_plot):\n        sns.kdeplot(data=df_chk_missing[columns[columns_idx]], ax=ax[row][col])\n        ax[row][col].set_title(columns[columns_idx])\n        columns_idx += 1\n        if columns_idx == len(columns) :\n            break\n\n\n\n\n\n\n\n\n\n아래의 항목들이 치우쳐져 있음\n\nsqft_living\nsqft_lot\nwaterfront (→유/무 지표로 0,1만 있는게 정상이므로 제외)\nsqft_above\nsqft_basement\nsqft_living15\nsqft_lot15\n\n\n\n# 변환대상 리스트에 저장\nskewed_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']\n\n# 그래프로 그리기 (변환 전/후 그래프를 함께 그릴 예정이므로 plot의 수는 두배)\nrow_plot = 6\ncol_plot = 2\nfig, ax = plt.subplots(row_plot, col_plot, figsize=(15, 35)) \n\ncolumns = skewed_columns\ncolumns_idx = 0\n\n\nfor row in range(row_plot):\n    # 로그변환 대상만 식별 후 진행\n    if columns[row] in skewed_columns:\n        # 기존 그래프 그리기\n        sns.kdeplot(data=df_chk_missing[columns[row]], ax=ax[row][0])\n        ax[row][0].set_title(columns[row])\n\n        # 로그변환\n        df_chk_missing[columns[row]] = np.log1p(df_chk_missing[columns[row]])\n\n        # 변환된 그래프 그리기\n        sns.kdeplot(data=df_chk_missing[columns[row]], ax=ax[row][1])\n        ax[row][1].set_title(columns[row]+'_log')\n\n\n\n\n\n\n\n\n\n\n\ntrain, test 데이터로 정리\n\npreprocessed_train = df_chk_missing[:train_length].copy()\npreprocessed_test = df_chk_missing[train_length:].copy()\nprice_train = y.copy()\n\n# date(날짜)의 타입을 int로 변경 (변경하지 않는 경우 object타입으로 인한 오류 발생)\npreprocessed_train['date'] = preprocessed_train['date'].astype(int)\npreprocessed_test['date'] = preprocessed_test['date'].astype(int)\n\nprint(preprocessed_train.shape)\nprint(preprocessed_test.shape)\n\n(15035, 19)\n(6555, 19)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#scikit-learn-등-관련-패키지-불러오기",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#scikit-learn-등-관련-패키지-불러오기",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "Scikit-learn 등 관련 패키지 불러오기",
    "text": "Scikit-learn 등 관련 패키지 불러오기\n\n본래 사용하는 패키지는 모두 최상단에서 불러오는게 맞음!\n\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold, cross_val_score\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\n모델 불러오고 Cross Validation으로 모델성능 측청\n\ngboost = GradientBoostingRegressor(random_state=1210)\nxgboost = xgb.XGBRegressor(random_state=1210)\nlightgbm = lgb.LGBMRegressor(random_state=1210)\n\nmodel_dict = {'GradientBoosting':gboost,\n              'XGBoost':xgboost,\n              'LigntGBM':lightgbm}\n\n# LightGBM의 메시지가 나오지 않도록 별도로 저장 후 출력\nmodel_cv_score = dict()\nfor model in model_dict.keys():\n    model_cv_score[model] = np.mean(cross_val_score(model_dict[model], X=preprocessed_train, y=price_train))\n\n\nfor model in model_dict.keys():\n    print(f'{model} : {model_cv_score[model]}')\n\nGradientBoosting : 0.8613647608814923\nXGBoost : 0.8762617283884332\nLigntGBM : 0.8818569800403846\n\n\n\n\n모델학습 및 예측\n\nScore가 가장 높았던 lightGBM으로 진행해보기\n\n\nmodel_dict['LigntGBM'].fit(preprocessed_train.values, y)\nprediction = model_dict['LigntGBM'].predict(preprocessed_test.values)\nprediction\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2338\n[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 19\n[LightGBM] [Info] Start training from score 540682.653143\n\n\narray([1296687.09405506,  311847.90404507,  806735.28228208, ...,\n       1726006.82963994,  395020.94053356,  333594.29000994])\n\n\n\n\n제출용 DataFrame 및 csv파일 생성\n\ndf_submission = pd.DataFrame({'id' : test_id, \n                              'price' : prediction})\ndf_submission\n\n\n\n\n\n\n\n\n\nid\nprice\n\n\n\n\n0\n15208\n1.296687e+06\n\n\n1\n15209\n3.118479e+05\n\n\n2\n15210\n8.067353e+05\n\n\n3\n15211\n2.098083e+05\n\n\n4\n15212\n4.343237e+05\n\n\n...\n...\n...\n\n\n6550\n21758\n4.230647e+05\n\n\n6551\n21759\n5.111171e+05\n\n\n6552\n21760\n1.726007e+06\n\n\n6553\n21761\n3.950209e+05\n\n\n6554\n21762\n3.335943e+05\n\n\n\n\n6555 rows × 2 columns\n\n\n\n\n\ndf_submission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#github-repository",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#github-repository",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "github repository",
    "text": "github repository\n관련 github레포"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "",
    "text": "사용빈도가 높은 정보가 여러 탭에 나뉘어 있고, 이러한 정보들을 주문(SR)별로 각각 조회하는 불편함이 있음\n유저 화면에서 보여줄 수 있는 행(row)이 4줄로 적고, 필요한 정보를 각각 복사하여 정리하는 불편함이 있음\n\n한번에 많은 물품이 포함된 경우, 수십건의 같거나 다른 HSCODE들을 하나의 줄 글로 정리함\n출발지와 도착지, 제품의 품명 등을 요약하여 요구받는 경우 작업시간이 소요됨\n\n각 탭 정보를 일괄 크롤링하고, 필요할 때 별도의 가공/복사작업 없이 바로 사용가능한 정보로 제공하도록 함\n\n확인가능한 정보 : Sales Org, Plant(Code,Name), POL(출발지), POD(도착지), HSCODE, Description(물품명세)\n\n\n\n[용어설명] SR : 하나의 기본 선적 단위, Shipping request HSCODE : 해외로 물건을 보내기 위해 수출신고할 때, (의약품, 전자기기 등)물품 종류를 알 수 있는 제품 코드\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#개요",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#개요",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "",
    "text": "필요한 정보가 여러 탭에 산재되어있거나, 줄 글로 뭉쳐져있어 별도의 가공/복사과정없이 주요정보를 바로 사용하게 해주는 Tool\n확인가능한 정보 : Sales Org, Plant(Code,Name), POL, POD, HSCODE, Description"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#github-repository",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#github-repository",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "github repository",
    "text": "github repository\n관련 github레포"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#사용법",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#사용법",
    "title": "[Python] Shipping request내 주요정보 크롤링 & 정리용 파일",
    "section": "사용법",
    "text": "사용법\n\n1건 확인 * 두번째 박스 sr_no 변수에 SR번호 1개를 입력하면 주요 정보 확인\n여러 건 확인 * 세번째 박스 sr_no 변수의 ’‘’와’’’사이에 모든 SR번호 입력 (, 즉 엔터를 기준으로 구분한다) (엑셀 등에서 표 형태로 붙여넣는 경우가 많기때문에 사용성을 고려한 옵션)\n엑셀로 저장 * 확인한 내용을 엑셀로 저장하고 싶은 경우, 네번째 박스 실행, 지정된 파일명+오늘날짜를 기준으로 다운로드 함 (몇번이나 쓸까 싶긴 하지만, 언제나 의외의 상황때문에 필요해질 수 있으니 미리 구현해두는 기능)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#사용법-및-설계의도",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#사용법-및-설계의도",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "사용법 및 설계의도",
    "text": "사용법 및 설계의도\n\n1건 확인 * 두번째 박스 sr_no 변수에 SR번호 1개를 입력하면 주요 정보 확인\n여러 건 확인 * 세번째 박스 sr_no 변수의 ’‘’와’’’사이에 모든 SR번호 입력 (, 즉 엔터를 기준으로 구분한다) (엑셀 등에서 표 형태로 붙여넣는 경우가 많기때문에 사용성을 고려한 옵션)\n엑셀로 저장 * 확인한 내용을 엑셀로 저장하고 싶은 경우, 네번째 박스 실행, 지정된 파일명+오늘날짜를 기준으로 다운로드 함 (몇번이나 쓸까 싶긴 하지만, 언제나 의외의 상황때문에 필요해질 수 있으니 미리 구현해두는 기능)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#추진배경",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#추진배경",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "",
    "text": "모든 정보가 하나의 ERP에 있음에도, 기능 별로 메뉴가 구분되어 있어 비효율/불편함\n\n주요기능 : L/C수신, L/C등록, 세금계산서 조회, 물품수령증 조회, 은행네고\n\n모든 정보가 전자화되어있으나, 각 서류의 내용(주문번호 등)이 일치하는지 눈으로 확인중\n\n24자리 영문/숫자 혼합 등이 있으며, 틀리면 물품대금을 받지 못하므로 확인이 매우 중요함\n\n각 서류, 행위마다 관련된 법 조항이 있어 준수해야 함\n\nex) XX서류가 발행되고 N일 내에 YY서류 제출\n\nDashboard형태로 구성하여 한번에 정보조회를 하고, 주요정보 일치여부 확인을 자동화\n\n\n[용어설명] L/C : 물품주문서이자 대금청구시 사용될 은행계좌와 비슷한 역할 (Letter of Credit, 신용장) 물품수령증 : 고객이 물건을 정상수령하였다는 서류, 대금청구에 사용할 수 있다 은행네고 : 정상수령했다는 서류 등을 제출하여, 은행에 준비되어있는 물품대금을 받을 수 있다"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#구현-목적내용-및-사용한-언어패키지",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#구현-목적내용-및-사용한-언어패키지",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "구현 목적/내용 및 사용한 언어/패키지",
    "text": "구현 목적/내용 및 사용한 언어/패키지\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting, win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드 : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#구현-목적내용-사용한-언어패키지",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#구현-목적내용-사용한-언어패키지",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "구현 목적/내용 & 사용한 언어/패키지",
    "text": "구현 목적/내용 & 사용한 언어/패키지\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting, win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드 : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#구현-내용-사용한-언어패키지",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#구현-내용-사용한-언어패키지",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "구현 내용 & 사용한 언어/패키지",
    "text": "구현 내용 & 사용한 언어/패키지\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting활용을 위한 win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup, sqlite3 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드(참고용 기록) : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#효과",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#효과",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "효과",
    "text": "효과\n\n유저가 각 메뉴코드를 기억/저장할 필요없이 한번에 정보를 확인하여 소요시간 및 불편사항 제거\n시스템 검증을 통한 Human error제거, 육안확인시간 감소 & 물품대금 정상입수"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#구현내용-사용한-언어패키지-등-세부내용",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#구현내용-사용한-언어패키지-등-세부내용",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "구현내용 & 사용한 언어/패키지 등 세부내용",
    "text": "구현내용 & 사용한 언어/패키지 등 세부내용\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting활용을 위한 win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup, sqlite3 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드(참고용 기록) : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-local-20240122/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "href": "posts_miniprojects/sel-py-local-20240122/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "title": "[Python] LocalL/C 관리용 Tool",
    "section": "[세부내용] 구현내용 & 사용한 언어/패키지 등",
    "text": "[세부내용] 구현내용 & 사용한 언어/패키지 등\n\n정보가 파편화되어있어 하나의 Tool로써 확인하고 관리하기 위해서 Streamlit 기반으로 만듦\n\n\n정보 저장 및 조회\n\n내부정보는 ERP에서 가져와서 db에 적재(SAP Scripting활용을 위한 win32com 사용)\n외부정보는 xml을 읽어서 Tag로 필요한 정보를 찾아 db에 적재(Beautifulsoup, sqlite3 사용) (외부정보라고는 하나, ERP에 저장되어있는 xml을 불러들여서 사용함)\n데이터 저장 및 최초 쿼리는 SQL문으로 가져오나, join등 필요한 사후처리는 pandas를 활용\n\n\n\nERP에 직접 입력하는 등의 수작업을 자동으로 수행\n\n\n자동화 기능\n\nERP 수주내역 등록(고정정보는 Master화, 변동정보는 Streamlit 텍스트박스 활용)\n준수사항(법령 등)의 자동체크\n\n특정 날짜 내에 완료해야한다던가, 일치해야하는 내용 등을 자동으로 검수\nStreamlit의 table내 체크박스표기(True,False)를 활용하여 이상여부를 직관적으로 확인 가능\n사용자가 어떤 행동을 해야하는지 참고사항란을 통해 지시(연장요청, 수령증발행요청 등)\n\n보유내역 및 관리대상(작업이 완료되지 않은 건)의 Filter 기능 제공(드롭박스로 선택)\nERP의 ID, PW를 입력해두어 작업 자동화 수행\n\n개인PC에서만 사용하는 Tool이며, 표기는 ***과 같이 암호화 표기되어 관리\n\n\n\n\n설계시 고려사항, 특이사항, 참고사항\n\n\n추가/삭제/변경 등 변동될 수 있는 정보는 Hardcoding이 아닌 db형태로 저장\n\n오류 등 상황에 대비하여 실행시 기존 db를 복사해두는 로직 구현해두었으나, 자주 실행시 과생성되어 향후 수정 예정\n\nERP관련 기능은 SAP메뉴(T-code)기준으로 함수화하여 관리\n정보조회 관련 기능은 기능별 dataframe 생성/변환하는 방향으로 함수화하여 관리\nERP제어(SAP Scripting) 주요기능을 구현한 ’NERP_PI_LC’는 자체제작한 것으로 정리하여 업로드 예정(pip 미등록)\n수익자기준 주요 EDI코드(참고용 기록) : 내국신용장(LOCADV), 물품수령증(LOCRCT)\n\nBeautifulSoup를 위해 정리해둔 딕셔너리(locrct_id, locadv_id)는 표준규격일 것으로 예상하여 재사용가능할 것으로 예상\n\n\n\nLocal L/C에 대한 세부정보 참고가능한 사이트\n\nKTNET - 이용안내 - 상세업무절차"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#추진배경",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#추진배경",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "",
    "text": "사용빈도가 높은 정보가 여러 탭에 나뉘어 있고, 이러한 정보들을 주문(SR)별로 각각 조회하는 불편함이 있음\n유저 화면에서 보여줄 수 있는 행(row)이 4줄로 적고, 필요한 정보를 각각 복사하여 정리하는 불편함이 있음\n\n한번에 많은 물품이 포함된 경우, 수십건의 같거나 다른 HSCODE들을 하나의 줄 글로 정리함\n출발지와 도착지, 제품의 품명 등을 요약하여 요구받는 경우 작업시간이 소요됨\n\n각 탭 정보를 일괄 크롤링하고, 필요할 때 별도의 가공/복사작업 없이 바로 사용가능한 정보로 제공하도록 함\n\n확인가능한 정보 : Sales Org, Plant(Code,Name), POL(출발지), POD(도착지), HSCODE, Description(물품명세)\n\n\n\n[용어설명] SR : 하나의 기본 선적 단위, Shipping request HSCODE : 해외로 물건을 보내기 위해 수출신고할 때, (의약품, 전자기기 등)물품 종류를 알 수 있는 제품 코드"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#효과",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#효과",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "효과",
    "text": "효과\n\n단건 또는 여러건의 주문(SR)에 대해 건당 1~2초 이내로 필요한 정보 수집\n클립보드 복사가 가능한 텍스트, 엑셀형태로 제공하여 요구사항에 대해 즉시대응 가능"
  },
  {
    "objectID": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "href": "posts_miniprojects/sel-py-crawl_sr-20240306/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "title": "[Python] ERP(SAP) 특정 메뉴의 주요정보 크롤링 & 정리 Tool",
    "section": "[세부내용] 구현내용 & 사용한 언어/패키지 등",
    "text": "[세부내용] 구현내용 & 사용한 언어/패키지 등\n\n단건 확인시, 코드셀에 붙여넣기 후 실행, 텍스트로 출력하며 pandas dataframe으로도 저장하여 필요시 엑셀도 제공\n여러건 확인시, 엑셀 등에서 복사한 표를 코드셀에 바로 붙여넣도록 설계(자동 분할, 편의성 고려함) 이후 작업은 단건 확인과 동일\n필요시 엑셀로 저장 (기존 업무유형상 출력텍스트가 더 많이 활용될 것으로 보여 별도 기능으로 추가함)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html",
    "href": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html",
    "title": "[Python] COO발급관리용 Tool",
    "section": "",
    "text": "업무상 공용ID가 3개로 나뉘어있으나, 모두 공동인증서 로그인으로 접속에 불편함이 있음 (ID, PW, 공동인증서PW)\n\n발급현황확인, 발급거절시 사유확인 후 보완 등 진행\n\n발급거절(오류통보) 사유확인시, 건별로 클릭하여 메뉴진입 필요\n월마다 20여개 페이지의 표를 복사해서 가공하는 작업 수행중(데이터 Merge, 필터링 등)\n각 포인트에 대해 대응할 수 있는 여러 기능을 탑재한 통합관리 Tool 제작\n\n주기적으로 3개 ID로 접속하여, 주요정보를, ID에 대응되는 테이블에 db형태로 저장(공용PC)\n유저는 streamlit으로 제작한 사이트에 접속해서 필요한 내용 확인/검색\n희망하는 경우, 대표Invoice번호를 등록해두면 발급완료/발급거절(보완) 상황발생시 toast알림\n월마다 가공하는 데이터에 대해서는, 별도버튼으로 db추출 후 가공완료한 데이터 제공\nID에 대응하는 로그인 버튼을 누르면 자동로그인 후 작업창을 띄워주는 기능 제공\n\n\n\n[용어설명] COO : 원산지증명서, Country of Origin\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#추진배경",
    "href": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#추진배경",
    "title": "[Python] COO발급관리용 Tool",
    "section": "",
    "text": "업무상 공용ID가 3개로 나뉘어있으나, 모두 공동인증서 로그인으로 접속에 불편함이 있음 (ID, PW, 공동인증서PW)\n\n발급현황확인, 발급거절시 사유확인 후 보완 등 진행\n\n발급거절(오류통보) 사유확인시, 건별로 클릭하여 메뉴진입 필요\n월마다 20여개 페이지의 표를 복사해서 가공하는 작업 수행중(데이터 Merge, 필터링 등)\n각 포인트에 대해 대응할 수 있는 여러 기능을 탑재한 통합관리 Tool 제작\n\n주기적으로 3개 ID로 접속하여, 주요정보를, ID에 대응되는 테이블에 db형태로 저장(공용PC)\n유저는 streamlit으로 제작한 사이트에 접속해서 필요한 내용 확인/검색\n희망하는 경우, 대표Invoice번호를 등록해두면 발급완료/발급거절(보완) 상황발생시 toast알림\n월마다 가공하는 데이터에 대해서는, 별도버튼으로 db추출 후 가공완료한 데이터 제공\nID에 대응하는 로그인 버튼을 누르면 자동로그인 후 작업창을 띄워주는 기능 제공\n\n\n\n[용어설명] COO : 원산지증명서, Country of Origin"
  },
  {
    "objectID": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#효과",
    "href": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#효과",
    "title": "[Python] COO발급관리용 Tool",
    "section": "효과",
    "text": "효과\n\n불편했던 로그인 작업 수요감소(필요 데이터의 streamlit 대시보드 제공, toast알림 제공), 로그인 편의성 증가\n월 가공작업 삭제(sql query로 추출시 원하는 형태로 저장, streamlit에서 query문 조건변경 가능[날짜조건, 파일경로 등])"
  },
  {
    "objectID": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#github-repository",
    "href": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#github-repository",
    "title": "[Python] COO발급관리용 Tool",
    "section": "github repository",
    "text": "github repository\n관련 github레포"
  },
  {
    "objectID": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "href": "posts_miniprojects/sel-py-monitoringCOO-20240220/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "title": "[Python] COO발급관리용 Tool",
    "section": "[세부내용] 구현내용 & 사용한 언어/패키지 등",
    "text": "[세부내용] 구현내용 & 사용한 언어/패키지 등\n\n저장할 db는 sqlite3으로 테이블 생성, 컬럼지정 등을 수행함 (컬럼별 조건은 하단 참조)\n\n\n접수번호 varchar PRIMARY KEY , → 대표Invoice와 고민했는데, 100% 유일값이라 Primary로 지정 증명서종류 varchar,  대표Invoice varchar(10), 접수일시 datetime,  처리상태 varchar,  Remark varchar\n\n\n각 기능은 아래의 파일로 나누어 개인/공용PC에서 실행\n\n\nMonitoringCOO(기본파일) : streamlit활용한 UI, json/pickle파일 읽기, 유저의 자동로그인, 월추출 데이터 저장 등\n\n마지막 스크레핑 시점을 표기하여 얼마나 최신화된 데이터인지 유저에게 공유\n\nMonitoringCOO_crawler : selenium으로 스크레핑, 스크레핑작업에 필요한 로그인 기능(pyautogui, pywin32로 이미지/키/윈도우 인식)\n\n유저가 기본파일에서 로그인기능을 사용하는 경우, 이 파일에서 import해서 사용하고 코드는 여기서 통합관리\n스크레핑작업은 기본적으로 Scheduler파일에서 실행되지만, 필요시 이 파일을 실행하여 수동 스크레핑 (코드는 여기서 통합관리)\n\nMonitoringCOO_push : 기본파일에서 유저가 등록해둔 대표Invoice번호를 db에서 조회하여, win11toast로 알림 (처음에는 파이썬과 호환성/속도가 좋은 pickle/list로 관리하고자 했으나, 사용자ID등 추가정보 관리가 필요하여 json/dict로 관리)\nScheduler : 스크레핑 주기/시간을 관리하는 파일. 주로 공용PC에서 작업 (9~17시 이후엔 데이터변경이 없으므로 이 시간대에만 작동하도록 설정, 서버설정 등을 고려하여 작업주기 반영 예정)"
  },
  {
    "objectID": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html",
    "href": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html",
    "title": "[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록",
    "section": "",
    "text": "제공받는 PI서류에, 시스템 등록에 필요한 일부가 늘 빠져있으며 별도 테이블을 참고하여 대응중\n기계가 인식할 수 있는 pdf로 제공되고 있으나, 마우스로 드래그하여 복사/붙여넣기를 반복\n제공하는 담당자의 내부규정때문에, 1메일:1파일로 나누어 여러 건을 별도메일로 제공중\n향후 분쟁대비, 또는 법적인 사유로 pdf의 이름을 변경하여 별도로 저장하는 작업중\n납품(수출)시 사용될 중요한 정보로 사용되며, 오류발생시 다른 국가로의 오배송, 수입절차 문제 등 발생\n각 포인트에 대응할 수 있도록 아래의 형태로 개발 추진\n\n아웃룩으로 수신된 메일의 첨부를 열어 필요한 각 항목을 regex로 리딩\n리딩된 정보 중 최소 확인사항을 코드가 검증 ex) 한국 수출인데 홍콩물품에 대해 보험을 드는 등 논리오류 검증\n시스템 등록 후 파일명 변경 및 아카이브에 자동 저장\n백그라운드에서 실행되며, 작업이 완료되면 윈도우 toast메시지로 알림\n\n\n\n[용어설명] PI : 수출납품계약서로 발주자의 양식 등을 사용함, Proforma Invoice regex : 정규표현식, 특정한 규칙을 통해 문자를 검색/편집하는데 사용\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#추진배경",
    "href": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#추진배경",
    "title": "[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록",
    "section": "",
    "text": "제공받는 PI서류에, 시스템 등록에 필요한 일부가 늘 빠져있으며 별도 테이블을 참고하여 대응중\n기계가 인식할 수 있는 pdf로 제공되고 있으나, 마우스로 드래그하여 복사/붙여넣기를 반복\n제공하는 담당자의 내부규정때문에, 1메일:1파일로 나누어 여러 건을 별도메일로 제공중\n향후 분쟁대비, 또는 법적인 사유로 pdf의 이름을 변경하여 별도로 저장하는 작업중\n납품(수출)시 사용될 중요한 정보로 사용되며, 오류발생시 다른 국가로의 오배송, 수입절차 문제 등 발생\n각 포인트에 대응할 수 있도록 아래의 형태로 개발 추진\n\n아웃룩으로 수신된 메일의 첨부를 열어 필요한 각 항목을 regex로 리딩\n리딩된 정보 중 최소 확인사항을 코드가 검증 ex) 한국 수출인데 홍콩물품에 대해 보험을 드는 등 논리오류 검증\n시스템 등록 후 파일명 변경 및 아카이브에 자동 저장\n백그라운드에서 실행되며, 작업이 완료되면 윈도우 toast메시지로 알림\n\n\n\n[용어설명] PI : 수출납품계약서로 발주자의 양식 등을 사용함, Proforma Invoice regex : 정규표현식, 특정한 규칙을 통해 문자를 검색/편집하는데 사용"
  },
  {
    "objectID": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#효과",
    "href": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#효과",
    "title": "[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록",
    "section": "효과",
    "text": "효과\n\n건별 메일열람 - 논리오류 검증 - 시스템 등록(복사/붙여넣기, 별도테이블 참고) - 파일명 변경 및 저장 등 프로세스 제거\nHuman error 제거로 인한 다른 국가로의 오배송(재운송에 필요한 각종 비용), 수입절차(법적이슈) 등 문제예방"
  },
  {
    "objectID": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#github-repository",
    "href": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#github-repository",
    "title": "[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록",
    "section": "github repository",
    "text": "github repository\n관련 github레포"
  },
  {
    "objectID": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "href": "posts_miniprojects/sel-py-autoPIforl001-20231215/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "title": "[Python] 아웃룩 메일열람 & pdf regex리딩 & 시스템 자동등록",
    "section": "[세부내용] 구현내용 & 사용한 언어/패키지 등",
    "text": "[세부내용] 구현내용 & 사용한 언어/패키지 등\n\npywin32로 아웃룩을 제어하여 조건에 맞는 pdf첨부 열람 등 진행\n\nselenium은 chrome버전변경 등 영향이 커서 구현했다가 미사용\n\nxlwings로 Excel로 저장해둔 별도 참고용 테이블을 열람\n\nDRM암호화와 관계없이 파일을 읽을 수 있기 때문에 xlwings를 채택\n\nre로 pdf의 문자열을 검색하여 필요한 내용을 저장\nNERP_PI_LC(주요 ERP관련 기능에 대해 제작한 파이썬 패키지)으로 시스템 등록 등을 진행\nwin11toast로 모든 작업이 완료되면 알림\n[삭제기능] selenium으로 PI제공자에게 자동회신도 했었으나, chrome업데이트 등 안정성 문제로 제외\n\n아웃룩 등 smtp발송은 내부규정상 막혀있어 사용하지 않음"
  },
  {
    "objectID": "posts_miniprojects/sel-py-readPIAR-20231101/index.html",
    "href": "posts_miniprojects/sel-py-readPIAR-20231101/index.html",
    "title": "[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩",
    "section": "",
    "text": "50~120건의 서류를 아침제공 후 오전 내 입력하도록 요청받아 다른 업무가 불가능할 정도의 피크타임 발생\n\n시차, 주문접수, 생산계획 등이 맞물려 조정이 불가능한 상황\n\n동일 양식의 내용이 다른 서류 50~120건이며, 일부 내용은 별도의 수주시스템에 시스템화되어 올려져 있음\n시스템 제약으로 글자수 제한이 있어, 주문번호를 줄이는 등 별도의 작업 수행\n정확도가 높은 수주시스템의 내용(엑셀로 저장)을 기반으로, pdf로 보완하여 자동화 추진\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#추진배경",
    "href": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#추진배경",
    "title": "[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩",
    "section": "",
    "text": "50~120건의 서류를 아침제공 후 오전 내 입력하도록 요청받아 다른 업무가 불가능할 정도의 피크타임 발생\n\n시차, 주문접수, 생산계획 등이 맞물려 조정이 불가능한 상황\n\n동일 양식의 내용이 다른 서류 50~120건이며, 일부 내용은 별도의 수주시스템에 시스템화되어 올려져 있음\n시스템 제약으로 글자수 제한이 있어, 주문번호를 줄이는 등 별도의 작업 수행\n정확도가 높은 수주시스템의 내용(엑셀로 저장)을 기반으로, pdf로 보완하여 자동화 추진"
  },
  {
    "objectID": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#효과",
    "href": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#효과",
    "title": "[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩",
    "section": "효과",
    "text": "효과\n\nTool활용을 위한 기초작업(엑셀 다운로드, pdf저장)에 5~10분 정도 소요되어, 기존 작업시간(~4시간)대비 투입시간 감소\n피크타임 감소 및 생산계획 마감시간 단축"
  },
  {
    "objectID": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#github-repository",
    "href": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#github-repository",
    "title": "[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩",
    "section": "github repository",
    "text": "github repository\n관련 github레포"
  },
  {
    "objectID": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "href": "posts_miniprojects/sel-py-readPIAR-20231101/index.html#세부내용-구현내용-사용한-언어패키지-등",
    "title": "[Python] Peak타임 대응용 수출계약서(pdf) tabula리딩",
    "section": "[세부내용] 구현내용 & 사용한 언어/패키지 등",
    "text": "[세부내용] 구현내용 & 사용한 언어/패키지 등\n\njson으로 파일을 저장할 경로정보 및 변환할 코드정보를 관리\nxlwings로 Excel로 저장해둔 기본정보를 열람\n\nDRM암호화와 관계없이 파일을 읽을 수 있기 때문에 xlwings를 채택\n\ntabula로 pdf를 표 형태로 읽어, 지정된 자리의 정보를 읽고 json형태로 저장\njson형태로 저장된 정보를 pandas DataFrame으로 concat처리 후 저장\n시스템 등록을 위해 사용중인 별도의 VBA Tool에 저장된 Excel을 넘기면 업무 완료"
  },
  {
    "objectID": "posts/prgms-sql-20240317/index.html",
    "href": "posts/prgms-sql-20240317/index.html",
    "title": "[프로그래머스SQL] 평균 일일 대여 요금 구하기",
    "section": "",
    "text": "프로그래머스 SQL 문제풀이 연습(Oracle기준, Mysql아님)입니다  (비상업적, 비영리적 용도)\n문제링크\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/prgms-sql-20240317/index.html#개요",
    "href": "posts/prgms-sql-20240317/index.html#개요",
    "title": "[프로그래머스SQL] 평균 일일 대여 요금 구하기",
    "section": "",
    "text": "프로그래머스 SQL 문제풀이 연습(Oracle기준, Mysql아님)입니다  (비상업적, 비영리적 용도)\n문제링크"
  },
  {
    "objectID": "posts/prgms-sql-20240317/index.html#문제-평균-일일-대여-요금-구하기",
    "href": "posts/prgms-sql-20240317/index.html#문제-평균-일일-대여-요금-구하기",
    "title": "[프로그래머스SQL] 평균 일일 대여 요금 구하기",
    "section": "문제 : 평균 일일 대여 요금 구하기",
    "text": "문제 : 평균 일일 대여 요금 구하기\n\n\n\n문제 이미지"
  },
  {
    "objectID": "posts/prgms-sql-20240317/index.html#작성답안",
    "href": "posts/prgms-sql-20240317/index.html#작성답안",
    "title": "[프로그래머스SQL] 평균 일일 대여 요금 구하기",
    "section": "작성답안",
    "text": "작성답안\n\n\n\nSELECT ROUND(AVG(DAILY_FEE)) AS AVERAGE_FEE\nFROM CAR_RENTAL_COMPANY_CAR\nWHERE CAR_TYPE = 'SUV'\n\n\nFigure 1"
  },
  {
    "objectID": "posts/prgms-sql-20240317/index.html#정리",
    "href": "posts/prgms-sql-20240317/index.html#정리",
    "title": "[프로그래머스SQL] 평균 일일 대여 요금 구하기",
    "section": "정리",
    "text": "정리\n\nROUND : 반올림\nAVG : 평균\nAS ??? : 컬럼명을 ???으로 가져온다 (Alias 라고 함)\nWHERE : 작성한 조건을 기준으로 가져온다\n\nWHERE의 여러 형태예시\n\nWHERE CAR_TYPE = 'SUV'\nWHERE CAR_TYPE != 'SUV'\nWHERE DAILY_FEE &gt; 14000\nWHERE DAILY_FEE BETWEEN 14000 AND 16000\nWHERE DAILY_FEE IN (14000, 16000)\nWHERE CAR_TYPE IN ('SUV', '세단')"
  },
  {
    "objectID": "posts/prgms-sql-20240318/index.html",
    "href": "posts/prgms-sql-20240318/index.html",
    "title": "[프로그래머스SQL] 가장 비싼 상품 구하기",
    "section": "",
    "text": "프로그래머스 SQL 문제풀이 연습(Oracle기준, Mysql아님)입니다  (비상업적, 비영리적 용도)\n문제링크 게시가능여부\nCopyright © 2024 Kibok Park All rights reserved."
  },
  {
    "objectID": "posts/prgms-sql-20240318/index.html#개요",
    "href": "posts/prgms-sql-20240318/index.html#개요",
    "title": "[프로그래머스SQL] 가장 비싼 상품 구하기",
    "section": "",
    "text": "프로그래머스 SQL 문제풀이 연습(Oracle기준, Mysql아님)입니다  (비상업적, 비영리적 용도)\n문제링크 게시가능여부"
  },
  {
    "objectID": "posts/prgms-sql-20240318/index.html#문제-가장-비싼-상품-구하기",
    "href": "posts/prgms-sql-20240318/index.html#문제-가장-비싼-상품-구하기",
    "title": "[프로그래머스SQL] 가장 비싼 상품 구하기",
    "section": "문제 : 가장 비싼 상품 구하기",
    "text": "문제 : 가장 비싼 상품 구하기\n\n\n\n문제 이미지"
  },
  {
    "objectID": "posts/prgms-sql-20240318/index.html#작성답안",
    "href": "posts/prgms-sql-20240318/index.html#작성답안",
    "title": "[프로그래머스SQL] 가장 비싼 상품 구하기",
    "section": "작성답안",
    "text": "작성답안\n\n\n\nSELECT MAX(PRICE) AS MAX_PRICE\nFROM PRODUCT\n\n\nFigure 1"
  },
  {
    "objectID": "posts/prgms-sql-20240318/index.html#정리",
    "href": "posts/prgms-sql-20240318/index.html#정리",
    "title": "[프로그래머스SQL] 가장 비싼 상품 구하기",
    "section": "정리",
    "text": "정리\n\nMAX(컬럼명) : 최대값\nMIN(컬럼명) : 최소값"
  }
]