<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kibok Park">
<meta name="dcterms.date" content="2024-08-12">

<title>Blog - [DE스터디/1주차강의] 다양한 데이터처리 플랫폼을 사용한 데이터 수집~모니터링</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/watermark-1.0.11/watermark.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LPL499WQBH"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LPL499WQBH', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index_dashboards.html"> 
<span class="menu-text">Dashboards</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index_miniprojects.html"> 
<span class="menu-text">Mini Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/KR9268"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/%EA%B8%B0%EB%B3%B5-%EB%B0%95-573a68268/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[DE스터디/1주차강의] 다양한 데이터처리 플랫폼을 사용한 데이터 수집~모니터링</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Spark</div>
                <div class="quarto-category">PySpark</div>
                <div class="quarto-category">Docker</div>
                <div class="quarto-category">Docker-compose</div>
                <div class="quarto-category">202408Study_DataEngineering</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Kibok Park </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 12, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#개요" id="toc-개요" class="nav-link active" data-scroll-target="#개요">개요</a></li>
  <li><a href="#주차-수업정리" id="toc-주차-수업정리" class="nav-link" data-scroll-target="#주차-수업정리">1주차 수업정리</a>
  <ul class="collapse">
  <li><a href="#데이터-엔지니어링시-각-단계별로-필요한-주요-플랫폼" id="toc-데이터-엔지니어링시-각-단계별로-필요한-주요-플랫폼" class="nav-link" data-scroll-target="#데이터-엔지니어링시-각-단계별로-필요한-주요-플랫폼">데이터 엔지니어링시 각 단계별로 필요한 주요 플랫폼</a></li>
  <li><a href="#spark-개요" id="toc-spark-개요" class="nav-link" data-scroll-target="#spark-개요">Spark 개요</a></li>
  <li><a href="#spark-environment-설정docker사용" id="toc-spark-environment-설정docker사용" class="nav-link" data-scroll-target="#spark-environment-설정docker사용">Spark Environment 설정(Docker사용)</a></li>
  <li><a href="#submitting-spark-job" id="toc-submitting-spark-job" class="nav-link" data-scroll-target="#submitting-spark-job">Submitting Spark Job</a></li>
  <li><a href="#pyspark" id="toc-pyspark" class="nav-link" data-scroll-target="#pyspark">Pyspark</a></li>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  <li><a href="#spark-materials" id="toc-spark-materials" class="nav-link" data-scroll-target="#spark-materials">Spark Materials</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>데이터 엔지니어링 스터디 내용정리 - Spark, Docker</p>
<section id="개요" class="level1">
<h1>개요</h1>
<ul>
<li>참여중인 데이터 엔지니어링 스터디에서 배우는 내용 정리
<ul>
<li>데이터 수집, 정제 : pyspark, airflow</li>
<li>저장 : elasticsearch</li>
<li>시각화 : kibana</li>
</ul></li>
</ul>
</section>
<section id="주차-수업정리" class="level1">
<h1>1주차 수업정리</h1>
<section id="데이터-엔지니어링시-각-단계별로-필요한-주요-플랫폼" class="level2">
<h2 class="anchored" data-anchor-id="데이터-엔지니어링시-각-단계별로-필요한-주요-플랫폼">데이터 엔지니어링시 각 단계별로 필요한 주요 플랫폼</h2>
<ul>
<li><p>수업에서 사용할 플랫폼은 Bold표기(데이터 분석/정제를 자동으로 수행하는 workflow파이프라인 제작 예정)</p>
<ul>
<li>언어 : SQL, Shell(터미널 사용), Java, Kotlin, Scala, <strong>Python</strong></li>
<li>대용량 데이터 인프라 (HDFS[Hadoop File System])</li>
<li>데이터 수집 (Kafka, Logstash)</li>
<li>데이터 저장/질의 (MySQL, Hive, <strong>ES[Elastic Search, 저장]</strong>, MongoDB)
<ul>
<li>Elastic search는 검색엔진이어서 의아할 수 있으나, ELK스택(로그관리, 저장)할 때 많이 사용. kibana와 연동한 쉬운 시각화 가능</li>
</ul></li>
<li>데이터 처리 (Hadoop MR[MapReduce], <strong>Spark</strong>, Flink(실시간 처리 용도), Spark Stream)</li>
<li>Workflow (<strong>Airflow</strong>, Ooozie)</li>
<li>데이터(모델) 서빙 (GraphQL, REST API, 웹 개발)</li>
<li>데이터 시각화 (분석가가 더 많이해서 비중은 적음. 차트 종류와 특징, <strong>kibana</strong>)</li>
<li>기타: 분석 도구 (Zeppelin), 데이터 설계, 머신러닝, 보안</li>
</ul></li>
<li><p>수업마다 왜 이 플랫폼을 선택했는지를 설명예정 <br></p></li>
<li><p>스터디 방향</p>
<ul>
<li>나의 플랫폼 선택이유를 설명할 수 있어야 함
<ul>
<li>수업마다 왜 이 플랫폼을 선택했는지를 설명예정</li>
</ul></li>
<li>대용량 데이터 처리 파이프라인에 대한 이해(대용량 분산처리를 위한 Spark이해)</li>
<li>데이터에 따라 정제 과정, 데이터 구조 설계
<ul>
<li>Fancy하지 않고 고민 오래하여 만들기</li>
</ul></li>
<li>Spark의 기본구조에 대한 이해 (+이직 등 목표라면 이론도 함께)</li>
<li>Airflow DAG구현</li>
<li>ES, Kibana : 위 항목보단 덜 중요하지만 기본구조는 이해 <br></li>
</ul></li>
<li><p>스터디 준비</p>
<ul>
<li>Terminal(윈도우라면 WSL설치)</li>
<li>Docker(ubuntu 20.04기준), Docker-compose</li>
<li>Resource (메모리 등)</li>
<li>IDE (Visual Studio Code 등) <br></li>
</ul></li>
<li><p>수업목표</p>
<ul>
<li>데이터를 주기적으로 수집하고 pyspark를 사용하여 정제</li>
<li>정제한 데이터를 저장, kibana로 시각화</li>
<li>자동 파이프라인 실행을 위한 Airflow job 생성</li>
<li>수업파일 git주소 : : https://github.com/kmin-z/de-2024.git</li>
</ul></li>
<li><p>수업환경 관련 가이드사항</p>
<ul>
<li>Jupyter 관련 문제 발생시, 이미 8888포트 사용중인지 확인하고, 사용중이라면 변경</li>
</ul></li>
<li><p>[향후 참고용] 문제에 대해 별도로 알아본 내역</p>
<ul>
<li><p>ubuntu 내부에서 git을 설치한 후 clone할 수 있다</p>
<pre class="wsl"><code>  sudo snap install gh   # git 설치
  git clone https://github.com/kmin-z/de-2024.git   # 레포 받기</code></pre></li>
<li><p>docker 실행시 sudo를 계속 사용해야하는 경우 : docker user관련 설정</p>
<ul>
<li>공식문서 링크 : https://docs.docker.com/engine/install/linux-postinstall/<br>
</li>
</ul></li>
<li><p>WSL버전 문제 : 패키지 설치가 안되거나 symbolic link 등 많은 문제가 있었는데 WSL을 오래전에 깔아둔 문제였음 powershell에서 <code>wsl --install</code> 로 재설치하여 해결</p></li>
</ul></li>
</ul>
</section>
<section id="spark-개요" class="level2">
<h2 class="anchored" data-anchor-id="spark-개요">Spark 개요</h2>
<ul>
<li>Data Warehouse vs Data Lake vs Data Lakehouse
<ul>
<li>Data Warehouse → Data Lake → Data Lakehouse로 발전</li>
<li><code>Data Warehous</code>e : (구조가 정해져있는)Structured data를 저장. BI나 Report를 생성</li>
<li><code>Data Lake</code> : (데이터가 다양해지며) Structured와 함께, Semi-structured, Unstructured(이미지나 사운드) Data도 저장
<ul>
<li>Structured data만 정제해서 Data warehouse로 저장(정제된 테이블데이터 생성)</li>
<li>기존처럼 BI, Report를 생성하기도 하고, Data Science를 위해 여러 유형의 데이터를 활용하기도 함. 또는 머신러닝 등도 진행</li>
</ul></li>
<li><code>Data Lakehouse</code> : 데이터를 덤프해두고, 따로 Warehouse 등을 저장해두지 않고, 사용자가 원하는 format으로 뽑아서 사용
<ul>
<li>Metadata, Governance Layer 등으로 데이터를 가져가기 쉬운 장치를 해둠. (과거유형의 정제해두지 않으면 데이터를 사용하기 어려운 것과 달리)</li>
<li>요즘의 트렌드(데이터를 저장해두고 사용하기 쉽게 해둠)
<ul>
<li>과거에는 정제해야하는 사람이 있었다면, 이 방법은 데이터를 붓는 쪽과 사용하는 쪽으로 나뉨 <br></li>
</ul></li>
</ul></li>
</ul></li>
<li><code>Distributed System</code> (Spark이해하기 위해 알아야 하는 개념)
<ul>
<li>간단한 실습이나 데이터 사이언스는 Local에서 가능했겠지만,</li>
<li>필요한 요소
<ul>
<li><strong>Resource management</strong> : 데이터를 적절히 분배하며 저장하는 Resource관리</li>
<li><strong>Scheduling</strong> : 여러 대의 서버가 Job을 어떻게 나누어 돌릴지</li>
</ul></li>
<li><strong>Hadoop</strong>이 위 두가지 요소의 역할을 함 : DFS(Distributed File System)을 구축한 프로젝트임
<ul>
<li>큰 데이터를 어떻게 적절히 나누어 저장할지 등의 결정을 해줌</li>
</ul></li>
<li>기존에는 대용량 데이터 처리를 위해 MapReduce를 많이 사용했는데, <strong>구현과 테스트가 매우 힘듦</strong>(+Hadoop)
<ul>
<li>직접 해보면 MR Job은 잘 죽음</li>
</ul></li>
<li><code>Spark</code> : Hadoop의 한계를 벗어나기 위한 프로젝트 <br></li>
</ul></li>
<li><code>Spark</code> : unified analytics engine for large-scale <strong>data processing</strong>
<ul>
<li>데이터 수집, 저장, 모니터링 등 여러 과정 중 주로 <strong>데이터 처리를 위해 사용</strong></li>
<li>(데이터 처리에 사용하는 만큼)다양한 데이터 포맷, 처리 방법, 저장소 사용가능
<ul>
<li>다양한 high level tool 제공
<ul>
<li>SQL, pandas API, MLlib(간단한 머신러닝)</li>
<li>GraphX(그래프 알고리즘을 분산으로 돌려볼 수 있음)</li>
<li>Structured Streaming(실시간 데이터 처리) <br></li>
</ul></li>
</ul></li>
</ul></li>
<li>Spark History
<ul>
<li>2009년 캘리포니아대 버클리캠퍼스 AMP Lab에서 개발한, MapReduce 단점개선 프로젝트</li>
<li>2013년 Apache 프로젝트에 등재됨</li>
<li>자세히 설명된 위키피디아 내용 : https://en.wikipedia.org/wiki/Apache_Spark <br></li>
</ul></li>
<li><code>Spark Cons</code> (장점, 선정한 이유로서 잘 기억하기)
<ul>
<li>빠른 속도 (Logistics regression기준 Hadoop보다 100배 빠름)
<ul>
<li>메모리에 데이터를 올려서 사용하는 플랫폼이므로, 무조건 디스크를 쓰는 Hadoop보다 빠름</li>
</ul></li>
<li>사용하기 편리함
<ul>
<li>분산처리를 고려한 처리방식때문에 헷갈릴수는 있으나, SQL 등 친숙한 사용법</li>
</ul></li>
<li>다양한 기능 제공(Generality)
<ul>
<li>SQL, Spark Streaming, MLlib 등 다양한 어플리케이션 제공</li>
</ul></li>
<li>다양한 Cluster, File system과 연동가능
<ul>
<li>Cluster마다 관리모듈이 다른데, Yarn, Mesos 등 다양한 Cluster를 붙여쓸 수 있는 플러그인 제공
<ul>
<li>Option에 넣으면 해당 Cluster에 맞는 다양한 처리를 해줌</li>
</ul></li>
<li>File system과 연동가능 : HDFS, Alluxio, Cassandra 등</li>
</ul></li>
<li>일반적인 작고 Local에서 돌리는 작업이라면 오히려 빠른 부분을 잘 못느낄 수 있음
<ul>
<li>분산처리를 위한 추가적인 작업때문에 오히려 늦다고 느낄 수도 있음</li>
<li>다만 대용량데이터를 다룰 때는 체감할 수 있다(다른 플랫폼은 돌아가지조차 않을 수 있음) <br></li>
</ul></li>
</ul></li>
<li>Spark의 구조
<ul>
<li>Driver(1개)와 Worker(n개)로 구성</li>
<li>Cluster manager는 Spark의 요소는 아님
<ul>
<li>Driver와 Worker는 Cluster manager를 통해 소통하며 일을 함</li>
</ul></li>
<li><code>Driver</code>
<ul>
<li>전체 Job을 관장하는 Master의 역할</li>
<li>SparkContext : Spark 전체의 환경(Environment)를 관장
<ul>
<li>항상 Spark Application작성시에는 SparkContext를 먼저 생성하는 코드를 넣음(Driver에 SparkContext가 떴다면 initialization이 끝난 것)
<ul>
<li>이유는 SparkContext가 떠야 Spark가 시작될 수 있음</li>
</ul></li>
</ul></li>
</ul></li>
<li><code>Worker</code>
<ul>
<li>실제로 작업을 하는 역할(Node). Executor(분산되어 할당된 여러 Task를 돌려줌) + Cache</li>
</ul></li>
<li><code>Cluster manager</code>
<ul>
<li>Spark의 역할은 오로지 데이터의 처리인데, Task를 나누고 분배하려면 각각 Node의 상황 등을 파악해야 함</li>
<li>가용성과 Task양 등은 Yarn resource 등의 Cluster manager가 알 수 있으며, Spark는 Resource management를 해주지 않음</li>
<li>Cluster의 종류를 옵션에 적으면, Cluster manager에 맞게 플러그인을 제공.</li>
<li>Cluster가 가용성 등의 정보를 제공해 Driver와 소통하여 Task를 나눌 수 있게한다 <img src="index_files/figure-html/42480dd0-1-image.png" class="img-fluid" alt="image.png"> <br></li>
</ul></li>
</ul></li>
<li>Spark Context
<ul>
<li>처리의 역할만 하고, 데이터를 읽고 Cluster를 관리 등은 플러그인을 제공한 타 기능이 실행</li>
<li>다양한 데이터 Source에 연결한 뒤, 데이터는 Job, Task가 나뉜 것에 따라 분배가 되어야하는데 Spark가 직접하지 않음</li>
<li>Hadoop이 이미 Distributed file system을 잘 구축해두었으므로(데이터 처리가 느리지만), 그대로 가져와서 사용</li>
<li>Spark를 설치해보면, 자동으로 HDFS가 자동으로 함께 설치됨(Dependency가 걸려있음)</li>
<li><strong>데이터 처리용도 외의 데이터를 자르거나 Job을 분배하는 처리는 다른 플랫폼을 활용한다</strong></li>
</ul></li>
</ul>
</section>
<section id="spark-environment-설정docker사용" class="level2">
<h2 class="anchored" data-anchor-id="spark-environment-설정docker사용">Spark Environment 설정(Docker사용)</h2>
<ul>
<li><p>클러스터의 무료 버전은 등록/제약(몇개월이내 데이터량) 등의 문제로 Local(Docker)에서 실습예정 <br></p></li>
<li><p><code>Docker</code></p>
<ul>
<li><p>어떤 환경을 쓰더라도, 다른 OS나 패키지 등의 상황에 대응하기 어려움 (→ 어떤 환경에서든 Application이 돌아갈 수 있도록 도와주는 Docker)</p></li>
<li><p>Virtual Machine이 OS단위 구현인 것과 달리, <strong>하나의 OS에서 Docker엔진이 Software단위로 패키징</strong></p>
<ul>
<li>OS커널은 다른 컨테이너와 공유할 수 있으며, 각 컨테이너는 격리된 프로세스로 실행</li>
</ul></li>
<li><p>수업은 Ubuntu를 활용하여 Docker Engine 설치</p>
<ul>
<li>https://docs.docker.com/engine/install/ubuntu/</li>
<li>Ubuntu설치 : https://ubuntu.com/download/desktop</li>
<li>Ubuntu설치 Tutorial : https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview</li>
</ul></li>
<li><p>Docker를 설치했다는 것은 Docker Engine을 설치했다는 것이고(하단그림 가로), 이제 위의 App(하단그림 세로)을 띄워야 함</p>
<ul>
<li>만들어져있는 App을 사용할 예정(Spark Driver, Spark Executer, Airflow, ES, Kibana, Jupyter 등) <br> <img src="index_files/figure-html/be9497a0-4-image.png" class="img-fluid" alt="image.png"></li>
</ul></li>
<li><p>Docker파일(컨테이너화 하는 파일) : 내가 원하는 소프트웨어를 어떤 환경/버전/라이브러리로 설치할 것을 정의하는 파일</p>
<ul>
<li>하단 그림을 해석하자면, airflow 2.7.1, Python 3.11버전을 사용하고 싶음
<ul>
<li>From에서 제공하는 이미지를 가져와서 (airflow에서 Docker이미지를 제공함[Docker쓰는 경우가 많아서])</li>
<li>root 권한을 사용하여 apt-get을 update 후 python3-dev 등을 설치</li>
<li>JAVA_Home세팅을 내가 설치한 java-11-openjdk-arm64로 해줌</li>
<li>airflow 유저네임으로 바꿔서</li>
<li>airflow에서 사용할 python패키지 (apache-airflow 등) 설치</li>
<li><strong>From의 이미지만을 사용하면 원하는 JDK를 사용하기 어렵고, 파이썬 패키지가 없는 상태임</strong> <img src="index_files/figure-html/be9497a0-1-image-2.png" class="img-fluid" alt="image-2.png"></li>
</ul></li>
<li><strong>Docker파일은 정의된 config파일</strong>로, 이것을 Docker이미지로 build하게 됨(build를 하면 이미지가 나옴)
<ul>
<li>docker build명령어로 config파일을 사용
<ul>
<li>-t : 이름지정</li>
<li>-f로 파일명을 지정하지 않고(-f Dockerfile 등), .을 찍으면 현재 디렉토리기준으로 Docker파일을 만듦</li>
</ul>
<pre><code>  docker build -t airflow-python:20240805 .</code></pre></li>
<li>수업에서는 Docker-Compose를 사용할 예정으로 별도의 build를 진행하지 않음</li>
</ul></li>
</ul></li>
<li><p><strong>Docker이미지</strong> : 컨테이너 App이 올라가기 전, 만들어져있는(올라가기 직전의) 명세</p></li>
<li><p><strong>Docker명령어 사용실습</strong></p>
<pre class="wsl"><code>  docker images  # Docker 이미지를 볼 수 있음</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/be9497a0-2-image-3.png" class="img-fluid figure-img"></p>
<figcaption>image-3.png</figcaption>
</figure>
</div>
<pre class="wsl"><code>  docker container ls  # 올라와있는(up되어있는) Docker container들을 볼 수 있음
                       # docker container까지만 치면 사용가능한 명령어를 보여줌</code></pre>
<p><br></p></li>
</ul></li>
<li><p><code>Docker Compose</code></p>
<ul>
<li>Docker 컨테이너 설정들을 한번에 관리하기 위한 기술 (docker설치시 같이 설치됨)</li>
<li>docker에서 실행(설치)하도록 하는 airflow제공 가이드 : https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html
<ul>
<li>airflow는 여러 기능이 있으므로 컨테이너도 여러개 있음</li>
</ul></li>
<li>spark를 기준으로 이해하자면, Driver를 뜨고 Worker(Node)를 뜨는 등 순서에 따라 진행하고, 모든 Node가 되는지 확인까지 compose로 진행</li>
<li>하단 그림을 기준으로
<ul>
<li>Services에 여러 컨테이너를 띄울 것(spark-master, spark-worker)</li>
<li>spark-worker의 <strong><code>depends_on</code>: spark-master</strong> : spark-master 뜬 다음에 진행하겠다는 의미 <img src="index_files/figure-html/be9497a0-3-image-4.png" class="img-fluid" alt="image-4.png"></li>
</ul></li>
<li>compose를 사용하지 않는다면 <strong>컨테이너별로 명령어를 따로 쳐야하는 불편함. 이를 막을 수 있도록 docker-compose를 사용</strong>
<ul>
<li>docker-compose.yml 파일에 정의해두고 사용</li>
</ul></li>
</ul></li>
<li><p><code>Docker Commands</code></p>
<ul>
<li>기본 커맨드
<ul>
<li>docker-compose up -d (start all the containers)
<ul>
<li>-d : 백그라운드에서 실행(터미널이 끌 수 없는 상태로 실행되는 것을 방지)</li>
</ul></li>
<li>docker-compose down (stop all the containers)
<ul>
<li>참고 : stop되지 않은 컨테이너는 rm이 불가하다</li>
</ul></li>
<li>docker ps (check the containers)
<ul>
<li>start된 컨테이너를 보여줌
<ul>
<li>docker container ls (stop된 컨테이너도 모두 뜸) <br></li>
</ul></li>
</ul></li>
</ul></li>
<li>디버깅이나 오류 상황등에서 사용하는 커맨드
<ul>
<li>docker logs <container name="" or="" id=""> (check container logs)
<ul>
<li>로그를 컨테이너별로 볼 수 있다</li>
</ul></container></li>
<li>docker stop <container name="" or="" id=""> (stop specific docker container)</container></li>
<li>docker rm <container name="" or="" id=""> (remove specific docker container)</container></li>
<li>docker container ls -a (check all the containers including stopped ones)</li>
<li>docker images (docker 이미지 목록) <br></li>
<li>docker run –options <docker-image-name> (run docker image)
<ul>
<li>docker run -it de-2024_scheduler scheduler (<strong>-it 옵션으로, de-2024_scheduler를 실행</strong>)
<ul>
<li>이름을 지정하지 않으면 임의의 이름을 부여 (-name=)</li>
</ul></li>
<li>docker run -it minz95/de2024:jupyter /bin/bash
<ul>
<li>container마다 /bin/bash가 존재함을 단순 참고</li>
</ul></li>
</ul></docker-image-name></li>
<li>docker rmi <docker-image-name> (remove docker image)
<ul>
<li><strong>docker rm 등은 실제 이미지가 지워지는게 아니며</strong>, docker rmi로 삭제</li>
</ul></docker-image-name></li>
<li>docker system prune (remove all the orphans in docker system)
<ul>
<li>cache 등 용량이 모자라면 사용(문제가 된 컨테이너가 계속 실행중인 경우 메모리가 쌓여있을 수 있음)</li>
</ul></li>
<li>docker start <container id="" or="" name="">
<ul>
<li>container 실행</li>
</ul></container></li>
<li>docker exec -it <container id="" or="" name=""> /bin/bash (execute docker container)
<ul>
<li>container에 들어가서 볼 수 있음</li>
<li>exit를 입력하여 종료 가능</li>
</ul></container></li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li><p>Docker에서 Spark-Master를 잘 실행했다면, <code>http://localhost:9090/</code> 를 입력하여 확인 가능</p>
<ul>
<li>하단 yml파일에 ports세팅을 해두었기 때문에 9090으로 접속 가능</li>
</ul></li>
<li><p>docker-compose.yml 파일</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">services</span><span class="kw">:</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">spark-master</span><span class="kw">:</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">&lt;&lt;</span><span class="kw">:</span><span class="at"> </span><span class="ot">*spark-common</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">hostname</span><span class="kw">:</span><span class="at"> spark-master</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">command</span><span class="kw">:</span><span class="at"> bin/spark-class org.apache.spark.deploy.master.Master</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">expose</span><span class="kw">:</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="st">"7077"</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">ports</span><span class="kw">:</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="st">"9090:8080"</span><span class="co"> # UI</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="st">"7077:7077"</span><span class="co"> # Master와 직접연결</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="st">"4444:4040"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p></li>
</ul></li>
<li><p>직접 Spark를 설치한다면 필요한 사항</p>
<ul>
<li>Java 8 이상이 설치된 Linux 서버</li>
<li>Spark 다운로드</li>
<li>Spark 홈페이지 -&gt; Download 페이지</li>
<li>원하는 버젼 선택 후 다운로드</li>
<li>스파크 설치, 압축 해제</li>
<li>각자의 환경에 맞는 config 설정하기</li>
<li>링크 : https://spark.apache.org/docs/latest/configuration.htm</li>
</ul></li>
</ul>
</section>
<section id="submitting-spark-job" class="level2">
<h2 class="anchored" data-anchor-id="submitting-spark-job">Submitting Spark Job</h2>
<ul>
<li>Spark Application
<ul>
<li>Build-in Application : Spark에서 기본 제공</li>
<li>User-Built Application : User가 작성 <br></li>
</ul></li>
<li>Spark Application 작성순서
<ul>
<li><p>SparkContext(SparkSession)생성</p>
<pre><code>    spark = SparkSession.builder.getOrCreate()</code></pre></li>
<li><p>데이터 모델 생성(DataFrame/Dataset, RDD)</p>
<pre><code>    df = spark.read.format("csv").option("header", True).load(csv_file)</code></pre></li>
<li><p>데이터 처리 : Where절 등 사용</p>
<pre><code>    result = df.withColumn('rate', col("rate").cast(DoubleType()))</code></pre></li>
<li><p>결과 파일 처리</p>
<pre><code>    result.show(3, false)</code></pre>
<p><br></p></li>
</ul></li>
<li>Spark Application 실습 (Word-Count)
<ul>
<li><p>과정</p>
<ol type="1">
<li>서버 준비</li>
<li>파일을 나누어 서버에 분산시켜 전송 (HDFS가 진행)</li>
<li>프로그램 빌드 (내가 진행)</li>
<li>빌드한 프로그램을 서버에 전송 (Cluster Manager가 진행)</li>
<li>서버 별로 실행 결과 기록 (Spark가 진행)</li>
<li>모든 결과를 더해서 최종 결과 추출 (Spark가 진행)</li>
</ol></li>
<li><p>코드</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> (</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    SparkSession.builder</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        .appName(<span class="st">"word-count"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        .master(<span class="st">"local"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        .getOrCreate()</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>sc <span class="op">=</span> spark.sparkContext</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Hello Spark Hello Python Hello Docker Hello World"</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> sc.parallelize(text.split(<span class="st">" "</span>))</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>wordCounts <span class="op">=</span> words.<span class="bu">map</span>(<span class="kw">lambda</span> word: (word, <span class="dv">1</span>)).reduceByKey(<span class="kw">lambda</span> a, b: a <span class="op">+</span> b)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> wc <span class="kw">in</span> wordCounts.collect():</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(wc[<span class="dv">0</span>], wc[<span class="dv">1</span>])</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>spark.stop()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p></li>
</ul></li>
<li>RDD(Resilient Distributed Dataset)
<ul>
<li><p>위의 실습코드의 <code>parallelize</code>로 사용한 것이 RDD라는 모델</p></li>
<li><p>분산 데이터 모델</p></li>
<li><p>MapReduce와 비슷한 역할 (MR용도에 최적화된, 그러나 하둡보다는 발전한)</p></li>
<li><p>How를 기술 (데이터를 어떻게 조작할지를 기술)</p>
<pre><code>  rdd.map((_., 1L))
  rdd.reduceByKey(_ + _)</code></pre>
<ul>
<li>참고 : pandas DataFrame은 How가 아닌 What을 기술(어떤 작업을 할지 컬럼별로 기술)
<ul>
<li><strong>RDD는 컬럼이 없는 데이터 모델</strong> <br></li>
</ul></li>
</ul></li>
</ul></li>
<li>Cluster Manager
<ul>
<li>Node 상태를 체크해서 작업을 분배, 죽은 Node를 제외하는 등 기능 필요</li>
</ul></li>
<li>Driver (Spark Context가 뜨는 Node)
<ul>
<li>백그라운드 프로세스와 정보들 관리</li>
<li>Cluster Manager와 관계없이 동작 (Cluster Manager가 보는 상태는 Executor의 상태, Driver를 좌우하지 않음)
<ul>
<li>Cluster Manager와 정보는 공유함</li>
</ul></li>
</ul></li>
<li>Executor
<ul>
<li>(Cluster manager의)Scheduler로부터 task를 할당받아 실행하는 역할 <br></li>
</ul></li>
<li><code>Spark-submit</code>
<ul>
<li>Spark실행때는 파이썬 명령어로 실행할 수 없음 (python test.py 등)
<ul>
<li><p>빌드한 프로그램을 각 서버(띄운 Worker에서 실행하도록) 명령을 보내주어야 함</p></li>
<li><p>이 내용이 Built-in application 중 <code>spark-submit</code>임</p>
<pre><code>  spark-submit --master=&lt;yarn|mesos…&gt; </code></pre></li>
</ul></li>
<li><code>Spark-submit을 하면 전체 Worker node에 job을 분배해줌</code></li>
<li>코드 샘플 (수업은 Local환경임을 참고)
<ul>
<li><p>spark-master : yml파일 참고하여 작성함</p>
<ul>
<li>spark-master : hostname</li>
<li>:7077 : master와 연결할 ports</li>
</ul>
<pre><code>spark://spark-master:7077</code></pre></li>
<li><p>docker-compose.yml</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">services</span><span class="kw">:</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark-master</span><span class="kw">:</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">&lt;&lt;</span><span class="kw">:</span><span class="at"> </span><span class="ot">*spark-common</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">hostname</span><span class="kw">:</span><span class="at"> spark-master</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">command</span><span class="kw">:</span><span class="at"> bin/spark-class org.apache.spark.deploy.master.Master</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">expose</span><span class="kw">:</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="st">"7077"</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">ports</span><span class="kw">:</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="st">"9090:8080"</span><span class="co"> # UI</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="st">"7077:7077"</span><span class="co"> # Master와 직접연결</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="st">"4444:4040"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p></li>
</ul></li>
</ul></li>
<li><code>Spark Context</code>
<ul>
<li>Spark Context를 생성해야 Spark Task를 실행할 수 있음
<ul>
<li>Initialize Environment의 역할</li>
</ul></li>
<li><strong>Spark Context는 매번 생성하므로 공통 함수가 있으면 편리함</strong> <br></li>
</ul></li>
<li><code>Spark Session</code>
<ul>
<li>Spark Session은 Spark Context를 코딩하기 쉽게 래핑해둔 것으로 이해
<ul>
<li>Spark Context가 Spark Session에 들어있다</li>
</ul></li>
<li>Low level 작업(RDD 등)을 할 때는 SparkContext를 사용</li>
<li>SparkContext도 Spark Session을 통해 접근할 수 있음 <br></li>
</ul></li>
<li>Spark Submission Command
<ul>
<li>[예시] 하단 코드를 기준으로
<ul>
<li><code>-it</code> option으로 <code>spark-submit</code>을 실행</li>
<li><code>--master</code> option으로 spark-master의, 7077로 지정</li>
<li><code>&lt;python-app-path&gt;</code>안에 파이썬 파일명</li>
<li>파이썬 파일이 파라미터를 받는다면 <code>&lt;data-path&gt;</code>을 지정</li>
</ul>
<pre><code>docker exec -it de-2024-spark-master-1 spark-submit --master spark://spark-master:7077 &lt;python-app-path&gt; &lt;data-path&gt;</code></pre></li>
<li>[방법1] docker에서 실행 (실습환경 기준)
<ul>
<li>jobs에 대한 매핑이 이미 되어있기에 가능함을 참고 (yml파일의 x-spark-common의 volumns 부분)</li>
<li>아래 파이썬 파일(word-count.py)은 파라미터를 받지 않음</li>
</ul>
<pre><code>docker exec -it de-2024-spark-master-1 spark-submit --master spark://spark-master:7077 jobs/word-count.py</code></pre></li>
<li>[방법2] 컨테이너에 들어간 후 실행 (실습환경 기준)
<ul>
<li>아래 파이썬 파일(hello-world.py)은 파라미터를 받음</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 해당 컨테이너에 들어감</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="at">docker exec -it de-2024-spark-master-1 /bin/bash</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 파일이 있는 폴더로 들어감</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="at">cd jobs</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 해당 폴더에서 직접 실행 </span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="at">spark-submit --master spark://spark-master:7077 hello-world.py ..data/movies.csv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
</ul>
</section>
<section id="pyspark" class="level2">
<h2 class="anchored" data-anchor-id="pyspark">Pyspark</h2>
<ul>
<li>Pyspark는 Main은 아님
<ul>
<li>Spark는 Scala로 구현되어있어, 신기능은 Scala로 먼저 개발됨</li>
<li>Python으로 포팅되기까지 시간이 걸림</li>
</ul></li>
<li>Scala가 필수는 아님
<ul>
<li>Scala는 함수형 프로그래밍에 대한 부담이 큼</li>
<li>Spark 자체가 다양한 언어를 지원하여, 간단한 처리로는 어떤 언어도 가능</li>
</ul></li>
<li>단 아래의 경우는 Scala가 필요함
<ul>
<li>최신 Spark API가 필요하거나 Customizing이 필요한 경우</li>
<li>성능최적화나 오픈소스 등을 기여하고자 할 때</li>
<li>Spark 내부구조를 분석해서 디버깅해야할 Case가 있을 때</li>
</ul></li>
</ul>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<ul>
<li><p>[참고]실습 데이터 폴더구조</p>
<ul>
<li>dags : airflow에서 사용</li>
<li>data : 데이터를 넣고 사용</li>
<li>es-data : elastic search에서 사용</li>
<li>jobs : 주로 사용할 메인코드, spark 코드 사용</li>
<li>logs : airflow 로그용 디렉토리</li>
<li>notebooks : jupyernotebook 파일</li>
<li>resources : elasticsearch jar파일</li>
</ul></li>
<li><p>과제 데이터셋 고민</p>
<ul>
<li>Yahoo Finance API</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> yfinance <span class="im">as</span> yf </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  msft <span class="op">=</span> yf.Ticker(<span class="st">"MSFT"</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  msft.info</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get historical market data </span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  hist <span class="op">=</span> msft.history(period<span class="op">=</span><span class="st">"1mo"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># show meta information about the history (requires history() to be called first) </span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  msft.history_metadata</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>데이터의 Schema 확인하는 샘플코드</p>
<pre><code>df = spark.read.csv('')
df.printSchema()</code></pre></li>
</ul>
</section>
<section id="spark-materials" class="level2">
<h2 class="anchored" data-anchor-id="spark-materials">Spark Materials</h2>
<ul>
<li>https://spark.apache.org/docs/latest/</li>
<li>https://databricks.com/blog/category/engineering/spark</li>
<li>spark 를 이루는 기반 기술에 대한 공부 (java I/O, python, Hadoop)</li>
</ul>


</section>
</section>

<p><br><strong>Copyright © 2024 Kibok Park All rights reserved.</strong><br></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kr9268\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="kr9268/giscus_for_blog" data-repo-id="R_kgDOL0Sthw" data-category="General" data-category-id="DIC_kwDOL0Sth84Ce_5h" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<script>
    const baseFontSize = parseFloat(getComputedStyle(document.documentElement).fontSize);
    const watermark = new XWatermark.XWatermark();
    watermark.init("Kibok Park", {
      parentSelector: "body",
      prevent: true,
      observer: true,
      mode: "normal",
      font: "system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', 'Noto Sans', 'Liberation Sans', Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'",
      fontsize: baseFontSize * 1.000000,
      angle: -15.000000,
      color: "#000000",
      alpha: 0.100000,
      cols: 10,
      rows: 50,
      xSpace: baseFontSize * 4.000000,
      ySpace: baseFontSize * 4.000000,
      zIndex: -1
    });
    </script>




</body></html>