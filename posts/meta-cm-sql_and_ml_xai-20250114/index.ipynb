{
  "cells": [
    {
      "cell_type": "raw",
      "id": "de6ec63f",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: '[DA스터디/4주차/과제] 불균형데이터 처리(오버샘플링, 가중치 조절 등)'\n",
        "author: 'Kibok Park'\n",
        "date: '2025-01-14'\n",
        "categories: [Python, Under-sampling, Over-sampling, Hybrid-sampling, Model selection, 202412Study_DataAnalysis]\n",
        "execute:\n",
        "  freeze: auto\n",
        "toc: true\n",
        "draft: false\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "comments:\n",
        "  giscus:\n",
        "    repo: kr9268/giscus_for_blog\n",
        "---\n",
        "금융권 데이터를 활용한 분석 스터디 - 4주차"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e861fae",
      "metadata": {},
      "source": [
        "# 개요\n",
        "\n",
        "* 아래의 목적/이유로 참가한 스터디에 대한 기록\n",
        "  * SQLD취득 후 장기 미사용 & GPT를 통한 SQL사용 등으로 많이 잊은 SQL을 복기\n",
        "  * 기존에 사용해 본 Optuna가 아닌 Autogluon이 커리큘럼에 있어 익혀보고자 함\n",
        "  * 기존에 관심있던 XAI(설명가능한 AI)를 익히고자 함\n",
        "\n",
        "* 4주차 과제 진행\n",
        "  * 지정과제에 대한 EDA, 전처리, 데이터마트(CSV파일)만들기\n",
        "    * 데이터마트는 sqlite3으로 DB형태로 만듦 \n",
        "  * 변수에 대한 설명 확인\n",
        "  * 수치/명목형 변수로 나누어 EDA 및 전처리 진행\n",
        "  * 향후 Test데이터 등에도 사용하기 위해 전처리 함수로 정리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af81464b",
      "metadata": {},
      "source": [
        "# 4주차 과제 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2108302e",
      "metadata": {},
      "source": [
        "## 과제 설명\n",
        "\n",
        "* 과제 : 월간 데이콘 신용카드 사용자 연체 예측 AI 경진대회\n",
        "  * https://dacon.io/competitions/official/235713/overview/description\n",
        "* 아래 내용 진행해보기\n",
        "  * 불균형데이터에 대해 다양한 불균형처리기법 사용해보기\n",
        "  * 최종 모델 결정해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc6922b",
      "metadata": {},
      "source": [
        "## 전처리 해둔 데이터 읽고 데이터셋 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520312cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pkb_sqlite3 import DB_sqlite3\n",
        "\n",
        "db_controller = DB_sqlite3('Dacon_creditcard_overdue.db')\n",
        "df_train = db_controller.search_db_show_df('SELECT * FROM train')\n",
        "df_train_pre = db_controller.search_db_show_df('SELECT * FROM train_pre')\n",
        "df_test = db_controller.search_db_show_df('SELECT * FROM test_pre')\n",
        "df_sample_submission = db_controller.search_db_show_df('SELECT * FROM sample_submission')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647a7171",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.concat([df_train_pre, df_train['credit']], axis=1)\n",
        "x_test = df_test.copy()\n",
        "\n",
        "x_train, x_validate = train_test_split(train, test_size=0.3, random_state=42, stratify=train['credit'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "794440d0",
      "metadata": {},
      "source": [
        "## 불균형데이터 처리실습\n",
        "\n",
        "### Undersampling - RUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31af497",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# RandomUnderSampler 적용\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_rus, y_rus = rus.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b9fbc7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (6765, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_rus.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156ce3bc",
      "metadata": {},
      "source": [
        "### Undersampling - ENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2249b869",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "\n",
        "# ENN 적용\n",
        "enn = EditedNearestNeighbours()\n",
        "X_enn, y_enn = enn.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfaf4f75",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (5712, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_enn.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f805a0a",
      "metadata": {},
      "source": [
        "### Undersampling - Tomek Links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807af710",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# Tomek Links 적용\n",
        "tomek = TomekLinks()\n",
        "X_tomek, y_tomek = tomek.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011f13a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (14117, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_tomek.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56596906",
      "metadata": {},
      "source": [
        "### Oversampling - ROS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac4fb33",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Random Oversampling 적용\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_ros, y_ros = ros.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f1863c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (35631, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_ros.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23512257",
      "metadata": {},
      "source": [
        "### Oversampling - SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55f9a2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SMOTE Oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab72240",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (35631, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_smote.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bac2622",
      "metadata": {},
      "source": [
        "### Oversampling - ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4152e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "# ADASYN Oversampling\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_adasyn, y_adasyn = adasyn.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6833a079",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (35665, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_adasyn.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79fc6da9",
      "metadata": {},
      "source": [
        "### Hybrid Method - SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac9045b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "# SMOTEENN Oversampling\n",
        "smoteenn = SMOTEENN(random_state=42)\n",
        "X_smoteenn, y_smoteenn = smoteenn.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ed70c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (10892, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_smoteenn.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1a0ee2",
      "metadata": {},
      "source": [
        "### Hybrid Method - SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05814cc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# SMOTETomek Oversampling\n",
        "smotetomek = SMOTETomek(random_state=42)\n",
        "X_smotetomek, y_smotetomek = smotetomek.fit_resample(x_train.drop(columns=['credit']), x_train['credit'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0fe52d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 적용 전 (18519, 35)\n",
            "* 적용 후 (31997, 35)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"* 적용 전 {x_train.drop(columns=['credit']).shape}\n",
        "* 적용 후 {X_smotetomek.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e792b4a6",
      "metadata": {},
      "source": [
        "## LightGBM활용한 불균형처리별 성능비교\n",
        "\n",
        "* 수업 중 가장 빠른 모델이었던 LightGBM을 활용해서 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a402e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
        "\n",
        "def compute_for_samplers(train, test, sampler, return_metric_only= False):\n",
        "  \n",
        "  X_sampled, y_sampled = sampler.fit_resample(train.drop(['credit'], axis = 1), train[\"credit\"])\n",
        "  model = LGBMClassifier(random_state = 42)\n",
        "  model.fit(X_sampled, y_sampled)\n",
        "  y_pred = model.predict(test.drop(['credit'], axis = 1))\n",
        "  y_proba = model.predict_proba(test.drop(['credit'], axis = 1))\n",
        "  y_test = test['credit']\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  logloss = log_loss(y_test, y_proba)\n",
        "  cf = confusion_matrix(y_test, y_pred)\n",
        "  if return_metric_only:\n",
        "    return accuracy, cf, auc\n",
        "  else:\n",
        "    return {'acc':accuracy,\n",
        "            'logloss':logloss,\n",
        "            'cf':cf,\n",
        "            'X_sampled' : X_sampled,\n",
        "            'y_sampled' : y_sampled,\n",
        "            'model' : model,\n",
        "            'y_pred' : y_pred,\n",
        "            'y_proba' : y_proba}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f148b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "\n",
        "sampler = {'RUS':RandomUnderSampler(random_state=42),\n",
        "            'ENN':EditedNearestNeighbours(),\n",
        "            'TOMEKLINKS':TomekLinks(),\n",
        "            'ROS':RandomOverSampler(random_state=42),\n",
        "            'SMOTE':SMOTE(random_state=42),\n",
        "            'ADASYN':ADASYN(random_state=42),\n",
        "            'SMOTEENN':SMOTEENN(random_state=42),\n",
        "            'SMOTETomek':SMOTETomek(random_state=42)}\n",
        "sampler_result = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279b6d4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RUS\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1262\n",
            "[LightGBM] [Info] Number of data points in the train set: 6765, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "\n",
            "ENN\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 5712, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -0.929419\n",
            "[LightGBM] [Info] Start training from score -4.607273\n",
            "[LightGBM] [Info] Start training from score -0.518794\n",
            "\n",
            "TOMEKLINKS\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 14117, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.834230\n",
            "[LightGBM] [Info] Start training from score -1.759900\n",
            "[LightGBM] [Info] Start training from score -0.403166\n",
            "\n",
            "ROS\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1340\n",
            "[LightGBM] [Info] Number of data points in the train set: 35631, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "\n",
            "SMOTE\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7329\n",
            "[LightGBM] [Info] Number of data points in the train set: 35631, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "\n",
            "ADASYN\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7336\n",
            "[LightGBM] [Info] Number of data points in the train set: 35665, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.073800\n",
            "[LightGBM] [Info] Start training from score -1.123079\n",
            "[LightGBM] [Info] Start training from score -1.099566\n",
            "\n",
            "SMOTEENN\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6992\n",
            "[LightGBM] [Info] Number of data points in the train set: 10892, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -0.680013\n",
            "[LightGBM] [Info] Start training from score -0.892431\n",
            "[LightGBM] [Info] Start training from score -2.480144\n",
            "\n",
            "SMOTETomek\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 7273\n",
            "[LightGBM] [Info] Number of data points in the train set: 31997, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.086003\n",
            "[LightGBM] [Info] Start training from score -1.080280\n",
            "[LightGBM] [Info] Start training from score -1.130299\n"
          ]
        }
      ],
      "source": [
        "for each_sampler in sampler:\n",
        "    print(f'\\n{each_sampler}')\n",
        "    sampler_result[each_sampler] = compute_for_samplers(x_train, \n",
        "                                                        x_validate, \n",
        "                                                        sampler[each_sampler]\n",
        "                                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "943a24d9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>logloss</th>\n",
              "      <th>cf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ADASYN</th>\n",
              "      <td>0.692618</td>\n",
              "      <td>0.789301</td>\n",
              "      <td>[[12, 139, 816], [7, 456, 1417], [7, 54, 5030]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTE</th>\n",
              "      <td>0.69287</td>\n",
              "      <td>0.793357</td>\n",
              "      <td>[[5, 137, 825], [3, 455, 1422], [4, 47, 5040]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTETomek</th>\n",
              "      <td>0.691358</td>\n",
              "      <td>0.797204</td>\n",
              "      <td>[[10, 141, 816], [13, 449, 1418], [4, 58, 5029]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOMEKLINKS</th>\n",
              "      <td>0.692996</td>\n",
              "      <td>0.808826</td>\n",
              "      <td>[[36, 119, 812], [24, 405, 1451], [14, 17, 5060]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROS</th>\n",
              "      <td>0.612875</td>\n",
              "      <td>0.930659</td>\n",
              "      <td>[[281, 202, 484], [190, 780, 910], [737, 550, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RUS</th>\n",
              "      <td>0.504661</td>\n",
              "      <td>1.011385</td>\n",
              "      <td>[[378, 255, 334], [412, 834, 634], [1293, 1004...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTEENN</th>\n",
              "      <td>0.325397</td>\n",
              "      <td>1.237064</td>\n",
              "      <td>[[387, 426, 154], [558, 1002, 320], [1889, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENN</th>\n",
              "      <td>0.589317</td>\n",
              "      <td>2.293334</td>\n",
              "      <td>[[357, 0, 610], [633, 2, 1245], [772, 0, 4319]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 acc   logloss  \\\n",
              "ADASYN      0.692618  0.789301   \n",
              "SMOTE        0.69287  0.793357   \n",
              "SMOTETomek  0.691358  0.797204   \n",
              "TOMEKLINKS  0.692996  0.808826   \n",
              "ROS         0.612875  0.930659   \n",
              "RUS         0.504661  1.011385   \n",
              "SMOTEENN    0.325397  1.237064   \n",
              "ENN         0.589317  2.293334   \n",
              "\n",
              "                                                           cf  \n",
              "ADASYN        [[12, 139, 816], [7, 456, 1417], [7, 54, 5030]]  \n",
              "SMOTE          [[5, 137, 825], [3, 455, 1422], [4, 47, 5040]]  \n",
              "SMOTETomek   [[10, 141, 816], [13, 449, 1418], [4, 58, 5029]]  \n",
              "TOMEKLINKS  [[36, 119, 812], [24, 405, 1451], [14, 17, 5060]]  \n",
              "ROS         [[281, 202, 484], [190, 780, 910], [737, 550, ...  \n",
              "RUS         [[378, 255, 334], [412, 834, 634], [1293, 1004...  \n",
              "SMOTEENN    [[387, 426, 154], [558, 1002, 320], [1889, 200...  \n",
              "ENN           [[357, 0, 610], [633, 2, 1245], [772, 0, 4319]]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame(sampler_result)\n",
        "df.loc[['acc','logloss','cf']].transpose().sort_values('logloss')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a7f35f",
      "metadata": {},
      "source": [
        "* Under/Over/Hybrid Sampling별로 1가지씩 해보는 것으로 결정\n",
        "  * TOMEKLINKS\n",
        "  * ADASYN\n",
        "  * SMOTETomek"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826d2bb6",
      "metadata": {},
      "source": [
        "## 모델 성능비교 및 선택\n",
        "\n",
        "* 전처리한 기본 데이터를 기준으로 모델 비교 해보기(Weight 미적용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d8218c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest + TOMEKLINKS\n",
            "* logloss : 0.7620037176688708\n",
            "\n",
            "LightGBM + TOMEKLINKS\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 14117, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.834230\n",
            "[LightGBM] [Info] Start training from score -1.759900\n",
            "[LightGBM] [Info] Start training from score -0.403166\n",
            "* logloss : 0.7692630280717329\n",
            "\n",
            "XGBoost + TOMEKLINKS\n",
            "* logloss : 0.7849133307714561\n",
            "\n",
            "CatBoost + TOMEKLINKS\n",
            "* logloss : 0.7740753039975535\n",
            "\n",
            "Extra Trees + TOMEKLINKS\n",
            "* logloss : 0.8551848758758333\n",
            "\n",
            "Random Forest + ADASYN\n",
            "* logloss : 0.7478335144023597\n",
            "\n",
            "LightGBM + ADASYN\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7336\n",
            "[LightGBM] [Info] Number of data points in the train set: 35665, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.073800\n",
            "[LightGBM] [Info] Start training from score -1.123079\n",
            "[LightGBM] [Info] Start training from score -1.099566\n",
            "* logloss : 0.747220175202705\n",
            "\n",
            "XGBoost + ADASYN\n",
            "* logloss : 0.7657405243628196\n",
            "\n",
            "CatBoost + ADASYN\n",
            "* logloss : 0.7674443572640199\n",
            "\n",
            "Extra Trees + ADASYN\n",
            "* logloss : 0.8141975026995196\n",
            "\n",
            "Random Forest + SMOTETomek\n",
            "* logloss : 0.7699790781735832\n",
            "\n",
            "LightGBM + SMOTETomek\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7273\n",
            "[LightGBM] [Info] Number of data points in the train set: 31997, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.086003\n",
            "[LightGBM] [Info] Start training from score -1.080280\n",
            "[LightGBM] [Info] Start training from score -1.130299\n",
            "* logloss : 0.7650168946174349\n",
            "\n",
            "XGBoost + SMOTETomek\n",
            "* logloss : 0.7927170149729137\n",
            "\n",
            "CatBoost + SMOTETomek\n",
            "* logloss : 0.7819625428548069\n",
            "\n",
            "Extra Trees + SMOTETomek\n",
            "* logloss : 0.8334713382827283\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "rsts = {}\n",
        "\n",
        "sampler = {'TOMEKLINKS':TomekLinks(),\n",
        "           'ADASYN':ADASYN(random_state=42),\n",
        "           'SMOTETomek':SMOTETomek(random_state=42)}\n",
        "\n",
        "for each_sample_type in sampler:\n",
        "    X_train, y_train = sampler[each_sample_type].fit_resample(x_train.drop(['credit'], axis = 1), x_train[\"credit\"])\n",
        "    X_test, y_test = sampler[each_sample_type].fit_resample(x_validate.drop(['credit'], axis = 1), x_validate[\"credit\"])\n",
        "\n",
        "    # 학습 및 평가\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n{name} + {each_sample_type}\")\n",
        "        start = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        logloss = log_loss(y_test, y_proba)\n",
        "        cf = confusion_matrix(y_test, y_pred)\n",
        "        rsts[f\"{name} + {each_sample_type}\"] = {'acc':accuracy,\n",
        "                    'logloss':logloss,\n",
        "                    'cf':cf,\n",
        "                    'model' : model,\n",
        "                    'y_pred' : y_pred,\n",
        "                    'y_proba' : y_proba,\n",
        "                    'time' : time.time() - start,\n",
        "                    'classification_report':classification_report(y_test, y_pred)}\n",
        "        \n",
        "        print(f\"\"\"* logloss : {logloss}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de056773",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>logloss</th>\n",
              "      <th>cf</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>\\nLightGBM + ADASYN</th>\n",
              "      <td>0.637518</td>\n",
              "      <td>0.74722</td>\n",
              "      <td>[[3159, 1178, 872], [1976, 1551, 1451], [7, 54...</td>\n",
              "      <td>0.650462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nRandom Forest + ADASYN</th>\n",
              "      <td>0.64354</td>\n",
              "      <td>0.747834</td>\n",
              "      <td>[[3166, 1339, 704], [1861, 1966, 1151], [126, ...</td>\n",
              "      <td>9.090805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nRandom Forest + TOMEKLINKS</th>\n",
              "      <td>0.717713</td>\n",
              "      <td>0.762004</td>\n",
              "      <td>[[138, 120, 709], [29, 278, 662], [79, 60, 3802]]</td>\n",
              "      <td>2.631492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nLightGBM + SMOTETomek</th>\n",
              "      <td>0.623706</td>\n",
              "      <td>0.765017</td>\n",
              "      <td>[[2341, 1148, 754], [1543, 1491, 1199], [4, 41...</td>\n",
              "      <td>0.58901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nXGBoost + ADASYN</th>\n",
              "      <td>0.630384</td>\n",
              "      <td>0.765741</td>\n",
              "      <td>[[2817, 1532, 860], [1738, 1868, 1372], [21, 1...</td>\n",
              "      <td>0.861137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nCatBoost + ADASYN</th>\n",
              "      <td>0.635293</td>\n",
              "      <td>0.767444</td>\n",
              "      <td>[[2834, 1522, 853], [1671, 1919, 1388], [18, 1...</td>\n",
              "      <td>17.005267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nLightGBM + TOMEKLINKS</th>\n",
              "      <td>0.711247</td>\n",
              "      <td>0.769263</td>\n",
              "      <td>[[36, 119, 812], [18, 228, 723], [11, 14, 3916]]</td>\n",
              "      <td>0.349786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nRandom Forest + SMOTETomek</th>\n",
              "      <td>0.629805</td>\n",
              "      <td>0.769979</td>\n",
              "      <td>[[2352, 1274, 617], [1454, 1832, 947], [98, 22...</td>\n",
              "      <td>7.562343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nCatBoost + TOMEKLINKS</th>\n",
              "      <td>0.709035</td>\n",
              "      <td>0.774075</td>\n",
              "      <td>[[57, 116, 794], [34, 232, 703], [23, 40, 3878]]</td>\n",
              "      <td>6.656712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nCatBoost + SMOTETomek</th>\n",
              "      <td>0.622261</td>\n",
              "      <td>0.781963</td>\n",
              "      <td>[[2110, 1413, 720], [1313, 1784, 1136], [20, 1...</td>\n",
              "      <td>15.503353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nXGBoost + TOMEKLINKS</th>\n",
              "      <td>0.708014</td>\n",
              "      <td>0.784913</td>\n",
              "      <td>[[84, 118, 765], [43, 232, 694], [46, 50, 3845]]</td>\n",
              "      <td>0.490033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nXGBoost + SMOTETomek</th>\n",
              "      <td>0.611508</td>\n",
              "      <td>0.792717</td>\n",
              "      <td>[[2037, 1496, 710], [1360, 1726, 1147], [31, 9...</td>\n",
              "      <td>1.109563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nExtra Trees + ADASYN</th>\n",
              "      <td>0.623511</td>\n",
              "      <td>0.814198</td>\n",
              "      <td>[[3054, 1437, 718], [1802, 2039, 1137], [197, ...</td>\n",
              "      <td>5.692895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nExtra Trees + SMOTETomek</th>\n",
              "      <td>0.618891</td>\n",
              "      <td>0.833471</td>\n",
              "      <td>[[2352, 1304, 587], [1388, 1887, 958], [152, 3...</td>\n",
              "      <td>5.461775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\nExtra Trees + TOMEKLINKS</th>\n",
              "      <td>0.691339</td>\n",
              "      <td>0.855185</td>\n",
              "      <td>[[225, 105, 637], [65, 244, 660], [167, 180, 3...</td>\n",
              "      <td>2.29099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   acc   logloss  \\\n",
              "\\nLightGBM + ADASYN           0.637518   0.74722   \n",
              "\\nRandom Forest + ADASYN       0.64354  0.747834   \n",
              "\\nRandom Forest + TOMEKLINKS  0.717713  0.762004   \n",
              "\\nLightGBM + SMOTETomek       0.623706  0.765017   \n",
              "\\nXGBoost + ADASYN            0.630384  0.765741   \n",
              "\\nCatBoost + ADASYN           0.635293  0.767444   \n",
              "\\nLightGBM + TOMEKLINKS       0.711247  0.769263   \n",
              "\\nRandom Forest + SMOTETomek  0.629805  0.769979   \n",
              "\\nCatBoost + TOMEKLINKS       0.709035  0.774075   \n",
              "\\nCatBoost + SMOTETomek       0.622261  0.781963   \n",
              "\\nXGBoost + TOMEKLINKS        0.708014  0.784913   \n",
              "\\nXGBoost + SMOTETomek        0.611508  0.792717   \n",
              "\\nExtra Trees + ADASYN        0.623511  0.814198   \n",
              "\\nExtra Trees + SMOTETomek    0.618891  0.833471   \n",
              "\\nExtra Trees + TOMEKLINKS    0.691339  0.855185   \n",
              "\n",
              "                                                                             cf  \\\n",
              "\\nLightGBM + ADASYN           [[3159, 1178, 872], [1976, 1551, 1451], [7, 54...   \n",
              "\\nRandom Forest + ADASYN      [[3166, 1339, 704], [1861, 1966, 1151], [126, ...   \n",
              "\\nRandom Forest + TOMEKLINKS  [[138, 120, 709], [29, 278, 662], [79, 60, 3802]]   \n",
              "\\nLightGBM + SMOTETomek       [[2341, 1148, 754], [1543, 1491, 1199], [4, 41...   \n",
              "\\nXGBoost + ADASYN            [[2817, 1532, 860], [1738, 1868, 1372], [21, 1...   \n",
              "\\nCatBoost + ADASYN           [[2834, 1522, 853], [1671, 1919, 1388], [18, 1...   \n",
              "\\nLightGBM + TOMEKLINKS        [[36, 119, 812], [18, 228, 723], [11, 14, 3916]]   \n",
              "\\nRandom Forest + SMOTETomek  [[2352, 1274, 617], [1454, 1832, 947], [98, 22...   \n",
              "\\nCatBoost + TOMEKLINKS        [[57, 116, 794], [34, 232, 703], [23, 40, 3878]]   \n",
              "\\nCatBoost + SMOTETomek       [[2110, 1413, 720], [1313, 1784, 1136], [20, 1...   \n",
              "\\nXGBoost + TOMEKLINKS         [[84, 118, 765], [43, 232, 694], [46, 50, 3845]]   \n",
              "\\nXGBoost + SMOTETomek        [[2037, 1496, 710], [1360, 1726, 1147], [31, 9...   \n",
              "\\nExtra Trees + ADASYN        [[3054, 1437, 718], [1802, 2039, 1137], [197, ...   \n",
              "\\nExtra Trees + SMOTETomek    [[2352, 1304, 587], [1388, 1887, 958], [152, 3...   \n",
              "\\nExtra Trees + TOMEKLINKS    [[225, 105, 637], [65, 244, 660], [167, 180, 3...   \n",
              "\n",
              "                                   time  \n",
              "\\nLightGBM + ADASYN            0.650462  \n",
              "\\nRandom Forest + ADASYN       9.090805  \n",
              "\\nRandom Forest + TOMEKLINKS   2.631492  \n",
              "\\nLightGBM + SMOTETomek         0.58901  \n",
              "\\nXGBoost + ADASYN             0.861137  \n",
              "\\nCatBoost + ADASYN           17.005267  \n",
              "\\nLightGBM + TOMEKLINKS        0.349786  \n",
              "\\nRandom Forest + SMOTETomek   7.562343  \n",
              "\\nCatBoost + TOMEKLINKS        6.656712  \n",
              "\\nCatBoost + SMOTETomek       15.503353  \n",
              "\\nXGBoost + TOMEKLINKS         0.490033  \n",
              "\\nXGBoost + SMOTETomek         1.109563  \n",
              "\\nExtra Trees + ADASYN         5.692895  \n",
              "\\nExtra Trees + SMOTETomek     5.461775  \n",
              "\\nExtra Trees + TOMEKLINKS      2.29099  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_results = pd.DataFrame(rsts).loc[['acc','logloss','cf','time'],:]\n",
        "df_results.transpose().sort_values('logloss')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d2b365",
      "metadata": {},
      "source": [
        "* logloss와 time을 기준으로 아래 2가지 조합 선정\n",
        "  * LightGBM + ADASYN\n",
        "  * Random Forest + TOMEKLINKS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919c5334",
      "metadata": {},
      "source": [
        "## 불균형 처리 + 모델선택 Case별 비교\n",
        "\n",
        "### 앞서 테스트를 통해 구한 조합에 대해 테스트\n",
        "\n",
        "* 아래 조합으로 테스트\n",
        "  * LightGBM (Weighted)\n",
        "  * LightGBM + ADASYN\n",
        "  * Random Forest (Weighted)\n",
        "  * Random Forest + TOMEKLINKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268aa11b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest + TOMEKLINKS\n",
            "\n",
            "LightGBM + TOMEKLINKS\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1303\n",
            "[LightGBM] [Info] Number of data points in the train set: 14117, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "\n",
            "Random Forest + ADASYN\n",
            "\n",
            "LightGBM + ADASYN\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7336\n",
            "[LightGBM] [Info] Number of data points in the train set: 35665, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(class_weight=\"balanced\", random_state=42),\n",
        "}\n",
        "\n",
        "rsts_weight = {}\n",
        "\n",
        "sampler = {'TOMEKLINKS':TomekLinks(),\n",
        "           'ADASYN':ADASYN(random_state=42)\n",
        "           }\n",
        "\n",
        "for each_sample_type in sampler:\n",
        "    X_train, y_train = sampler[each_sample_type].fit_resample(x_train.drop(['credit'], axis = 1), x_train[\"credit\"])\n",
        "    X_test, y_test = sampler[each_sample_type].fit_resample(x_validate.drop(['credit'], axis = 1), x_validate[\"credit\"])\n",
        "\n",
        "    # 학습 및 평가\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n{name} + {each_sample_type}\")\n",
        "        start = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        logloss = log_loss(y_test, y_proba)\n",
        "        cf = confusion_matrix(y_test, y_pred)\n",
        "        rsts_weight[f\"{name} + {each_sample_type}\"] = {'acc':accuracy,\n",
        "                    'logloss':logloss,\n",
        "                    'cf':cf,\n",
        "                    'model' : model,\n",
        "                    'y_pred' : y_pred,\n",
        "                    'y_proba' : y_proba,\n",
        "                    'time' : time.time() - start,\n",
        "                    'classification_report':classification_report(y_test, y_pred)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e539840",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>logloss</th>\n",
              "      <th>cf</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LightGBM + ADASYN</th>\n",
              "      <td>0.633198</td>\n",
              "      <td>0.750138</td>\n",
              "      <td>[[3019, 1317, 873], [1902, 1624, 1452], [6, 54...</td>\n",
              "      <td>1.112855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest + TOMEKLINKS</th>\n",
              "      <td>0.717543</td>\n",
              "      <td>0.751406</td>\n",
              "      <td>[[134, 110, 723], [31, 260, 678], [68, 50, 3823]]</td>\n",
              "      <td>2.637113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest + ADASYN</th>\n",
              "      <td>0.6421</td>\n",
              "      <td>0.757042</td>\n",
              "      <td>[[3172, 1311, 726], [1891, 1940, 1147], [127, ...</td>\n",
              "      <td>9.652027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM + TOMEKLINKS</th>\n",
              "      <td>0.602008</td>\n",
              "      <td>0.92511</td>\n",
              "      <td>[[305, 189, 473], [122, 377, 470], [658, 427, ...</td>\n",
              "      <td>0.504209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 acc   logloss  \\\n",
              "LightGBM + ADASYN           0.633198  0.750138   \n",
              "Random Forest + TOMEKLINKS  0.717543  0.751406   \n",
              "Random Forest + ADASYN        0.6421  0.757042   \n",
              "LightGBM + TOMEKLINKS       0.602008   0.92511   \n",
              "\n",
              "                                                                           cf  \\\n",
              "LightGBM + ADASYN           [[3019, 1317, 873], [1902, 1624, 1452], [6, 54...   \n",
              "Random Forest + TOMEKLINKS  [[134, 110, 723], [31, 260, 678], [68, 50, 3823]]   \n",
              "Random Forest + ADASYN      [[3172, 1311, 726], [1891, 1940, 1147], [127, ...   \n",
              "LightGBM + TOMEKLINKS       [[305, 189, 473], [122, 377, 470], [658, 427, ...   \n",
              "\n",
              "                                time  \n",
              "LightGBM + ADASYN           1.112855  \n",
              "Random Forest + TOMEKLINKS  2.637113  \n",
              "Random Forest + ADASYN      9.652027  \n",
              "LightGBM + TOMEKLINKS       0.504209  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_results_weight = pd.DataFrame(rsts_weight).loc[['acc','logloss','cf','time'],:]\n",
        "df_results_weight.transpose().sort_values('logloss')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95bf40b8",
      "metadata": {},
      "source": [
        "### 추가 테스트\n",
        "\n",
        "* 이진분류가 아닌 경우에 대해 한번 해보고 싶어서 적용\n",
        "  * Catboost (Weighted)\n",
        "  * XGBoost (Weighted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba08dc8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{2.0: 1.0, 1.0: 2.707317073170732, 0.0: 5.266962305986696}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 클래스 비율 계산\n",
        "class_counts = x_train['credit'].value_counts()\n",
        "class_weights = {cls: max(class_counts) / count for cls, count in class_counts.items()}\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff5c535",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost\n",
            "* logloss : 0.7854300507522355\n",
            "\n",
            "CatBoost\n",
            "* logloss : 0.8862784774127822\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# 모델 리스트\n",
        "models = {\n",
        "    # XGBoost : eval_metric=\"mlogloss\n",
        "    \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\", random_state=42),\n",
        "    # CatBoost : {0.0: 1.0, 1.0: 2.707317073170732, 2.0: 5.266962305986696}로 설정\n",
        "    \"CatBoost\": CatBoostClassifier(class_weights=[1.0, 2.707317073170732, 5.266962305986696]\n",
        "                                   , verbose=0, random_state=42),\n",
        "}\n",
        "\n",
        "X_train = x_train.drop(['credit'], axis = 1)\n",
        "y_train = x_train['credit']\n",
        "X_test = x_validate.drop(['credit'], axis = 1)\n",
        "y_test = x_validate['credit']\n",
        "rsts_additional = {}\n",
        "\n",
        "# 학습 및 평가\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    logloss = log_loss(y_test, y_proba)\n",
        "    cf = confusion_matrix(y_test, y_pred)\n",
        "    rsts_additional[name] = {'acc':accuracy,\n",
        "                  'logloss':logloss,\n",
        "                  'cf':cf,\n",
        "                  'model' : model,\n",
        "                  'y_pred' : y_pred,\n",
        "                  'y_proba' : y_proba,\n",
        "                  'time' : time.time() - start,\n",
        "                  'classification_report':classification_report(y_test, y_pred, zero_division=0)\n",
        "                  }\n",
        "    \n",
        "    print(f\"\"\"* logloss : {logloss}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599eb4cf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>logloss</th>\n",
              "      <th>cf</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.696019</td>\n",
              "      <td>0.78543</td>\n",
              "      <td>[[56, 142, 769], [20, 524, 1336], [26, 120, 49...</td>\n",
              "      <td>1.066831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.693122</td>\n",
              "      <td>0.886278</td>\n",
              "      <td>[[0, 134, 833], [0, 444, 1436], [0, 33, 5058]]</td>\n",
              "      <td>10.805283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               acc   logloss  \\\n",
              "XGBoost   0.696019   0.78543   \n",
              "CatBoost  0.693122  0.886278   \n",
              "\n",
              "                                                         cf       time  \n",
              "XGBoost   [[56, 142, 769], [20, 524, 1336], [26, 120, 49...   1.066831  \n",
              "CatBoost     [[0, 134, 833], [0, 444, 1436], [0, 33, 5058]]  10.805283  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_results_additional = pd.DataFrame(rsts_additional).loc[['acc','logloss','cf','time'],:]\n",
        "df_results_additional.transpose().sort_values('logloss')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
