{
  "cells": [
    {
      "cell_type": "raw",
      "id": "de6ec63f",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: '[MStudy_과제개선3] 신용카드 이상거래 탐지 모델링 with ML'\n",
        "author: 'Kibok Park'\n",
        "date: '2024-07-18'\n",
        "categories: ['파이썬', '딥러닝', '202406Study_FDS','FDS','optuna','OptunaSearchCV','RandomForest','Scikit-learn']\n",
        "execute:\n",
        "  freeze: auto\n",
        "toc: true\n",
        "draft: false\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "comments:\n",
        "  giscus:\n",
        "    repo: kr9268/giscus_for_blog\n",
        "---\n",
        "Kaggle CreditCard Fraud Detection\n",
        "(개선3 : optuna SearchCV, RandomForest)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839941b",
      "metadata": {},
      "source": [
        "# 개요 \n",
        "* 딥러닝 스터디에 제출했던 과제에 대한 피드백 반영 및 개선(지속 개선예정)\n",
        "* 원본데이터 : [Kaggle CreditCard Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
        "* 적용한 피드백\n",
        "  * weighted f1 score 사용\n",
        "* 추가 테스트\n",
        "  * Optuna (optuna searchCV) 사용해 봄\n",
        "  * Randomforest를 배우지는 않아서, 몇가지 파라미터만 뽑아서 optuna로 돌려 봄\n",
        "    * 과적합 방지를 위한 가지치기(Pruning)이 있다고 하여 적용\n",
        "  * 파라미터를 별도로 저장하고 다시 estimator에 넣는게 불편해보였는데, refit이라는 기능으로 바로 사용가능하다고 하여 적용해 봄\n",
        "* 결과 및 감상\n",
        "  * 수업때 데이터에 따라 오히려 머신러닝이 더 적합할 수 있다고 했는데, Keras Tuner딥러닝보다 점수가 잘나와서 신기\n",
        "  * 복잡한 머신러닝 모델은 SMOTE와 같은 샘플링이 오히려 안좋을 수 있다하여 추이를 보고 적용하려 했는데, 결과적으로 미적용\n",
        "  * optuna가 int, float, categorical로 Keras Tuner대비 입력이 쉽고 전반적으로 사용성이 좋은 느낌\n",
        "    * 간단히 구글링했을 때 샘플코드는, 파라미터가 dict에 담겨 옮겨야했는데, refit 기능으로 best_estimator를 편하게 불러올 수 있었음\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5c44b8",
      "metadata": {},
      "source": [
        "# 개선과제 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8f9c8d",
      "metadata": {},
      "source": [
        "## 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fbc0306",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
              "...          ...       ...       ...       ...       ...       ...     ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('creditcard.db')\n",
        "df = pd.read_sql_query(\"SELECT * FROM creditcard\", conn)\n",
        "conn.close()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd9a158e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((284807, 29), (284807,))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_x = df.drop(['Time', 'Class'], axis=1).copy()\n",
        "df_y = df['Class'].copy()\n",
        "\n",
        "df_x.shape, df_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8698d314",
      "metadata": {},
      "source": [
        "### Train, Validation, Test 나누기\n",
        "* Train, Test로만 나누고, optuna의 CV기능을 사용할 예정으로 별도 분할하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd81f3a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256326, 29), (28481, 29)\n",
            "(256326,), (28481,)\n",
            "\n",
            "y_train Class\n",
            "0    255883\n",
            "1       443\n",
            "Name: count, dtype: int64\n",
            "y_test Class\n",
            "0    28432\n",
            "1       49\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Train, Test 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratify 적용\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, stratify=df_y)\n",
        "\n",
        "print(f\"{x_train.shape}, {x_test.shape}\")\n",
        "print(f\"{y_train.shape}, {y_test.shape}\")\n",
        "print()\n",
        "print(f\"y_train {y_train.value_counts()}\")\n",
        "print(f\"y_test {y_test.value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a74c5d4",
      "metadata": {},
      "source": [
        "## 모델 구성 및 학습(머신러닝)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aca3ad2",
      "metadata": {},
      "source": [
        "### RandomForestClassifier with optuna(OptunaSearchCV)\n",
        "* optuna OptunaSearchCV 공식문서\n",
        "  * [https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.integration.OptunaSearchCV.html](https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.integration.OptunaSearchCV.html)\n",
        "* optuna OptunaSearchCV 샘플코드\n",
        "  * [https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_optuna_search_cv_simple.py](https://github.com/optuna/optuna-examples/blob/main/sklearn/sklearn_optuna_search_cv_simple.py)\n",
        "* Scikit-learn RandomForestClassifier 공식문서\n",
        "  * [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#randomforestclassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#randomforestclassifier)\n",
        "* Scikit-learn ccp_alpha(Pruning, [과적합방지용]가지치기)\n",
        "  * [https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb383c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kibok\\AppData\\Local\\Temp\\ipykernel_20892\\2371441327.py:14: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
            "  optuna_search = optuna.integration.OptunaSearchCV(\n",
            "[I 2024-07-30 22:37:21,982] A new study created in memory with name: no-name-b5929343-b4ec-493f-9805-5e3c4e45dd7c\n",
            "[I 2024-07-30 22:37:44,249] Trial 1 finished with value: 0.9952872331714773 and parameters: {'n_estimators': 10, 'max_depth': 2, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.025}. Best is trial 1 with value: 0.9952872331714773.\n",
            "[I 2024-07-30 22:37:45,772] Trial 4 finished with value: 0.995843694897976 and parameters: {'n_estimators': 10, 'max_depth': 3, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.05}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:37:59,089] Trial 6 finished with value: 0.9904473457587857 and parameters: {'n_estimators': 10, 'max_depth': 5, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.015}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:01,804] Trial 3 finished with value: 0.9926729729394594 and parameters: {'n_estimators': 10, 'max_depth': 5, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.02}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:18,959] Trial 5 finished with value: 0.990931377564992 and parameters: {'n_estimators': 10, 'max_depth': 6, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.045}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:26,532] Trial 2 finished with value: 0.9916618565971218 and parameters: {'n_estimators': 10, 'max_depth': 24, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.025}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:27,286] Trial 7 finished with value: 0.9957148747000535 and parameters: {'n_estimators': 10, 'max_depth': 24, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.05}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:28,366] Trial 0 finished with value: 0.9923829210347611 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.035}. Best is trial 4 with value: 0.995843694897976.\n",
            "[I 2024-07-30 22:38:39,049] Trial 12 finished with value: 0.9970092145586555 and parameters: {'n_estimators': 10, 'max_depth': 2, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.02}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:38:47,101] Trial 10 finished with value: 0.9962438881186829 and parameters: {'n_estimators': 10, 'max_depth': 5, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:38:49,591] Trial 8 finished with value: 0.9934021476853907 and parameters: {'n_estimators': 10, 'max_depth': 25, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.04}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:38:54,134] Trial 9 finished with value: 0.993142523031211 and parameters: {'n_estimators': 10, 'max_depth': 32, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.035}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:06,825] Trial 11 finished with value: 0.9932623645614775 and parameters: {'n_estimators': 10, 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.05}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:21,819] Trial 13 finished with value: 0.99478232737095 and parameters: {'n_estimators': 10, 'max_depth': 6, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.05}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:27,448] Trial 20 finished with value: 0.9952568348608214 and parameters: {'n_estimators': 10, 'max_depth': 2, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:31,517] Trial 15 finished with value: 0.9907314835923732 and parameters: {'n_estimators': 10, 'max_depth': 27, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.02}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:33,576] Trial 14 finished with value: 0.9942530678494605 and parameters: {'n_estimators': 10, 'max_depth': 17, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.015}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:46,802] Trial 16 finished with value: 0.9935641141470762 and parameters: {'n_estimators': 10, 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.035}. Best is trial 12 with value: 0.9970092145586555.\n",
            "[I 2024-07-30 22:39:51,642] Trial 17 finished with value: 0.9994244713511794 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 17 with value: 0.9994244713511794.\n",
            "[I 2024-07-30 22:39:54,732] Trial 18 finished with value: 0.9994107978877771 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 17 with value: 0.9994244713511794.\n",
            "[I 2024-07-30 22:40:00,405] Trial 19 finished with value: 0.9994271656763747 and parameters: {'n_estimators': 10, 'max_depth': 13, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 19 with value: 0.9994271656763747.\n",
            "[I 2024-07-30 22:40:25,456] Trial 21 finished with value: 0.999434017386118 and parameters: {'n_estimators': 10, 'max_depth': 12, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 21 with value: 0.999434017386118.\n",
            "[I 2024-07-30 22:40:31,434] Trial 23 finished with value: 0.9962951737422998 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 21 with value: 0.999434017386118.\n",
            "[I 2024-07-30 22:40:31,957] Trial 22 finished with value: 0.9965979604608748 and parameters: {'n_estimators': 10, 'max_depth': 12, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 21 with value: 0.999434017386118.\n",
            "[I 2024-07-30 22:40:34,465] Trial 24 finished with value: 0.9994337632833448 and parameters: {'n_estimators': 10, 'max_depth': 9, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 21 with value: 0.999434017386118.\n",
            "[I 2024-07-30 22:40:52,562] Trial 25 finished with value: 0.9994408540197803 and parameters: {'n_estimators': 10, 'max_depth': 12, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 25 with value: 0.9994408540197803.\n",
            "[I 2024-07-30 22:40:54,683] Trial 26 finished with value: 0.996698106283177 and parameters: {'n_estimators': 10, 'max_depth': 10, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 25 with value: 0.9994408540197803.\n",
            "[I 2024-07-30 22:40:57,905] Trial 27 finished with value: 0.9994515611974206 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:08,439] Trial 28 finished with value: 0.9994120771228445 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:35,264] Trial 29 finished with value: 0.9966293246541232 and parameters: {'n_estimators': 10, 'max_depth': 11, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:37,240] Trial 32 finished with value: 0.9943959629024558 and parameters: {'n_estimators': 10, 'max_depth': 8, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:38,829] Trial 30 finished with value: 0.9970195292623012 and parameters: {'n_estimators': 10, 'max_depth': 10, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:39,059] Trial 31 finished with value: 0.9934055423774755 and parameters: {'n_estimators': 10, 'max_depth': 15, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:56,868] Trial 33 finished with value: 0.99282882500281 and parameters: {'n_estimators': 10, 'max_depth': 8, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:57,826] Trial 34 finished with value: 0.9945005228300087 and parameters: {'n_estimators': 10, 'max_depth': 8, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:41:59,958] Trial 35 finished with value: 0.9933363510923483 and parameters: {'n_estimators': 10, 'max_depth': 8, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:42:17,745] Trial 36 finished with value: 0.993721820632459 and parameters: {'n_estimators': 10, 'max_depth': 18, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:42:41,309] Trial 38 finished with value: 0.9929849780466793 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:42:45,541] Trial 37 finished with value: 0.9929940457138292 and parameters: {'n_estimators': 10, 'max_depth': 19, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:42:46,614] Trial 39 finished with value: 0.9943285703735368 and parameters: {'n_estimators': 10, 'max_depth': 18, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:42:51,170] Trial 40 finished with value: 0.9931415390179374 and parameters: {'n_estimators': 10, 'max_depth': 19, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:43:06,667] Trial 41 finished with value: 0.9933606814925435 and parameters: {'n_estimators': 10, 'max_depth': 19, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.01}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:43:07,777] Trial 42 finished with value: 0.9994489609295651 and parameters: {'n_estimators': 10, 'max_depth': 18, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 27 with value: 0.9994515611974206.\n",
            "[I 2024-07-30 22:43:08,669] Trial 43 finished with value: 0.999488225721899 and parameters: {'n_estimators': 10, 'max_depth': 18, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:43:27,259] Trial 44 finished with value: 0.9924828083378433 and parameters: {'n_estimators': 10, 'max_depth': 19, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.03}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:43:48,513] Trial 45 finished with value: 0.992049590337098 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.03}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:43:50,422] Trial 46 finished with value: 0.9932099601175659 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.015}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:43:51,611] Trial 47 finished with value: 0.9993886440078258 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:43:58,958] Trial 48 finished with value: 0.9994401064500785 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:07,137] Trial 50 finished with value: 0.9929105605924612 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.03}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:07,476] Trial 51 finished with value: 0.9919062228404238 and parameters: {'n_estimators': 10, 'max_depth': 13, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.03}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:13,069] Trial 49 finished with value: 0.9993790258572499 and parameters: {'n_estimators': 10, 'max_depth': 13, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:28,940] Trial 52 finished with value: 0.9993922088126771 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:46,614] Trial 53 finished with value: 0.9994186582024277 and parameters: {'n_estimators': 10, 'max_depth': 14, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:52,610] Trial 54 finished with value: 0.9994145698407128 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:44:53,677] Trial 55 finished with value: 0.9966165268172439 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:03,419] Trial 56 finished with value: 0.9965818304821432 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:08,608] Trial 58 finished with value: 0.9994701188866102 and parameters: {'n_estimators': 10, 'max_depth': 21, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:11,718] Trial 57 finished with value: 0.9972321227337474 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:16,902] Trial 59 finished with value: 0.9965227246171346 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:35,122] Trial 60 finished with value: 0.9967497598327621 and parameters: {'n_estimators': 10, 'max_depth': 24, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:48,926] Trial 61 finished with value: 0.9965924076680792 and parameters: {'n_estimators': 10, 'max_depth': 22, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:49,771] Trial 63 finished with value: 0.9968081847020078 and parameters: {'n_estimators': 10, 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:55,545] Trial 64 finished with value: 0.9966869244888036 and parameters: {'n_estimators': 10, 'max_depth': 6, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:45:57,437] Trial 62 finished with value: 0.9969938454559518 and parameters: {'n_estimators': 10, 'max_depth': 21, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:00,484] Trial 65 finished with value: 0.9966459887651427 and parameters: {'n_estimators': 10, 'max_depth': 6, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:11,828] Trial 68 finished with value: 0.9974972425443761 and parameters: {'n_estimators': 10, 'max_depth': 4, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:13,138] Trial 66 finished with value: 0.9966811021312786 and parameters: {'n_estimators': 10, 'max_depth': 26, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.005}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:17,972] Trial 67 finished with value: 0.9942535796236317 and parameters: {'n_estimators': 10, 'max_depth': 27, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.04}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:50,434] Trial 69 finished with value: 0.999467911342283 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:51,833] Trial 70 finished with value: 0.9994470603825087 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:46:58,637] Trial 71 finished with value: 0.9994393427930474 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:00,805] Trial 72 finished with value: 0.9994521021059237 and parameters: {'n_estimators': 10, 'max_depth': 27, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:01,833] Trial 73 finished with value: 0.9994418358442221 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:10,673] Trial 75 finished with value: 0.9994360984204311 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:13,758] Trial 74 finished with value: 0.999452858045289 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:20,926] Trial 76 finished with value: 0.9994684374402942 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:52,626] Trial 78 finished with value: 0.9994431588645505 and parameters: {'n_estimators': 10, 'max_depth': 17, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:47:52,704] Trial 77 finished with value: 0.9994565806201864 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:01,973] Trial 79 finished with value: 0.9994605390044315 and parameters: {'n_estimators': 10, 'max_depth': 16, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:02,771] Trial 80 finished with value: 0.9994633300944326 and parameters: {'n_estimators': 10, 'max_depth': 29, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:02,865] Trial 81 finished with value: 0.999438774915282 and parameters: {'n_estimators': 10, 'max_depth': 32, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:11,875] Trial 82 finished with value: 0.999426730915667 and parameters: {'n_estimators': 10, 'max_depth': 31, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:14,934] Trial 83 finished with value: 0.999434660837624 and parameters: {'n_estimators': 10, 'max_depth': 32, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n",
            "[I 2024-07-30 22:48:19,116] Trial 84 finished with value: 0.9994468408750077 and parameters: {'n_estimators': 10, 'max_depth': 25, 'criterion': 'log_loss', 'class_weight': 'balanced', 'ccp_alpha': 0.0}. Best is trial 43 with value: 0.999488225721899.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Value:  0.999488225721899\n",
            "  Params: \n",
            "    n_estimators: 10\n",
            "    max_depth: 18\n",
            "    criterion: log_loss\n",
            "    class_weight: balanced\n",
            "    ccp_alpha: 0.0\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=10) # n_estimators : number of trees\n",
        "\n",
        "param_distributions = {\n",
        "    \"n_estimators\":optuna.distributions.IntDistribution(10, 10), # 트리의 수\n",
        "    \"max_depth\": optuna.distributions.IntDistribution(2, 32, log=True),\n",
        "    \"criterion\": optuna.distributions.CategoricalDistribution(['gini', 'entropy', 'log_loss']),\n",
        "    \"class_weight\" : optuna.distributions.CategoricalDistribution(['balanced', 'balanced_subsample']),\n",
        "    \"ccp_alpha\" : optuna.distributions.FloatDistribution(0, 0.05, step=0.005)\n",
        "}\n",
        "\n",
        "optuna_search = optuna.integration.OptunaSearchCV(\n",
        "    clf, \n",
        "    param_distributions, \n",
        "    n_jobs=-1, # Number of parallel jobs. -1 means using all processors.\n",
        "    cv=5, #  estimator가 classifier & label이 binary or multiclass라면 sklearn.model_selection.StratifiedKFold 적용 (이외는 sklearn.model_selection.KFold)\n",
        "    n_trials=100, \n",
        "    timeout=600, \n",
        "    verbose=2,\n",
        "    scoring='f1_weighted',\n",
        "    refit=True # Best Parameter로 refit. refitted estimator는 best_estimator_ attribute로 바로 predict가능\n",
        ")\n",
        "\n",
        "X, y = x_train, y_train\n",
        "optuna_search.fit(X, y)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = optuna_search.study_.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8351b24c",
      "metadata": {},
      "source": [
        "#### Attributes(Best Parameter, Scorer, Best estimator[Fitted])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce4fac24",
      "metadata": {},
      "source": [
        "* Best Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9de6e48",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 10,\n",
              " 'max_depth': 18,\n",
              " 'criterion': 'log_loss',\n",
              " 'class_weight': 'balanced',\n",
              " 'ccp_alpha': 0.0}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna_search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fd5e95",
      "metadata": {},
      "source": [
        "* Scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c46769",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "make_scorer(f1_score, response_method='predict', pos_label=None, average=weighted)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna_search.scorer_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed1388f",
      "metadata": {},
      "source": [
        "* Best estimator[Fitted]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b1837b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;log_loss&#x27;,\n",
              "                       max_depth=18, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;log_loss&#x27;,\n",
              "                       max_depth=18, n_estimators=10)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', criterion='log_loss',\n",
              "                       max_depth=18, n_estimators=10)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_model_randomforest = optuna_search.best_estimator_\n",
        "best_model_randomforest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81accdd6",
      "metadata": {},
      "source": [
        "#### 모델평가\n",
        "*  Scikit-learn cross_val_score 공식문서\n",
        "    * [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
        "* Scikit-learn f1_score 공식문서 (적용한 weighted f1 score에 대한 설명)\n",
        "  *  [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
        "  * 'weighted' : Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). \n",
        "  `This alters ‘macro’ to account for label imbalance` it can result in an F-score that is not between precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9736b993",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83234aa5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.99921023, 0.99962696, 0.99945948, 0.99866279, 0.99897608])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sklearn.model_selection.cross_val_score(best_model_randomforest, x_test, y_test, scoring='f1_weighted', cv=5, \n",
        "                                        n_jobs=None, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea7d423",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.87482422, 0.9374121 , 0.94991206, 0.81548173, 0.78545062])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sklearn.model_selection.cross_val_score(best_model_randomforest, x_test, y_test, scoring='f1_macro', cv=5, \n",
        "                                        n_jobs=None, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfcdbef3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.99912235, 0.99982444, 0.99964888, 0.99877107, 0.99929775])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sklearn.model_selection.cross_val_score(best_model_randomforest, x_test, y_test, scoring='accuracy', cv=5, \n",
        "                                        n_jobs=None, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83251d9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.97      0.78      0.86        49\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.99      0.89      0.93     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "print(classification_report(y_test, best_model_randomforest.predict(x_test)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
