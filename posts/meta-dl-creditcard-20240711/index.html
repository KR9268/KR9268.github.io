<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.55">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kibok Park">
<meta name="dcterms.date" content="2024-07-11">

<title>[M_Study_최종과제] 신용카드 이상거래 탐지 모델링 – Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/watermark-1.0.11/watermark.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LPL499WQBH"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LPL499WQBH', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index_dashboards.html"> 
<span class="menu-text">Dashboards</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index_miniprojects.html"> 
<span class="menu-text">Mini Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/KR9268"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/%EA%B8%B0%EB%B3%B5-%EB%B0%95-573a68268/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">[M_Study_최종과제] 신용카드 이상거래 탐지 모델링</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">파이썬</div>
                <div class="quarto-category">딥러닝</div>
                <div class="quarto-category">202406Study_FDS</div>
                <div class="quarto-category">FDS</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Kibok Park </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 11, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#개요" id="toc-개요" class="nav-link active" data-scroll-target="#개요">개요</a></li>
  <li><a href="#과제-작성-credit-card-fraud-detection" id="toc-과제-작성-credit-card-fraud-detection" class="nav-link" data-scroll-target="#과제-작성-credit-card-fraud-detection">과제 작성 (Credit Card Fraud Detection)</a>
  <ul class="collapse">
  <li><a href="#데이터-확인kaggle-설명" id="toc-데이터-확인kaggle-설명" class="nav-link" data-scroll-target="#데이터-확인kaggle-설명">데이터 확인(Kaggle 설명)</a></li>
  <li><a href="#데이터-확인-및-전처리" id="toc-데이터-확인-및-전처리" class="nav-link" data-scroll-target="#데이터-확인-및-전처리">데이터 확인 및 전처리</a></li>
  <li><a href="#모델링" id="toc-모델링" class="nav-link" data-scroll-target="#모델링">모델링</a>
  <ul class="collapse">
  <li><a href="#모델링-기초-딥러닝" id="toc-모델링-기초-딥러닝" class="nav-link" data-scroll-target="#모델링-기초-딥러닝">모델링 (기초 딥러닝)</a></li>
  <li><a href="#모델링-keras-tunerhyper-parameter세팅" id="toc-모델링-keras-tunerhyper-parameter세팅" class="nav-link" data-scroll-target="#모델링-keras-tunerhyper-parameter세팅">모델링 (Keras tuner[Hyper parameter세팅])</a></li>
  <li><a href="#모델링-keras-tuner-initialization-추가" id="toc-모델링-keras-tuner-initialization-추가" class="nav-link" data-scroll-target="#모델링-keras-tuner-initialization-추가">모델링 (Keras tuner + Initialization 추가)</a></li>
  <li><a href="#모델링-keras-tuner-batch-normalization-추가" id="toc-모델링-keras-tuner-batch-normalization-추가" class="nav-link" data-scroll-target="#모델링-keras-tuner-batch-normalization-추가">모델링 (Keras tuner + Batch Normalization 추가)</a></li>
  <li><a href="#모델-중간-저장" id="toc-모델-중간-저장" class="nav-link" data-scroll-target="#모델-중간-저장">모델 중간 저장</a></li>
  <li><a href="#모델링-현재-모델에서-learning-rate별-비교-0.1-0.01-0.05" id="toc-모델링-현재-모델에서-learning-rate별-비교-0.1-0.01-0.05" class="nav-link" data-scroll-target="#모델링-현재-모델에서-learning-rate별-비교-0.1-0.01-0.05">모델링 (현재 모델에서 Learning rate별 비교 : 0.1, 0.01, 0.05)</a></li>
  <li><a href="#추가적용-learning-rate-scheduler" id="toc-추가적용-learning-rate-scheduler" class="nav-link" data-scroll-target="#추가적용-learning-rate-scheduler">추가적용 : Learning rate scheduler</a></li>
  <li><a href="#추가적용-earlystopping-with-patience" id="toc-추가적용-earlystopping-with-patience" class="nav-link" data-scroll-target="#추가적용-earlystopping-with-patience">추가적용 : EarlyStopping with patience</a></li>
  <li><a href="#결론" id="toc-결론" class="nav-link" data-scroll-target="#결론">결론</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Kaggle CreditCard Fraud Detection (개선예정)</p>
<section id="개요" class="level1">
<h1>개요</h1>
<ul>
<li>참여중인 딥러닝 스터디 개인과제 정리</li>
<li>원본데이터 : <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud">Kaggle CreditCard Fraud Detection</a>
<ul>
<li>Privacy보호가 중요한 금융 데이터 익명화를 위해 PCA가 적용되어 있음</li>
<li>Class(label)은 1 이상거래, 0은 정상거래를 뜻함</li>
</ul></li>
<li>데이터 확인 및 전처리
<ul>
<li>Null값 확인</li>
<li>Amount(거래액)이 0인 경우는 잡아야 할 거래가 아니라는 관점에서 데이터 제외</li>
<li>Standard/MinMax Scaler 적용</li>
<li>데이터가 Imbalance하므로 평가지표를 <code>F1-score</code>로 설정(정상 99.8 / 이상 0.2)</li>
</ul></li>
<li>모델링
<ul>
<li>수업 때 배운 <code>딥러닝</code> 코드로 간단히 구성</li>
<li>Keras Tuner를 사용한 모델 구성 후 비교</li>
<li>수업 때 배운 요소들을 지속적으로 하나씩 추가하며 기존모델과 비교
<ul>
<li>Initialization</li>
<li>Batch Normalization</li>
<li>Learning rate scheduler</li>
<li>Early stopping with patience</li>
</ul></li>
</ul></li>
<li>결론
<ul>
<li><code>Loss는 지속적인 개선이 되고 있으나 F1score는 계속 비슷한 수치</code>를 보임
<ul>
<li><code>Learning rate Scheduling 적용시에만 약간의 개선</code>이 있음</li>
<li>과제 발표 후 관련내용 질의 및 <code>모델개선 예정</code></li>
</ul></li>
<li>과제 진행 중 생긴 궁금한 점들에 대해서도 추가 질의 예정
<ul>
<li>이런 모델은 결국 사용하고자 만드는 것인데, PCA로 만든 모델이면 새로운 거래가 생성된 경우 그대로 넣어도 모델이 판별 가능한지</li>
<li>epoch 수 대비 적절한 Early stopping patience값이 있는지</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="과제-작성-credit-card-fraud-detection" class="level1">
<h1>과제 작성 (Credit Card Fraud Detection)</h1>
<section id="데이터-확인kaggle-설명" class="level2">
<h2 class="anchored" data-anchor-id="데이터-확인kaggle-설명">데이터 확인(Kaggle 설명)</h2>
<ul>
<li>Kaggle 링크 : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud</li>
<li>컬럼별 정보
<ul>
<li>V1~V28 : may be result of a PCA Dimensionality reduction to protect user identities and sensitive features(v1-v28)</li>
<li>Amount : Transaction amount</li>
<li>Class : 1 for fraudulent transactions, 0 otherwise</li>
</ul></li>
</ul>
</section>
<section id="데이터-확인-및-전처리" class="level2">
<h2 class="anchored" data-anchor-id="데이터-확인-및-전처리">데이터 확인 및 전처리</h2>
<div id="296bbfd2" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sqlite3</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a connection to the SQLite database</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>conn <span class="op">=</span> sqlite3.<span class="ex">connect</span>(<span class="st">'creditcard.db'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the data from the database into a pandas DataFrame</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_sql_query(<span class="st">"SELECT * FROM creditcard"</span>, conn)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Close the connection</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>conn.close()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.0</td>
<td>-1.359807</td>
<td>-0.072781</td>
<td>2.536347</td>
<td>1.378155</td>
<td>-0.338321</td>
<td>0.462388</td>
<td>0.239599</td>
<td>0.098698</td>
<td>0.363787</td>
<td>...</td>
<td>-0.018307</td>
<td>0.277838</td>
<td>-0.110474</td>
<td>0.066928</td>
<td>0.128539</td>
<td>-0.189115</td>
<td>0.133558</td>
<td>-0.021053</td>
<td>149.62</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>1.191857</td>
<td>0.266151</td>
<td>0.166480</td>
<td>0.448154</td>
<td>0.060018</td>
<td>-0.082361</td>
<td>-0.078803</td>
<td>0.085102</td>
<td>-0.255425</td>
<td>...</td>
<td>-0.225775</td>
<td>-0.638672</td>
<td>0.101288</td>
<td>-0.339846</td>
<td>0.167170</td>
<td>0.125895</td>
<td>-0.008983</td>
<td>0.014724</td>
<td>2.69</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>-1.358354</td>
<td>-1.340163</td>
<td>1.773209</td>
<td>0.379780</td>
<td>-0.503198</td>
<td>1.800499</td>
<td>0.791461</td>
<td>0.247676</td>
<td>-1.514654</td>
<td>...</td>
<td>0.247998</td>
<td>0.771679</td>
<td>0.909412</td>
<td>-0.689281</td>
<td>-0.327642</td>
<td>-0.139097</td>
<td>-0.055353</td>
<td>-0.059752</td>
<td>378.66</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>-0.966272</td>
<td>-0.185226</td>
<td>1.792993</td>
<td>-0.863291</td>
<td>-0.010309</td>
<td>1.247203</td>
<td>0.237609</td>
<td>0.377436</td>
<td>-1.387024</td>
<td>...</td>
<td>-0.108300</td>
<td>0.005274</td>
<td>-0.190321</td>
<td>-1.175575</td>
<td>0.647376</td>
<td>-0.221929</td>
<td>0.062723</td>
<td>0.061458</td>
<td>123.50</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2.0</td>
<td>-1.158233</td>
<td>0.877737</td>
<td>1.548718</td>
<td>0.403034</td>
<td>-0.407193</td>
<td>0.095921</td>
<td>0.592941</td>
<td>-0.270533</td>
<td>0.817739</td>
<td>...</td>
<td>-0.009431</td>
<td>0.798278</td>
<td>-0.137458</td>
<td>0.141267</td>
<td>-0.206010</td>
<td>0.502292</td>
<td>0.219422</td>
<td>0.215153</td>
<td>69.99</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284802</td>
<td>172786.0</td>
<td>-11.881118</td>
<td>10.071785</td>
<td>-9.834783</td>
<td>-2.066656</td>
<td>-5.364473</td>
<td>-2.606837</td>
<td>-4.918215</td>
<td>7.305334</td>
<td>1.914428</td>
<td>...</td>
<td>0.213454</td>
<td>0.111864</td>
<td>1.014480</td>
<td>-0.509348</td>
<td>1.436807</td>
<td>0.250034</td>
<td>0.943651</td>
<td>0.823731</td>
<td>0.77</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284803</td>
<td>172787.0</td>
<td>-0.732789</td>
<td>-0.055080</td>
<td>2.035030</td>
<td>-0.738589</td>
<td>0.868229</td>
<td>1.058415</td>
<td>0.024330</td>
<td>0.294869</td>
<td>0.584800</td>
<td>...</td>
<td>0.214205</td>
<td>0.924384</td>
<td>0.012463</td>
<td>-1.016226</td>
<td>-0.606624</td>
<td>-0.395255</td>
<td>0.068472</td>
<td>-0.053527</td>
<td>24.79</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284804</td>
<td>172788.0</td>
<td>1.919565</td>
<td>-0.301254</td>
<td>-3.249640</td>
<td>-0.557828</td>
<td>2.630515</td>
<td>3.031260</td>
<td>-0.296827</td>
<td>0.708417</td>
<td>0.432454</td>
<td>...</td>
<td>0.232045</td>
<td>0.578229</td>
<td>-0.037501</td>
<td>0.640134</td>
<td>0.265745</td>
<td>-0.087371</td>
<td>0.004455</td>
<td>-0.026561</td>
<td>67.88</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284805</td>
<td>172788.0</td>
<td>-0.240440</td>
<td>0.530483</td>
<td>0.702510</td>
<td>0.689799</td>
<td>-0.377961</td>
<td>0.623708</td>
<td>-0.686180</td>
<td>0.679145</td>
<td>0.392087</td>
<td>...</td>
<td>0.265245</td>
<td>0.800049</td>
<td>-0.163298</td>
<td>0.123205</td>
<td>-0.569159</td>
<td>0.546668</td>
<td>0.108821</td>
<td>0.104533</td>
<td>10.00</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284806</td>
<td>172792.0</td>
<td>-0.533413</td>
<td>-0.189733</td>
<td>0.703337</td>
<td>-0.506271</td>
<td>-0.012546</td>
<td>-0.649617</td>
<td>1.577006</td>
<td>-0.414650</td>
<td>0.486180</td>
<td>...</td>
<td>0.261057</td>
<td>0.643078</td>
<td>0.376777</td>
<td>0.008797</td>
<td>-0.473649</td>
<td>-0.818267</td>
<td>-0.002415</td>
<td>0.013649</td>
<td>217.00</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>284807 rows × 31 columns</p>
</div>
</div>
</div>
<ul>
<li><strong>Null값 확인</strong></li>
</ul>
<div id="bf207a33" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 284807 entries, 0 to 284806
Data columns (total 31 columns):
 #   Column  Non-Null Count   Dtype  
---  ------  --------------   -----  
 0   Time    284807 non-null  float64
 1   V1      284807 non-null  float64
 2   V2      284807 non-null  float64
 3   V3      284807 non-null  float64
 4   V4      284807 non-null  float64
 5   V5      284807 non-null  float64
 6   V6      284807 non-null  float64
 7   V7      284807 non-null  float64
 8   V8      284807 non-null  float64
 9   V9      284807 non-null  float64
 10  V10     284807 non-null  float64
 11  V11     284807 non-null  float64
 12  V12     284807 non-null  float64
 13  V13     284807 non-null  float64
 14  V14     284807 non-null  float64
 15  V15     284807 non-null  float64
 16  V16     284807 non-null  float64
 17  V17     284807 non-null  float64
 18  V18     284807 non-null  float64
 19  V19     284807 non-null  float64
 20  V20     284807 non-null  float64
 21  V21     284807 non-null  float64
 22  V22     284807 non-null  float64
 23  V23     284807 non-null  float64
 24  V24     284807 non-null  float64
 25  V25     284807 non-null  float64
 26  V26     284807 non-null  float64
 27  V27     284807 non-null  float64
 28  V28     284807 non-null  float64
 29  Amount  284807 non-null  float64
 30  Class   284807 non-null  int64  
dtypes: float64(30), int64(1)
memory usage: 67.4 MB</code></pre>
</div>
</div>
<ul>
<li><strong>Amount가 0인 값 확인</strong>
<ul>
<li>결제에 대한 Validation 등에 대한 기록으로 추정</li>
<li>이상거래(Class 1)인 데이터도 있긴 하지만, 실질적인 돈의 이동이 없는 것을 이상거래로 잡아야할지에 대한 의문</li>
<li>Amount 0인 값은 제외하는 것으로 결정</li>
</ul></li>
</ul>
<div id="7375419f" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df[df[<span class="st">'Amount'</span>]<span class="op">==</span><span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">383</td>
<td>282.0</td>
<td>-0.356466</td>
<td>0.725418</td>
<td>1.971749</td>
<td>0.831343</td>
<td>0.369681</td>
<td>-0.107776</td>
<td>0.751610</td>
<td>-0.120166</td>
<td>-0.420675</td>
<td>...</td>
<td>0.020804</td>
<td>0.424312</td>
<td>-0.015989</td>
<td>0.466754</td>
<td>-0.809962</td>
<td>0.657334</td>
<td>-0.043150</td>
<td>-0.046401</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">514</td>
<td>380.0</td>
<td>-1.299837</td>
<td>0.881817</td>
<td>1.452842</td>
<td>-1.293698</td>
<td>-0.025105</td>
<td>-1.170103</td>
<td>0.861610</td>
<td>-0.193934</td>
<td>0.592001</td>
<td>...</td>
<td>-0.272563</td>
<td>-0.360853</td>
<td>0.223911</td>
<td>0.598930</td>
<td>-0.397705</td>
<td>0.637141</td>
<td>0.234872</td>
<td>0.021379</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">534</td>
<td>403.0</td>
<td>1.237413</td>
<td>0.512365</td>
<td>0.687746</td>
<td>1.693872</td>
<td>-0.236323</td>
<td>-0.650232</td>
<td>0.118066</td>
<td>-0.230545</td>
<td>-0.808523</td>
<td>...</td>
<td>-0.077543</td>
<td>-0.178220</td>
<td>0.038722</td>
<td>0.471218</td>
<td>0.289249</td>
<td>0.871803</td>
<td>-0.066884</td>
<td>0.012986</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">541</td>
<td>406.0</td>
<td>-2.312227</td>
<td>1.951992</td>
<td>-1.609851</td>
<td>3.997906</td>
<td>-0.522188</td>
<td>-1.426545</td>
<td>-2.537387</td>
<td>1.391657</td>
<td>-2.770089</td>
<td>...</td>
<td>0.517232</td>
<td>-0.035049</td>
<td>-0.465211</td>
<td>0.320198</td>
<td>0.044519</td>
<td>0.177840</td>
<td>0.261145</td>
<td>-0.143276</td>
<td>0.0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">575</td>
<td>430.0</td>
<td>-1.860258</td>
<td>-0.629859</td>
<td>0.966570</td>
<td>0.844632</td>
<td>0.759983</td>
<td>-1.481173</td>
<td>-0.509681</td>
<td>0.540722</td>
<td>-0.733623</td>
<td>...</td>
<td>0.268028</td>
<td>0.125515</td>
<td>-0.225029</td>
<td>0.586664</td>
<td>-0.031598</td>
<td>0.570168</td>
<td>-0.043007</td>
<td>-0.223739</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">283719</td>
<td>171817.0</td>
<td>-0.750414</td>
<td>0.904175</td>
<td>0.996461</td>
<td>0.427284</td>
<td>1.720336</td>
<td>0.929256</td>
<td>0.794272</td>
<td>0.176719</td>
<td>-1.836261</td>
<td>...</td>
<td>0.050750</td>
<td>0.115532</td>
<td>-0.623995</td>
<td>-0.186896</td>
<td>0.733759</td>
<td>2.558151</td>
<td>-0.188835</td>
<td>0.001654</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">283782</td>
<td>171870.0</td>
<td>2.083677</td>
<td>-0.065811</td>
<td>-1.442870</td>
<td>0.135416</td>
<td>0.043035</td>
<td>-1.306975</td>
<td>0.335835</td>
<td>-0.371635</td>
<td>0.730560</td>
<td>...</td>
<td>-0.147536</td>
<td>-0.246599</td>
<td>0.194758</td>
<td>-0.082277</td>
<td>0.012887</td>
<td>-0.069278</td>
<td>-0.048995</td>
<td>-0.065482</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">283949</td>
<td>172027.0</td>
<td>2.132569</td>
<td>-0.057836</td>
<td>-1.724522</td>
<td>-0.030326</td>
<td>0.412146</td>
<td>-0.903088</td>
<td>0.345843</td>
<td>-0.348132</td>
<td>0.722638</td>
<td>...</td>
<td>-0.188739</td>
<td>-0.343876</td>
<td>0.105024</td>
<td>-0.763831</td>
<td>0.117381</td>
<td>-0.027682</td>
<td>-0.047514</td>
<td>-0.071700</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284085</td>
<td>172140.0</td>
<td>-2.210521</td>
<td>-1.039425</td>
<td>0.189704</td>
<td>-1.291932</td>
<td>3.742120</td>
<td>-1.665061</td>
<td>3.120388</td>
<td>-2.324089</td>
<td>0.364926</td>
<td>...</td>
<td>-0.286359</td>
<td>1.326003</td>
<td>-0.361764</td>
<td>-0.268117</td>
<td>1.051309</td>
<td>0.334629</td>
<td>-1.930149</td>
<td>-0.899888</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284770</td>
<td>172759.0</td>
<td>-0.822731</td>
<td>1.270140</td>
<td>-0.138566</td>
<td>0.479620</td>
<td>1.242101</td>
<td>0.795218</td>
<td>0.454284</td>
<td>0.556038</td>
<td>-1.550610</td>
<td>...</td>
<td>0.138766</td>
<td>0.450908</td>
<td>-0.192146</td>
<td>-0.196218</td>
<td>-0.261664</td>
<td>2.372675</td>
<td>-0.042743</td>
<td>0.109613</td>
<td>0.0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>1825 rows × 31 columns</p>
</div>
</div>
</div>
<div id="4933dc92" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df_filtered1 <span class="op">=</span> df[df[<span class="st">'Amount'</span>] <span class="op">!=</span> <span class="dv">0</span>].copy()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df_filtered1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.0</td>
<td>-1.359807</td>
<td>-0.072781</td>
<td>2.536347</td>
<td>1.378155</td>
<td>-0.338321</td>
<td>0.462388</td>
<td>0.239599</td>
<td>0.098698</td>
<td>0.363787</td>
<td>...</td>
<td>-0.018307</td>
<td>0.277838</td>
<td>-0.110474</td>
<td>0.066928</td>
<td>0.128539</td>
<td>-0.189115</td>
<td>0.133558</td>
<td>-0.021053</td>
<td>149.62</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>1.191857</td>
<td>0.266151</td>
<td>0.166480</td>
<td>0.448154</td>
<td>0.060018</td>
<td>-0.082361</td>
<td>-0.078803</td>
<td>0.085102</td>
<td>-0.255425</td>
<td>...</td>
<td>-0.225775</td>
<td>-0.638672</td>
<td>0.101288</td>
<td>-0.339846</td>
<td>0.167170</td>
<td>0.125895</td>
<td>-0.008983</td>
<td>0.014724</td>
<td>2.69</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>-1.358354</td>
<td>-1.340163</td>
<td>1.773209</td>
<td>0.379780</td>
<td>-0.503198</td>
<td>1.800499</td>
<td>0.791461</td>
<td>0.247676</td>
<td>-1.514654</td>
<td>...</td>
<td>0.247998</td>
<td>0.771679</td>
<td>0.909412</td>
<td>-0.689281</td>
<td>-0.327642</td>
<td>-0.139097</td>
<td>-0.055353</td>
<td>-0.059752</td>
<td>378.66</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>-0.966272</td>
<td>-0.185226</td>
<td>1.792993</td>
<td>-0.863291</td>
<td>-0.010309</td>
<td>1.247203</td>
<td>0.237609</td>
<td>0.377436</td>
<td>-1.387024</td>
<td>...</td>
<td>-0.108300</td>
<td>0.005274</td>
<td>-0.190321</td>
<td>-1.175575</td>
<td>0.647376</td>
<td>-0.221929</td>
<td>0.062723</td>
<td>0.061458</td>
<td>123.50</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2.0</td>
<td>-1.158233</td>
<td>0.877737</td>
<td>1.548718</td>
<td>0.403034</td>
<td>-0.407193</td>
<td>0.095921</td>
<td>0.592941</td>
<td>-0.270533</td>
<td>0.817739</td>
<td>...</td>
<td>-0.009431</td>
<td>0.798278</td>
<td>-0.137458</td>
<td>0.141267</td>
<td>-0.206010</td>
<td>0.502292</td>
<td>0.219422</td>
<td>0.215153</td>
<td>69.99</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284802</td>
<td>172786.0</td>
<td>-11.881118</td>
<td>10.071785</td>
<td>-9.834783</td>
<td>-2.066656</td>
<td>-5.364473</td>
<td>-2.606837</td>
<td>-4.918215</td>
<td>7.305334</td>
<td>1.914428</td>
<td>...</td>
<td>0.213454</td>
<td>0.111864</td>
<td>1.014480</td>
<td>-0.509348</td>
<td>1.436807</td>
<td>0.250034</td>
<td>0.943651</td>
<td>0.823731</td>
<td>0.77</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284803</td>
<td>172787.0</td>
<td>-0.732789</td>
<td>-0.055080</td>
<td>2.035030</td>
<td>-0.738589</td>
<td>0.868229</td>
<td>1.058415</td>
<td>0.024330</td>
<td>0.294869</td>
<td>0.584800</td>
<td>...</td>
<td>0.214205</td>
<td>0.924384</td>
<td>0.012463</td>
<td>-1.016226</td>
<td>-0.606624</td>
<td>-0.395255</td>
<td>0.068472</td>
<td>-0.053527</td>
<td>24.79</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284804</td>
<td>172788.0</td>
<td>1.919565</td>
<td>-0.301254</td>
<td>-3.249640</td>
<td>-0.557828</td>
<td>2.630515</td>
<td>3.031260</td>
<td>-0.296827</td>
<td>0.708417</td>
<td>0.432454</td>
<td>...</td>
<td>0.232045</td>
<td>0.578229</td>
<td>-0.037501</td>
<td>0.640134</td>
<td>0.265745</td>
<td>-0.087371</td>
<td>0.004455</td>
<td>-0.026561</td>
<td>67.88</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284805</td>
<td>172788.0</td>
<td>-0.240440</td>
<td>0.530483</td>
<td>0.702510</td>
<td>0.689799</td>
<td>-0.377961</td>
<td>0.623708</td>
<td>-0.686180</td>
<td>0.679145</td>
<td>0.392087</td>
<td>...</td>
<td>0.265245</td>
<td>0.800049</td>
<td>-0.163298</td>
<td>0.123205</td>
<td>-0.569159</td>
<td>0.546668</td>
<td>0.108821</td>
<td>0.104533</td>
<td>10.00</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">284806</td>
<td>172792.0</td>
<td>-0.533413</td>
<td>-0.189733</td>
<td>0.703337</td>
<td>-0.506271</td>
<td>-0.012546</td>
<td>-0.649617</td>
<td>1.577006</td>
<td>-0.414650</td>
<td>0.486180</td>
<td>...</td>
<td>0.261057</td>
<td>0.643078</td>
<td>0.376777</td>
<td>0.008797</td>
<td>-0.473649</td>
<td>-0.818267</td>
<td>-0.002415</td>
<td>0.013649</td>
<td>217.00</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>282982 rows × 31 columns</p>
</div>
</div>
</div>
<div id="4d7d65c9" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df_filtered1[df_filtered1[<span class="st">'Amount'</span>]<span class="op">==</span><span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
</tbody>
</table>

<p>0 rows × 31 columns</p>
</div>
</div>
</div>
<ul>
<li><strong>Label값(이상거래 비중) 확인</strong>
<ul>
<li>Imbalance한 경우, Accuracy는 성능측정에 한계가 있으므로, 다른 지표를 사용</li>
<li><code>F1-Score</code> 사용 예정</li>
</ul></li>
</ul>
<div id="41b7d570" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df_filtered1[<span class="st">"Class"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Class
0    0.998357
1    0.001643
Name: proportion, dtype: float64</code></pre>
</div>
</div>
<ul>
<li><strong>X와 Y로 나누고, Scaler 적용(StandardScaler, MinMaxScaler)</strong></li>
</ul>
<div id="54579d3e" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df_x <span class="op">=</span> df_filtered1.drop([<span class="st">'Time'</span>, <span class="st">'Class'</span>], axis<span class="op">=</span><span class="dv">1</span>).copy()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df_y <span class="op">=</span> df_filtered1[<span class="st">'Class'</span>].copy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e165b397" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df_x.shape, df_y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>((282982, 29), (282982,))</code></pre>
</div>
</div>
<div id="d001ccbc" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, MinMaxScaler</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>scaler_minmax <span class="op">=</span> MinMaxScaler()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>df_x_scaled <span class="op">=</span> scaler_minmax.fit_transform(df_x)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>scaler_std <span class="op">=</span> StandardScaler()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>df_x_scaled <span class="op">=</span> scaler_std.fit_transform(df_x_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4c7952b4" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df_x_scaled</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([[-0.6947547 , -0.04287463,  1.67720049, ...,  0.33079262,
        -0.06431265,  0.24200481],
       [ 0.60928   ,  0.16247803,  0.11211972, ..., -0.02292114,
         0.0439881 , -0.34378459],
       [-0.6940121 , -0.81075824,  1.17321784, ..., -0.13798659,
        -0.18145722,  1.15515532],
       ...,
       [ 0.98117703, -0.18130206, -2.14391593, ...,  0.01042466,
        -0.08098516, -0.08388116],
       [-0.12269922,  0.32263185,  0.46611873, ...,  0.26940666,
         0.31584664, -0.31464064],
       [-0.27242357, -0.11373381,  0.46666497, ..., -0.0066233 ,
         0.04073321,  0.51063947]])</code></pre>
</div>
</div>
<ul>
<li><strong>train, test데이터 나누기</strong></li>
</ul>
<div id="d9d32a04" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># train + test</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>x_train, x_test <span class="op">=</span> train_test_split(df_x_scaled, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y_train, y_test <span class="op">=</span> train_test_split(df_y, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Train과 Test로 나누기'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_train.shape, x_test.shape)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_train.shape, y_test.shape)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># train + validation</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>x_train, x_validate <span class="op">=</span> train_test_split(x_train, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>y_train, y_validate <span class="op">=</span> train_test_split(y_train, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Train과 Validation으로 나누기'</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_train.shape, x_validate.shape, x_test.shape)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train.shape, y_validate.shape, y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train과 Test로 나누기
(198087, 29) (84895, 29)
(198087, 29) (84895,)

Train과 Validation으로 나누기
(138660, 29) (59427, 29) (84895, 29)
(138660,) (59427,) (84895,)</code></pre>
</div>
</div>
</section>
<section id="모델링" class="level2">
<h2 class="anchored" data-anchor-id="모델링">모델링</h2>
<section id="모델링-기초-딥러닝" class="level3">
<h3 class="anchored" data-anchor-id="모델링-기초-딥러닝">모델링 (기초 딥러닝)</h3>
<div id="d2674445" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="abdc0b88" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델링</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Input((<span class="dv">29</span>,<span class="dv">1</span>)),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Flatten(),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>) <span class="co"># 이진분류이므로 Sigmoid사용</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, <span class="co"># 0과 1의 이진분류이므로 binary_crossentropy 사용</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 4s 763us/step - F1Score: 0.0037 - loss: 0.0360
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 776us/step - F1Score: 0.0036 - loss: 0.0140
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 761us/step - F1Score: 0.0035 - loss: 0.0129
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 730us/step - F1Score: 0.0033 - loss: 0.0123
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 718us/step - F1Score: 0.0036 - loss: 0.0131
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 728us/step - F1Score: 0.0033 - loss: 0.0119
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 740us/step - F1Score: 0.0036 - loss: 0.0128
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 730us/step - F1Score: 0.0033 - loss: 0.0118
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 726us/step - F1Score: 0.0033 - loss: 0.0114
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 3s 729us/step - F1Score: 0.0035 - loss: 0.0122
* 모델평가
4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114
2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</code></pre>
</div>
</div>
</section>
<section id="모델링-keras-tunerhyper-parameter세팅" class="level3">
<h3 class="anchored" data-anchor-id="모델링-keras-tunerhyper-parameter세팅">모델링 (Keras tuner[Hyper parameter세팅])</h3>
<ul>
<li><code>Hidden Layer</code>의 수</li>
<li><code>Neuron</code>의 수</li>
<li><code>Activation fuction</code> : ReLU, ELU 중 택1
<ul>
<li>Reaky ReLU도 고려대상에 넣고싶었지만, String이 아닌 별도 함수로 적용해야해서 제외</li>
</ul></li>
<li><code>Optimizer</code> : 같은 조건으로 2개의 Optimizer(Adam, Nadam)로 먼저 돌렸다가 Tuner에게 추천받은 Nadam으로 설정</li>
</ul>
<div id="febe4793" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras_tuner <span class="im">as</span> kt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="58e652bb" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Sequential()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input &amp; Flatten</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Input((<span class="dv">29</span>,<span class="dv">1</span>)))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Flatten())</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hidden Layers</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(hp.Int(<span class="st">'num_layers'</span>,min_value<span class="op">=</span><span class="dv">1</span>,max_value<span class="op">=</span><span class="dv">20</span>)):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dense</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        units <span class="op">=</span> hp.Int(<span class="st">'units'</span>,min_value<span class="op">=</span><span class="dv">5</span>,max_value<span class="op">=</span><span class="dv">150</span>,step<span class="op">=</span><span class="dv">5</span>) <span class="co"># For Neurons</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> hp.Choice(<span class="st">'activation'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="st">'relu'</span>,<span class="st">'elu'</span>]) <span class="co"># For Activation</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dense(units, activation<span class="op">=</span>activation))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dropout</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        dropout_rate <span class="op">=</span> hp.Choice(<span class="st">'dropout'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.7</span>,<span class="fl">0.8</span>,<span class="fl">0.9</span>])</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dropout(dropout_rate))</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)) <span class="co"># 이진분류이므로 Sigmoid사용</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>hp.Choice(<span class="st">'optimizer'</span>,values<span class="op">=</span>[<span class="st">'Nadam'</span>])</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.device(<span class="st">'/device:GPU:0'</span>):</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    tuner<span class="op">=</span>kt.RandomSearch(build_model,</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>                        objective<span class="op">=</span>kt.Objective(<span class="st">'val_F1Score'</span>, direction<span class="op">=</span><span class="st">'max'</span>),<span class="co"># accuracy 미사용</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>                        overwrite<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>                        max_trials<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>                        project_name<span class="op">=</span><span class="st">'randomsearch_model'</span>)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    tuner.search(x_train,y_train,epochs<span class="op">=</span><span class="dv">10</span>,validation_data<span class="op">=</span>(x_test,y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 9 Complete [00h 01m 10s]
val_F1Score: 0.0028702165000140667

Best val_F1Score So Far: 0.0028861388564109802
Total elapsed time: 00h 18m 28s</code></pre>
</div>
</div>
<div id="5ebbfd41" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>tuner.get_best_hyperparameters()[<span class="dv">0</span>].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'num_layers': 12,
 'units': 90,
 'activation0': 'relu',
 'dropout0': 0.9,
 'optimizer': 'Nadam',
 'activation1': 'relu',
 'dropout1': 0.1,
 'activation2': 'relu',
 'dropout2': 0.1,
 'activation3': 'relu',
 'dropout3': 0.1,
 'activation4': 'relu',
 'dropout4': 0.1,
 'activation5': 'relu',
 'dropout5': 0.1,
 'activation6': 'relu',
 'dropout6': 0.1,
 'activation7': 'relu',
 'dropout7': 0.1,
 'activation8': 'relu',
 'dropout8': 0.1,
 'activation9': 'relu',
 'dropout9': 0.1,
 'activation10': 'relu',
 'dropout10': 0.1,
 'activation11': 'relu',
 'dropout11': 0.1}</code></pre>
</div>
</div>
<div id="87df7865" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model_2<span class="op">=</span> tuner.get_best_models(num_models<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>model_2.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>c:\Users\kibok\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\saving\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 2 variables whereas the saved optimizer has 55 variables. 
  saveable.load_own_variables(weights_store.get(inner_path))</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">29</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">2,700</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,190</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">90</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">91</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">92,881</span> (362.82 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">92,881</span> (362.82 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div id="5d7c5633" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_2.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_2.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_2.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 15s 2ms/step - F1Score: 0.0031 - loss: 0.0463
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0222
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0031 - loss: 0.0144
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0032 - loss: 0.0202
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0200
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0166
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0036 - loss: 0.0167
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 12s 3ms/step - F1Score: 0.0032 - loss: 0.0131
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 11s 3ms/step - F1Score: 0.0033 - loss: 0.0229
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 11s 3ms/step - F1Score: 0.0032 - loss: 0.0216
* 모델평가
4334/4334 - 4s - 1ms/step - F1Score: 0.0034 - loss: 0.0125
2653/2653 - 2s - 787us/step - F1Score: 0.0029 - loss: 0.0113</code></pre>
</div>
</div>
<section id="f1score-및-loss-개선-비교" class="level4">
<h4 class="anchored" data-anchor-id="f1score-및-loss-개선-비교">F1Score 및 Loss 개선 비교</h4>
<ul>
<li>모델평가(기본) <br>
<ul>
<li>4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114</li>
<li>2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</li>
</ul></li>
<li>모델평가(Tuner) <br>
<ul>
<li>4334/4334 - 4s - 860us/step - F1Score: 0.0034 - loss: 0.0175</li>
<li>2653/2653 - 2s - 862us/step - F1Score: 0.0029 - loss: 0.0164</li>
</ul></li>
</ul>
</section>
</section>
<section id="모델링-keras-tuner-initialization-추가" class="level3">
<h3 class="anchored" data-anchor-id="모델링-keras-tuner-initialization-추가">모델링 (Keras tuner + Initialization 추가)</h3>
<ul>
<li><code>HeNormal (Kaiming) 적용</code>
<ul>
<li>수업시간에 배운 <code>Random</code>/<code>Xavier</code>/ <code>Kaiming/MSRA Initialization for ReLU</code>에 대해 검색해 봄
<ul>
<li>미설정시 기본값은 Xavier(GlorotNormal)로 적용된다고 함</li>
<li><strong>Pytorch와 Tensorflow에서의 Initialization 명칭이 다름</strong>
<ul>
<li>HeNormal(Tensorflow) / Kaiming (Pytorch)</li>
<li>GlorotNormal(Tensorflow) / XavierNormal (Pytorch)</li>
<li>Random Normall(Tensorflow) / Random(Pytorch)</li>
</ul></li>
<li>Innitialization은 <code>kernel_initializer(Weight)</code>뿐 아니라 <code>bias_initializer(Bias)</code>도 있음</li>
</ul></li>
</ul></li>
</ul>
<div id="0f75d716" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Sequential()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input &amp; Flatten</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Input((<span class="dv">29</span>,<span class="dv">1</span>)))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Flatten())</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hidden Layers</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(hp.Int(<span class="st">'num_layers'</span>,min_value<span class="op">=</span><span class="dv">1</span>,max_value<span class="op">=</span><span class="dv">20</span>)):</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dense</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        units <span class="op">=</span> hp.Int(<span class="st">'units'</span>,min_value<span class="op">=</span><span class="dv">5</span>,max_value<span class="op">=</span><span class="dv">150</span>,step<span class="op">=</span><span class="dv">5</span>) <span class="co"># For Neurons</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> hp.Choice(<span class="st">'activation'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="st">'relu'</span>,<span class="st">'elu'</span>]) <span class="co"># For Activation</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dense(units, activation<span class="op">=</span>activation,</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># 기본값은 glorot_uniform(Xavier), He(Kaiming)적용</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>                                        kernel_initializer<span class="op">=</span>tf.keras.initializers.HeNormal())) </span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dropout</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        dropout_rate <span class="op">=</span> hp.Choice(<span class="st">'dropout'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.7</span>,<span class="fl">0.8</span>,<span class="fl">0.9</span>])</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dropout(dropout_rate))</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)) <span class="co"># 이진분류이므로 Sigmoid사용</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>hp.Choice(<span class="st">'optimizer'</span>,values<span class="op">=</span>[<span class="st">'Nadam'</span>])</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.device(<span class="st">'/device:GPU:0'</span>):</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    tuner<span class="op">=</span>kt.RandomSearch(build_model,</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>                        objective<span class="op">=</span>kt.Objective(<span class="st">'val_F1Score'</span>, direction<span class="op">=</span><span class="st">'min'</span>),<span class="co"># accuracy 미사용</span></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>                        overwrite<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>                        max_trials<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>                        project_name<span class="op">=</span><span class="st">'randomsearch_model_+initialize'</span>)</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    tuner.search(x_train,y_train,epochs<span class="op">=</span><span class="dv">10</span>,validation_data<span class="op">=</span>(x_test,y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 9 Complete [00h 01m 32s]
val_F1Score: 0.002870013704523444

Best val_F1Score So Far: 0.0
Total elapsed time: 00h 21m 15s</code></pre>
</div>
</div>
<div id="14581795" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>tuner.get_best_hyperparameters()[<span class="dv">0</span>].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'num_layers': 17,
 'units': 145,
 'activation0': 'elu',
 'dropout0': 0.9,
 'optimizer': 'Nadam',
 'activation1': 'relu',
 'dropout1': 0.9,
 'activation2': 'relu',
 'dropout2': 0.8,
 'activation3': 'elu',
 'dropout3': 0.9,
 'activation4': 'elu',
 'dropout4': 0.6,
 'activation5': 'elu',
 'dropout5': 0.9,
 'activation6': 'relu',
 'dropout6': 0.4,
 'activation7': 'relu',
 'dropout7': 0.2,
 'activation8': 'elu',
 'dropout8': 0.7,
 'activation9': 'relu',
 'dropout9': 0.3,
 'activation10': 'elu',
 'dropout10': 0.4,
 'activation11': 'relu',
 'dropout11': 0.8,
 'activation12': 'elu',
 'dropout12': 0.2,
 'activation13': 'relu',
 'dropout13': 0.1,
 'activation14': 'relu',
 'dropout14': 0.1,
 'activation15': 'relu',
 'dropout15': 0.1,
 'activation16': 'relu',
 'dropout16': 0.1}</code></pre>
</div>
</div>
<div id="dccddb89" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model_3<span class="op">=</span> tuner.get_best_models(num_models<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>model_3.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>c:\Users\kibok\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\saving\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 2 variables whereas the saved optimizer has 75 variables. 
  saveable.load_own_variables(weights_store.get(inner_path))</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">29</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">4,350</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">21,170</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">145</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">146</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">343,216</span> (1.31 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">343,216</span> (1.31 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div id="4289fbb2" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_3.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_3.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_3.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 26s 5ms/step - F1Score: 0.0031 - loss: 0.3784
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 21s 5ms/step - F1Score: 0.0033 - loss: 0.0700
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 19s 4ms/step - F1Score: 0.0031 - loss: 0.1938
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 20s 5ms/step - F1Score: 0.0032 - loss: 0.2460
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 18s 4ms/step - F1Score: 0.0035 - loss: 0.2332
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 19s 4ms/step - F1Score: 0.0038 - loss: 0.0661
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 18s 4ms/step - F1Score: 0.0033 - loss: 0.0123
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 20s 5ms/step - F1Score: 0.0033 - loss: 0.0124
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 20s 5ms/step - F1Score: 0.0031 - loss: 0.0583
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 20s 4ms/step - F1Score: 0.0033 - loss: 0.4909
* 모델평가
4334/4334 - 6s - 1ms/step - F1Score: 0.0034 - loss: 0.0124
2653/2653 - 4s - 1ms/step - F1Score: 0.0029 - loss: 0.0109</code></pre>
</div>
</div>
<section id="f1score-및-loss-개선-비교-1" class="level4">
<h4 class="anchored" data-anchor-id="f1score-및-loss-개선-비교-1">F1Score 및 Loss 개선 비교</h4>
<ul>
<li>모델평가(기본) <br>
<ul>
<li>4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114</li>
<li>2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</li>
</ul></li>
<li>모델평가(Tuner) <br>
<ul>
<li>4334/4334 - 4s - 860us/step - F1Score: 0.0034 - loss: 0.0175</li>
<li>2653/2653 - 2s - 862us/step - F1Score: 0.0029 - loss: 0.0164</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization) <br>
<ul>
<li>4334/4334 - 6s - 1ms/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 4s - 1ms/step - F1Score: 0.0029 - loss: 0.0109</li>
</ul></li>
</ul>
</section>
</section>
<section id="모델링-keras-tuner-batch-normalization-추가" class="level3">
<h3 class="anchored" data-anchor-id="모델링-keras-tuner-batch-normalization-추가">모델링 (Keras tuner + Batch Normalization 추가)</h3>
<ul>
<li>Activation layer 전에 Batch normalization 적용</li>
</ul>
<div id="a561a1e4" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Sequential()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input &amp; Flatten</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Input((<span class="dv">29</span>,<span class="dv">1</span>)))</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Flatten())</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hidden Layers</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(hp.Int(<span class="st">'num_layers'</span>,min_value<span class="op">=</span><span class="dv">1</span>,max_value<span class="op">=</span><span class="dv">20</span>)):</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dense</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>        units <span class="op">=</span> hp.Int(<span class="st">'units'</span>,min_value<span class="op">=</span><span class="dv">5</span>,max_value<span class="op">=</span><span class="dv">150</span>,step<span class="op">=</span><span class="dv">5</span>) <span class="co"># For Neurons</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> hp.Choice(<span class="st">'activation'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="st">'relu'</span>,<span class="st">'elu'</span>]) <span class="co"># For Activation</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dense(units, activation<span class="op">=</span>activation,</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># 기본값은 glorot_uniform(Xavier), He는 Kaiming</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>                                        kernel_initializer<span class="op">=</span>tf.keras.initializers.HeNormal())) </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Batch Normalization</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.BatchNormalization()) <span class="co"># Layer통과후 &amp; Activation 전</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For Dropout</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>        dropout_rate <span class="op">=</span> hp.Choice(<span class="st">'dropout'</span><span class="op">+</span><span class="bu">str</span>(i),values<span class="op">=</span>[<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.7</span>,<span class="fl">0.8</span>,<span class="fl">0.9</span>])</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>        model.add(tf.keras.layers.Dropout(dropout_rate))</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    model.add(tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)) <span class="co"># 이진분류이므로 Sigmoid사용</span></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>hp.Choice(<span class="st">'optimizer'</span>,values<span class="op">=</span>[<span class="st">'Nadam'</span>])</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.device(<span class="st">'/device:GPU:0'</span>):</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>    tuner<span class="op">=</span>kt.RandomSearch(build_model,</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>                        objective<span class="op">=</span>kt.Objective(<span class="st">'val_F1Score'</span>, direction<span class="op">=</span><span class="st">'min'</span>),<span class="co"># accuracy 미사용</span></span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>                        overwrite<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>                        max_trials<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>                        project_name<span class="op">=</span><span class="st">'randomsearch_model_+initialize+batchnormalize'</span>)</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>    tuner.search(x_train,y_train,epochs<span class="op">=</span><span class="dv">10</span>,validation_data<span class="op">=</span>(x_test,y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 9 Complete [00h 05m 00s]
val_F1Score: 0.003198833204805851

Best val_F1Score So Far: 0.003198833204805851
Total elapsed time: 00h 25m 05s</code></pre>
</div>
</div>
<div id="a27d42eb" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>tuner.get_best_hyperparameters()[<span class="dv">0</span>].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'num_layers': 3,
 'units': 5,
 'activation0': 'relu',
 'dropout0': 0.2,
 'optimizer': 'Nadam',
 'activation1': 'relu',
 'dropout1': 0.1,
 'activation2': 'relu',
 'dropout2': 0.1}</code></pre>
</div>
</div>
<div id="e8d8ea13" class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model_4<span class="op">=</span> tuner.get_best_models(num_models<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>model_4.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>c:\Users\kibok\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\saving\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 2 variables whereas the saved optimizer has 31 variables. 
  saveable.load_own_variables(weights_store.get(inner_path))</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">29</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">150</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">20</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">30</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">20</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">30</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │            <span style="color: #00af00; text-decoration-color: #00af00">20</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>)              │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │             <span style="color: #00af00; text-decoration-color: #00af00">6</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">276</span> (1.08 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">246</span> (984.00 B)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">30</span> (120.00 B)
</pre>
</div>
</div>
<div id="add5769d" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 13s 2ms/step - F1Score: 0.0038 - loss: 0.0143
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0030 - loss: 0.0116
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0033 - loss: 0.0125
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 9s 2ms/step - F1Score: 0.0034 - loss: 0.0130
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0126
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0035 - loss: 0.0132
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0130
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0036 - loss: 0.0133
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0029 - loss: 0.0111
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0035 - loss: 0.0131
* 모델평가
4334/4334 - 3s - 788us/step - F1Score: 0.0034 - loss: 0.0125
2653/2653 - 2s - 757us/step - F1Score: 0.0029 - loss: 0.0110</code></pre>
</div>
</div>
<section id="f1score-및-loss-개선-비교-2" class="level4">
<h4 class="anchored" data-anchor-id="f1score-및-loss-개선-비교-2">F1Score 및 Loss 개선 비교</h4>
<ul>
<li>모델평가(기본) <br>
<ul>
<li>4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114</li>
<li>2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</li>
</ul></li>
<li>모델평가(Tuner) <br>
<ul>
<li>4334/4334 - 4s - 860us/step - F1Score: 0.0034 - loss: 0.0175</li>
<li>2653/2653 - 2s - 862us/step - F1Score: 0.0029 - loss: 0.0164</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization) <br>
<ul>
<li>4334/4334 - 6s - 1ms/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 4s - 1ms/step - F1Score: 0.0029 - loss: 0.0109</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization) <br>
<ul>
<li>4334/4334 - 3s - 788us/step - F1Score: 0.0034 - loss: 0.0125</li>
<li>2653/2653 - 2s - 757us/step - F1Score: 0.0029 - loss: 0.0110</li>
</ul></li>
</ul>
</section>
</section>
<section id="모델-중간-저장" class="level3">
<h3 class="anchored" data-anchor-id="모델-중간-저장">모델 중간 저장</h3>
<ul>
<li>이후 부터는 Learning rate 등의 변경만 있을 예정으로, Tuner를 사용하지 않고 모델을 저장했다가 사용</li>
</ul>
<div id="d52c4dcf" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> tuner.get_best_models(num_models<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>model_4.save(<span class="st">'model_4.keras'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="모델링-현재-모델에서-learning-rate별-비교-0.1-0.01-0.05" class="level3">
<h3 class="anchored" data-anchor-id="모델링-현재-모델에서-learning-rate별-비교-0.1-0.01-0.05">모델링 (현재 모델에서 Learning rate별 비교 : 0.1, 0.01, 0.05)</h3>
<section id="learning-rate-0.1" class="level4">
<h4 class="anchored" data-anchor-id="learning-rate-0.1">Learning rate : 0.1</h4>
<ul>
<li>Loss값이 튀는 상황으로 줄여야 할 것으로 보임</li>
</ul>
<div id="3ec5517c" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 학습률 설정</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>new_learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 9s 2ms/step - F1Score: 0.0038 - loss: 0.0155
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0036 - loss: 0.0142
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0035 - loss: 0.0136
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0034 - loss: 0.0137
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0143
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0036 - loss: 0.0144
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0031 - loss: 0.0120
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0037 - loss: 0.0145
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0036 - loss: 0.0141
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0034 - loss: 0.0131
* 모델평가
4334/4334 - 3s - 639us/step - F1Score: 0.0034 - loss: 0.0130
2653/2653 - 2s - 629us/step - F1Score: 0.0032 - loss: 0.0127</code></pre>
</div>
</div>
<div id="9a3e1597" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="learning-rate-0.01" class="level4">
<h4 class="anchored" data-anchor-id="learning-rate-0.01">Learning rate : 0.01</h4>
<ul>
<li>Loss값이 원만하게 하락</li>
</ul>
<div id="d98fc1f2" class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 학습률 설정</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>new_learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 1ms/step - F1Score: 0.0034 - loss: 0.0137
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0031 - loss: 0.0122
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0037 - loss: 0.0137
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0029 - loss: 0.0114
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0128
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0127
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0126
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0033 - loss: 0.0123
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0037 - loss: 0.0134
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0033 - loss: 0.0122
* 모델평가
4334/4334 - 3s - 649us/step - F1Score: 0.0034 - loss: 0.0124
2653/2653 - 2s - 658us/step - F1Score: 0.0032 - loss: 0.0121</code></pre>
</div>
</div>
<div id="8b3c3e3f" class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="learning-rate-0.05" class="level4">
<h4 class="anchored" data-anchor-id="learning-rate-0.05">Learning rate : 0.05</h4>
<ul>
<li>Loss값이 조금 위아래로 움직임.</li>
<li>향후 현재의 10회가 아닌 1000회 epoch을 돌려볼 것이므로 학습시간을 고려새 0.01이 아닌 0.05로 적용하는 것을 고려</li>
</ul>
<div id="2e9ec9e5" class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 학습률 설정</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>new_learning_rate <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 1ms/step - F1Score: 0.0032 - loss: 0.0137
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0120
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0119
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0130
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0131
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0033 - loss: 0.0124
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0033 - loss: 0.0126
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0128
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0038 - loss: 0.0141
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0032 - loss: 0.0119
* 모델평가
4334/4334 - 3s - 666us/step - F1Score: 0.0034 - loss: 0.0124
2653/2653 - 2s - 648us/step - F1Score: 0.0032 - loss: 0.0119</code></pre>
</div>
</div>
<div id="6b7fa099" class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-34-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="추가적용-learning-rate-scheduler" class="level3">
<h3 class="anchored" data-anchor-id="추가적용-learning-rate-scheduler">추가적용 : Learning rate scheduler</h3>
<ul>
<li>Learning rate 0.05를 적용하기로 했으므로, 동일한 기준인 10 epoch중 loss가 증가했던 구간부터 rate 변경 적용 #### 기본 Learning rate scheduler</li>
<li>적용 전과 비교했을 때, Loss가 전반적으로 우하향 하는 추세를 보여줌</li>
</ul>
<div id="a64913e1" class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> LearningRateScheduler</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bca3666d" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scheduler(epoch, lr):</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">&lt;</span> <span class="dv">5</span>:</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(lr)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(lr <span class="op">*</span> tf.exp(<span class="op">-</span><span class="fl">0.1</span>))</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>lr_scheduler <span class="op">=</span> LearningRateScheduler(scheduler, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 학습률 설정</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>new_learning_rate <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>                      callbacks<span class="op">=</span>[lr_scheduler])</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Epoch 1: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 1ms/step - F1Score: 0.0032 - loss: 0.0134 - learning_rate: 0.0500

Epoch 2: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0134 - learning_rate: 0.0500

Epoch 3: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0031 - loss: 0.0120 - learning_rate: 0.0500

Epoch 4: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 5s 1ms/step - F1Score: 0.0033 - loss: 0.0125 - learning_rate: 0.0500

Epoch 5: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0031 - loss: 0.0120 - learning_rate: 0.0500

Epoch 6: LearningRateScheduler setting learning rate to 0.04524187371134758.
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0129 - learning_rate: 0.0452

Epoch 7: LearningRateScheduler setting learning rate to 0.04093654081225395.
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0031 - loss: 0.0119 - learning_rate: 0.0409

Epoch 8: LearningRateScheduler setting learning rate to 0.037040915340185165.
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0037 - loss: 0.0137 - learning_rate: 0.0370

Epoch 9: LearningRateScheduler setting learning rate to 0.03351600840687752.
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0127 - learning_rate: 0.0335

Epoch 10: LearningRateScheduler setting learning rate to 0.030326539650559425.
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0127 - learning_rate: 0.0303
* 모델평가
4334/4334 - 3s - 643us/step - F1Score: 0.0034 - loss: 0.0124
2653/2653 - 2s - 611us/step - F1Score: 0.0032 - loss: 0.0120</code></pre>
</div>
</div>
<ul>
<li>적용 전과 비교했을 때, Loss가 전반적으로 우하향 하는 추세를 보여줌</li>
</ul>
<div id="592a8655" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-37-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="cosine-learning-rate-scheduler" class="level4">
<h4 class="anchored" data-anchor-id="cosine-learning-rate-scheduler"><code>Cosine</code> Learning rate scheduler</h4>
<ul>
<li>ChatGPT의 도움을 받아 기존의 scheduler코드를 수업 때 배웠던 Cosine decay로 변경</li>
<li>Cosine decay 적용 전보다 더 부드럽게 우하향하는 추세를 보여줌</li>
</ul>
<div id="ddcc56b7" class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>total_epoch_value <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scheduler(epoch, lr):</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the cosine decay factor</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    cosine_decay <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> np.cos(np.pi <span class="op">*</span> epoch <span class="op">/</span> total_epoch_value))</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update learning rate</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>    new_lr <span class="op">=</span> lr <span class="op">*</span> cosine_decay</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(new_lr)</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>lr_scheduler <span class="op">=</span> LearningRateScheduler(scheduler, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 학습률 설정</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>new_learning_rate <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span>total_epoch_value, </span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a>                      callbacks<span class="op">=</span>[lr_scheduler])</span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Epoch 1: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 1/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 9s 1ms/step - F1Score: 0.0036 - loss: 0.0149 - learning_rate: 0.0500

Epoch 2: LearningRateScheduler setting learning rate to 0.048776413634204034.
Epoch 2/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0130 - learning_rate: 0.0488

Epoch 3: LearningRateScheduler setting learning rate to 0.04411868114727063.
Epoch 3/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0033 - loss: 0.0123 - learning_rate: 0.0441

Epoch 4: LearningRateScheduler setting learning rate to 0.03502549477486741.
Epoch 4/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0132 - learning_rate: 0.0350

Epoch 5: LearningRateScheduler setting learning rate to 0.022924484773646628.
Epoch 5/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0035 - loss: 0.0129 - learning_rate: 0.0229

Epoch 6: LearningRateScheduler setting learning rate to 0.011462242342531681.
Epoch 6/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0030 - loss: 0.0114 - learning_rate: 0.0115

Epoch 7: LearningRateScheduler setting learning rate to 0.003960107332522642.
Epoch 7/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 1ms/step - F1Score: 0.0032 - loss: 0.0119 - learning_rate: 0.0040

Epoch 8: LearningRateScheduler setting learning rate to 0.0008162073473510564.
Epoch 8/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0032 - loss: 0.0119 - learning_rate: 8.1621e-04

Epoch 9: LearningRateScheduler setting learning rate to 7.794086367885386e-05.
Epoch 9/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0032 - loss: 0.0120 - learning_rate: 7.7941e-05

Epoch 10: LearningRateScheduler setting learning rate to 1.9073487425812585e-06.
Epoch 10/10
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 6s 1ms/step - F1Score: 0.0034 - loss: 0.0126 - learning_rate: 1.9073e-06
* 모델평가
4334/4334 - 3s - 640us/step - F1Score: 0.0034 - loss: 0.0124
2653/2653 - 2s - 670us/step - F1Score: 0.0032 - loss: 0.0119</code></pre>
</div>
</div>
<ul>
<li>Cosine decay 적용 전보다 더 부드럽게 우하향하는 추세를 보여줌</li>
</ul>
<div id="e2a9a150" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-39-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="f1score-및-loss-개선-비교-3" class="level4">
<h4 class="anchored" data-anchor-id="f1score-및-loss-개선-비교-3">F1Score 및 Loss 개선 비교</h4>
<ul>
<li>모델평가(기본) <br>
<ul>
<li>4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114</li>
<li>2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</li>
</ul></li>
<li>모델평가(Tuner) <br>
<ul>
<li>4334/4334 - 4s - 860us/step - F1Score: 0.0034 - loss: 0.0175</li>
<li>2653/2653 - 2s - 862us/step - F1Score: 0.0029 - loss: 0.0164</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization) <br>
<ul>
<li>4334/4334 - 6s - 1ms/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 4s - 1ms/step - F1Score: 0.0029 - loss: 0.0109</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization) <br>
<ul>
<li>4334/4334 - 3s - 788us/step - F1Score: 0.0034 - loss: 0.0125</li>
<li>2653/2653 - 2s - 757us/step - F1Score: 0.0029 - loss: 0.0110</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization + Learning rate Scheduling) <br>
<ul>
<li>4334/4334 - 3s - 640us/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 2s - 670us/step - F1Score: 0.0032 - loss: 0.0119</li>
</ul></li>
</ul>
</section>
</section>
<section id="추가적용-earlystopping-with-patience" class="level3">
<h3 class="anchored" data-anchor-id="추가적용-earlystopping-with-patience">추가적용 : EarlyStopping with patience</h3>
<ul>
<li>epoch 1000회로 세팅</li>
<li>patience 200으로 세팅</li>
</ul>
<div id="365b454a" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>total_epoch_value <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scheduler(epoch, lr):</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the cosine decay factor</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    cosine_decay <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> np.cos(np.pi <span class="op">*</span> epoch <span class="op">/</span> total_epoch_value))</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update learning rate</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    new_lr <span class="op">=</span> lr <span class="op">*</span> cosine_decay</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(new_lr)</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.device(<span class="st">'/device:GPU:0'</span>):</span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>    lr_scheduler <span class="op">=</span> LearningRateScheduler(scheduler, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>    es <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'F1Score'</span>, mode<span class="op">=</span><span class="st">'max'</span>, verbose<span class="op">=</span><span class="dv">1</span>, patience<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 새로운 학습률 설정</span></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    new_learning_rate <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    model_4 <span class="op">=</span> keras.models.load_model(<span class="st">'model_4.keras'</span>)</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>    new_optimizer <span class="op">=</span> tf.keras.optimizers.Nadam(learning_rate<span class="op">=</span>new_learning_rate)</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    model_4.<span class="bu">compile</span>(optimizer<span class="op">=</span>new_optimizer, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'F1Score'</span>])</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 모델 학습</span></span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> model_4.fit(x_train, y_train, epochs<span class="op">=</span>total_epoch_value, </span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a>                        callbacks<span class="op">=</span>[lr_scheduler, es],</span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>                        validation_data<span class="op">=</span>(x_test,y_test))</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 평가</span></span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'* 모델평가'</span>)</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_train, y_train, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a>loss, f1score <span class="op">=</span> model_4.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Epoch 1: LearningRateScheduler setting learning rate to 0.05000000074505806.
Epoch 1/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0031 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0500

Epoch 2: LearningRateScheduler setting learning rate to 0.049999877375102676.
Epoch 2/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0500

Epoch 3: LearningRateScheduler setting learning rate to 0.04999938433308759.
Epoch 3/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0500

Epoch 4: LearningRateScheduler setting learning rate to 0.04999827576351572.
Epoch 4/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0038 - loss: 0.0142 - val_F1Score: 0.0032 - val_loss: 0.0126 - learning_rate: 0.0500

Epoch 5: LearningRateScheduler setting learning rate to 0.04999630210880771.
Epoch 5/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0138 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0500

Epoch 6: LearningRateScheduler setting learning rate to 0.049993217571968625.
Epoch 6/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0500

Epoch 7: LearningRateScheduler setting learning rate to 0.04998877640343745.
Epoch 7/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0500

Epoch 8: LearningRateScheduler setting learning rate to 0.04998273291321625.
Epoch 8/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0500

Epoch 9: LearningRateScheduler setting learning rate to 0.04997484148299723.
Epoch 9/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0500

Epoch 10: LearningRateScheduler setting learning rate to 0.04996485285374156.
Epoch 10/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0029 - loss: 0.0111 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0500

Epoch 11: LearningRateScheduler setting learning rate to 0.049952525311787795.
Epoch 11/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0500

Epoch 12: LearningRateScheduler setting learning rate to 0.04993761352668951.
Epoch 12/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0499

Epoch 13: LearningRateScheduler setting learning rate to 0.04991987228817006.
Epoch 13/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0499

Epoch 14: LearningRateScheduler setting learning rate to 0.04989906024197024.
Epoch 14/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0499

Epoch 15: LearningRateScheduler setting learning rate to 0.04987493245373588.
Epoch 15/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0499

Epoch 16: LearningRateScheduler setting learning rate to 0.04984724786871271.
Epoch 16/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0114 - val_F1Score: 0.0032 - val_loss: 0.0123 - learning_rate: 0.0498

Epoch 17: LearningRateScheduler setting learning rate to 0.04981576932241795.
Epoch 17/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0498

Epoch 18: LearningRateScheduler setting learning rate to 0.049780256105761714.
Epoch 18/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0137 - val_F1Score: 0.0032 - val_loss: 0.0123 - learning_rate: 0.0498

Epoch 19: LearningRateScheduler setting learning rate to 0.049740471422997326.
Epoch 19/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0497

Epoch 20: LearningRateScheduler setting learning rate to 0.049696178679942346.
Epoch 20/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0497

Epoch 21: LearningRateScheduler setting learning rate to 0.049647145217296636.
Epoch 21/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0496

Epoch 22: LearningRateScheduler setting learning rate to 0.04959314232045517.
Epoch 22/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0133 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0496

Epoch 23: LearningRateScheduler setting learning rate to 0.04953394150819476.
Epoch 23/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0495

Epoch 24: LearningRateScheduler setting learning rate to 0.049469314543987404.
Epoch 24/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0495

Epoch 25: LearningRateScheduler setting learning rate to 0.04939904088730174.
Epoch 25/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0494

Epoch 26: LearningRateScheduler setting learning rate to 0.049322900261303024.
Epoch 26/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0493

Epoch 27: LearningRateScheduler setting learning rate to 0.0492406763828536.
Epoch 27/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0039 - loss: 0.0144 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0492

Epoch 28: LearningRateScheduler setting learning rate to 0.04915215697099108.
Epoch 28/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0492

Epoch 29: LearningRateScheduler setting learning rate to 0.04905713747321047.
Epoch 29/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0135 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0491

Epoch 30: LearningRateScheduler setting learning rate to 0.048955409918060896.
Epoch 30/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0490

Epoch 31: LearningRateScheduler setting learning rate to 0.04884677779609719.
Epoch 31/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0137 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0488

Epoch 32: LearningRateScheduler setting learning rate to 0.04873104491241159.
Epoch 32/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0138 - val_F1Score: 0.0032 - val_loss: 0.0126 - learning_rate: 0.0487

Epoch 33: LearningRateScheduler setting learning rate to 0.04860802282816687.
Epoch 33/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0137 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0486

Epoch 34: LearningRateScheduler setting learning rate to 0.048477530864382556.
Epoch 34/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0038 - loss: 0.0141 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0485

Epoch 35: LearningRateScheduler setting learning rate to 0.04833938867581208.
Epoch 35/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0131 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0483

Epoch 36: LearningRateScheduler setting learning rate to 0.048193427402064476.
Epoch 36/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0125 - learning_rate: 0.0482

Epoch 37: LearningRateScheduler setting learning rate to 0.04803948224003987.
Epoch 37/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0480

Epoch 38: LearningRateScheduler setting learning rate to 0.04787739244900734.
Epoch 38/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0131 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0479

Epoch 39: LearningRateScheduler setting learning rate to 0.04770701249149665.
Epoch 39/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0029 - loss: 0.0111 - val_F1Score: 0.0032 - val_loss: 0.0133 - learning_rate: 0.0477

Epoch 40: LearningRateScheduler setting learning rate to 0.04752819718190602.
Epoch 40/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0124 - learning_rate: 0.0475

Epoch 41: LearningRateScheduler setting learning rate to 0.04734080911500294.
Epoch 41/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0473

Epoch 42: LearningRateScheduler setting learning rate to 0.047144726085502936.
Epoch 42/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0471

Epoch 43: LearningRateScheduler setting learning rate to 0.04693982624336337.
Epoch 43/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0469

Epoch 44: LearningRateScheduler setting learning rate to 0.046726002933231724.
Epoch 44/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0467

Epoch 45: LearningRateScheduler setting learning rate to 0.04650315356208633.
Epoch 45/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0465

Epoch 46: LearningRateScheduler setting learning rate to 0.04627118701398982.
Epoch 46/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0463

Epoch 47: LearningRateScheduler setting learning rate to 0.04603002364280635.
Epoch 47/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0460

Epoch 48: LearningRateScheduler setting learning rate to 0.045779591559066454.
Epoch 48/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0129 - learning_rate: 0.0458

Epoch 49: LearningRateScheduler setting learning rate to 0.04551983403368002.
Epoch 49/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0141 - learning_rate: 0.0455

Epoch 50: LearningRateScheduler setting learning rate to 0.04525069467084936.
Epoch 50/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0453

Epoch 51: LearningRateScheduler setting learning rate to 0.04497213962521406.
Epoch 51/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0450

Epoch 52: LearningRateScheduler setting learning rate to 0.044684139069935486.
Epoch 52/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0447

Epoch 53: LearningRateScheduler setting learning rate to 0.04438667459485334.
Epoch 53/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0113 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0444

Epoch 54: LearningRateScheduler setting learning rate to 0.044079742893301965.
Epoch 54/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0131 - val_F1Score: 0.0032 - val_loss: 0.0144 - learning_rate: 0.0441

Epoch 55: LearningRateScheduler setting learning rate to 0.04376335204512589.
Epoch 55/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0114 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0438

Epoch 56: LearningRateScheduler setting learning rate to 0.04343751780458211.
Epoch 56/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0434

Epoch 57: LearningRateScheduler setting learning rate to 0.04310227467966714.
Epoch 57/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0431

Epoch 58: LearningRateScheduler setting learning rate to 0.04275766481926046.
Epoch 58/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0029 - loss: 0.0108 - val_F1Score: 0.0032 - val_loss: 0.0137 - learning_rate: 0.0428

Epoch 59: LearningRateScheduler setting learning rate to 0.04240374169564687.
Epoch 59/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0424

Epoch 60: LearningRateScheduler setting learning rate to 0.042040577473459635.
Epoch 60/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0135 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0420

Epoch 61: LearningRateScheduler setting learning rate to 0.04166825190326737.
Epoch 61/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0029 - loss: 0.0112 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0417

Epoch 62: LearningRateScheduler setting learning rate to 0.041286855998470276.
Epoch 62/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0413

Epoch 63: LearningRateScheduler setting learning rate to 0.040896499394979254.
Epoch 63/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0409

Epoch 64: LearningRateScheduler setting learning rate to 0.04049729925174605.
Epoch 64/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0405

Epoch 65: LearningRateScheduler setting learning rate to 0.04008939129741767.
Epoch 65/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0401

Epoch 66: LearningRateScheduler setting learning rate to 0.03967291873571355.
Epoch 66/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0397

Epoch 67: LearningRateScheduler setting learning rate to 0.03924803959794496.
Epoch 67/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0039 - loss: 0.0142 - val_F1Score: 0.0032 - val_loss: 0.0223 - learning_rate: 0.0392

Epoch 68: LearningRateScheduler setting learning rate to 0.03881492302789103.
Epoch 68/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0139 - val_F1Score: 0.0032 - val_loss: 0.0125 - learning_rate: 0.0388

Epoch 69: LearningRateScheduler setting learning rate to 0.038373756621834496.
Epoch 69/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0384

Epoch 70: LearningRateScheduler setting learning rate to 0.03792473166260165.
Epoch 70/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0379

Epoch 71: LearningRateScheduler setting learning rate to 0.03746805782613492.
Epoch 71/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0135 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0375

Epoch 72: LearningRateScheduler setting learning rate to 0.03700395210292682.
Epoch 72/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0370

Epoch 73: LearningRateScheduler setting learning rate to 0.036532649808634195.
Epoch 73/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0365

Epoch 74: LearningRateScheduler setting learning rate to 0.036054393511249797.
Epoch 74/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0361

Epoch 75: LearningRateScheduler setting learning rate to 0.035569436681775514.
Epoch 75/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0133 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0356

Epoch 76: LearningRateScheduler setting learning rate to 0.03507804366240132.
Epoch 76/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0031 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0351

Epoch 77: LearningRateScheduler setting learning rate to 0.034580493306341685.
Epoch 77/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0346

Epoch 78: LearningRateScheduler setting learning rate to 0.03407706792429393.
Epoch 78/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0341

Epoch 79: LearningRateScheduler setting learning rate to 0.03356806794275915.
Epoch 79/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0028 - loss: 0.0108 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0336

Epoch 80: LearningRateScheduler setting learning rate to 0.03305380085029894.
Epoch 80/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0114 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0331

Epoch 81: LearningRateScheduler setting learning rate to 0.0325345775020496.
Epoch 81/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0325

Epoch 82: LearningRateScheduler setting learning rate to 0.03201072309373603.
Epoch 82/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0320

Epoch 83: LearningRateScheduler setting learning rate to 0.03148256978963389.
Epoch 83/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0315

Epoch 84: LearningRateScheduler setting learning rate to 0.030950456692133768.
Epoch 84/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0137 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0310

Epoch 85: LearningRateScheduler setting learning rate to 0.030414729810794083.
Epoch 85/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0133 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0304

Epoch 86: LearningRateScheduler setting learning rate to 0.029875742030884136.
Epoch 86/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0299

Epoch 87: LearningRateScheduler setting learning rate to 0.029333851252558933.
Epoch 87/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0115 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0293

Epoch 88: LearningRateScheduler setting learning rate to 0.028789420362314282.
Epoch 88/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0127 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0288

Epoch 89: LearningRateScheduler setting learning rate to 0.028242819031350504.
Epoch 89/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0282

Epoch 90: LearningRateScheduler setting learning rate to 0.027694420029314302.
Epoch 90/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0277

Epoch 91: LearningRateScheduler setting learning rate to 0.027144599198612736.
Epoch 91/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0271

Epoch 92: LearningRateScheduler setting learning rate to 0.026593733603646846.
Epoch 92/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0266

Epoch 93: LearningRateScheduler setting learning rate to 0.026042203332819286.
Epoch 93/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0260

Epoch 94: LearningRateScheduler setting learning rate to 0.025490389649056783.
Epoch 94/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0255

Epoch 95: LearningRateScheduler setting learning rate to 0.02493867678984359.
Epoch 95/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0249

Epoch 96: LearningRateScheduler setting learning rate to 0.0243874446546497.
Epoch 96/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0028 - loss: 0.0105 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0244

Epoch 97: LearningRateScheduler setting learning rate to 0.02383707607775812.
Epoch 97/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0238

Epoch 98: LearningRateScheduler setting learning rate to 0.0232879495225387.
Epoch 98/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0233

Epoch 99: LearningRateScheduler setting learning rate to 0.022740442709790577.
Epoch 99/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0227

Epoch 100: LearningRateScheduler setting learning rate to 0.022194928963840378.
Epoch 100/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0222

Epoch 101: LearningRateScheduler setting learning rate to 0.021651780837725836.
Epoch 101/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0217

Epoch 102: LearningRateScheduler setting learning rate to 0.021111362830849738.
Epoch 102/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0211

Epoch 103: LearningRateScheduler setting learning rate to 0.020574038650582698.
Epoch 103/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0206

Epoch 104: LearningRateScheduler setting learning rate to 0.020040162123402632.
Epoch 104/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0115 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0200

Epoch 105: LearningRateScheduler setting learning rate to 0.019510082641125054.
Epoch 105/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0036 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0195

Epoch 106: LearningRateScheduler setting learning rate to 0.01898414334111084.
Epoch 106/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0135 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0190

Epoch 107: LearningRateScheduler setting learning rate to 0.018462677481004153.
Epoch 107/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0185

Epoch 108: LearningRateScheduler setting learning rate to 0.017946012067510217.
Epoch 108/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0179

Epoch 109: LearningRateScheduler setting learning rate to 0.01743446604557586.
Epoch 109/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0174

Epoch 110: LearningRateScheduler setting learning rate to 0.0169283466852938.
Epoch 110/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0169

Epoch 111: LearningRateScheduler setting learning rate to 0.016427951403963508.
Epoch 111/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0164

Epoch 112: LearningRateScheduler setting learning rate to 0.015933567776404835.
Epoch 112/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0159

Epoch 113: LearningRateScheduler setting learning rate to 0.015445473545956377.
Epoch 113/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0154

Epoch 114: LearningRateScheduler setting learning rate to 0.014963933929296461.
Epoch 114/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0150

Epoch 115: LearningRateScheduler setting learning rate to 0.014489202538243347.
Epoch 115/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0145

Epoch 116: LearningRateScheduler setting learning rate to 0.014021520496817624.
Epoch 116/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0140

Epoch 117: LearningRateScheduler setting learning rate to 0.013561116462970584.
Epoch 117/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0127 - learning_rate: 0.0136

Epoch 118: LearningRateScheduler setting learning rate to 0.013108206651183544.
Epoch 118/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0131

Epoch 119: LearningRateScheduler setting learning rate to 0.012662993956245575.
Epoch 119/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0127

Epoch 120: LearningRateScheduler setting learning rate to 0.012225667081091017.
Epoch 120/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0123 - learning_rate: 0.0122

Epoch 121: LearningRateScheduler setting learning rate to 0.01179640236465126.
Epoch 121/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0118

Epoch 122: LearningRateScheduler setting learning rate to 0.011375362011883477.
Epoch 122/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0114

Epoch 123: LearningRateScheduler setting learning rate to 0.010962693228735833.
Epoch 123/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0110

Epoch 124: LearningRateScheduler setting learning rate to 0.01055853005235644.
Epoch 124/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0106

Epoch 125: LearningRateScheduler setting learning rate to 0.010162992486406664.
Epoch 125/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0030 - loss: 0.0112 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0102

Epoch 126: LearningRateScheduler setting learning rate to 0.009776186536514266.
Epoch 126/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0098

Epoch 127: LearningRateScheduler setting learning rate to 0.00939820335139082.
Epoch 127/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0094

Epoch 128: LearningRateScheduler setting learning rate to 0.009029121052566404.
Epoch 128/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0090

Epoch 129: LearningRateScheduler setting learning rate to 0.008669002981605245.
Epoch 129/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0087

Epoch 130: LearningRateScheduler setting learning rate to 0.00831789863593302.
Epoch 130/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0083

Epoch 131: LearningRateScheduler setting learning rate to 0.007975844602221773.
Epoch 131/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0080

Epoch 132: LearningRateScheduler setting learning rate to 0.00764286280991781.
Epoch 132/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0076

Epoch 133: LearningRateScheduler setting learning rate to 0.007318962806057378.
Epoch 133/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0073

Epoch 134: LearningRateScheduler setting learning rate to 0.007004140902813916.
Epoch 134/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0070

Epoch 135: LearningRateScheduler setting learning rate to 0.006698380665480482.
Epoch 135/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0067

Epoch 136: LearningRateScheduler setting learning rate to 0.006401653399573791.
Epoch 136/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0115 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0064

Epoch 137: LearningRateScheduler setting learning rate to 0.006113918192281751.
Epoch 137/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0061

Epoch 138: LearningRateScheduler setting learning rate to 0.00583512239919073.
Epoch 138/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0058

Epoch 139: LearningRateScheduler setting learning rate to 0.005565202574146112.
Epoch 139/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0056

Epoch 140: LearningRateScheduler setting learning rate to 0.005304084064791188.
Epoch 140/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0053

Epoch 141: LearningRateScheduler setting learning rate to 0.005051681497723035.
Epoch 141/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0051

Epoch 142: LearningRateScheduler setting learning rate to 0.004807899705742073.
Epoch 142/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0127 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0048

Epoch 143: LearningRateScheduler setting learning rate to 0.004572634652071941.
Epoch 143/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0046

Epoch 144: LearningRateScheduler setting learning rate to 0.004345772581226123.
Epoch 144/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0131 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0043

Epoch 145: LearningRateScheduler setting learning rate to 0.0041271918277528885.
Epoch 145/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0041

Epoch 146: LearningRateScheduler setting learning rate to 0.003916761966443078.
Epoch 146/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0039

Epoch 147: LearningRateScheduler setting learning rate to 0.0037143456165374526.
Epoch 147/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0037

Epoch 148: LearningRateScheduler setting learning rate to 0.003519798694295597.
Epoch 148/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0035

Epoch 149: LearningRateScheduler setting learning rate to 0.0033329702241221442.
Epoch 149/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0119 - learning_rate: 0.0033

Epoch 150: LearningRateScheduler setting learning rate to 0.003153703693298654.
Epoch 150/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0032

Epoch 151: LearningRateScheduler setting learning rate to 0.002981837080382247.
Epoch 151/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0122 - learning_rate: 0.0030

Epoch 152: LearningRateScheduler setting learning rate to 0.002817203763890849.
Epoch 152/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0028

Epoch 153: LearningRateScheduler setting learning rate to 0.002659632548117222.
Epoch 153/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0027

Epoch 154: LearningRateScheduler setting learning rate to 0.002508948787459685.
Epoch 154/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0025

Epoch 155: LearningRateScheduler setting learning rate to 0.0023649744086335148.
Epoch 155/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0024

Epoch 156: LearningRateScheduler setting learning rate to 0.002227528810319298.
Epoch 156/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0022

Epoch 157: LearningRateScheduler setting learning rate to 0.002096428882420658.
Epoch 157/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0021

Epoch 158: LearningRateScheduler setting learning rate to 0.0019714901202732477.
Epoch 158/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0020

Epoch 159: LearningRateScheduler setting learning rate to 0.0018525268586946407.
Epoch 159/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0038 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0019

Epoch 160: LearningRateScheduler setting learning rate to 0.001739352177175322.
Epoch 160/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0017

Epoch 161: LearningRateScheduler setting learning rate to 0.0016317790070494893.
Epoch 161/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0016

Epoch 162: LearningRateScheduler setting learning rate to 0.0015296205786924965.
Epoch 162/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0015

Epoch 163: LearningRateScheduler setting learning rate to 0.0014326904304467975.
Epoch 163/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0014

Epoch 164: LearningRateScheduler setting learning rate to 0.0013408029622755352.
Epoch 164/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0013

Epoch 165: LearningRateScheduler setting learning rate to 0.0012537739867035033.
Epoch 165/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0113 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0013

Epoch 166: LearningRateScheduler setting learning rate to 0.0011714208419180048.
Epoch 166/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0012

Epoch 167: LearningRateScheduler setting learning rate to 0.0010935627215877873.
Epoch 167/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 0.0011

Epoch 168: LearningRateScheduler setting learning rate to 0.0010200213286971748.
Epoch 168/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 0.0010

Epoch 169: LearningRateScheduler setting learning rate to 0.0009506207664891017.
Epoch 169/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0037 - loss: 0.0133 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 9.5062e-04

Epoch 170: LearningRateScheduler setting learning rate to 0.0008851880802090808.
Epoch 170/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 8.8519e-04

Epoch 171: LearningRateScheduler setting learning rate to 0.0008235533085124968.
Epoch 171/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 8.2355e-04

Epoch 172: LearningRateScheduler setting learning rate to 0.0007655498590444079.
Epoch 172/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 7.6555e-04

Epoch 173: LearningRateScheduler setting learning rate to 0.000711014611544236.
Epoch 173/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 7.1101e-04

Epoch 174: LearningRateScheduler setting learning rate to 0.0006597882362160549.
Epoch 174/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0029 - loss: 0.0109 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 6.5979e-04

Epoch 175: LearningRateScheduler setting learning rate to 0.0006117152403282328.
Epoch 175/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 6.1172e-04

Epoch 176: LearningRateScheduler setting learning rate to 0.0005666441221124275.
Epoch 176/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 9s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 5.6664e-04

Epoch 177: LearningRateScheduler setting learning rate to 0.0005244275774159951.
Epoch 177/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 5.2443e-04

Epoch 178: LearningRateScheduler setting learning rate to 0.0004849225434646702.
Epoch 178/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0036 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 4.8492e-04

Epoch 179: LearningRateScheduler setting learning rate to 0.0004479903496044815.
Epoch 179/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 4.4799e-04

Epoch 180: LearningRateScheduler setting learning rate to 0.00041349667884561114.
Epoch 180/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0030 - loss: 0.0111 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 4.1350e-04

Epoch 181: LearningRateScheduler setting learning rate to 0.00038131174396874263.
Epoch 181/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.8131e-04

Epoch 182: LearningRateScheduler setting learning rate to 0.00035131022098520786.
Epoch 182/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.5131e-04

Epoch 183: LearningRateScheduler setting learning rate to 0.000323371316538639.
Epoch 183/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.2337e-04

Epoch 184: LearningRateScheduler setting learning rate to 0.0002973788077995383.
Epoch 184/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.9738e-04

Epoch 185: LearningRateScheduler setting learning rate to 0.00027322094806250124.
Epoch 185/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 2.7322e-04

Epoch 186: LearningRateScheduler setting learning rate to 0.0002507905060636847.
Epoch 186/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 2.5079e-04

Epoch 187: LearningRateScheduler setting learning rate to 0.00022998472463185788.
Epoch 187/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0038 - loss: 0.0136 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.2998e-04

Epoch 188: LearningRateScheduler setting learning rate to 0.00021070525252817312.
Epoch 188/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0127 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 2.1071e-04

Epoch 189: LearningRateScheduler setting learning rate to 0.00019285808961416642.
Epoch 189/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0133 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.9286e-04

Epoch 190: LearningRateScheduler setting learning rate to 0.00017635351865172405.
Epoch 190/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.7635e-04

Epoch 191: LearningRateScheduler setting learning rate to 0.00016110605041721006.
Epoch 191/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0030 - loss: 0.0111 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.6111e-04

Epoch 192: LearningRateScheduler setting learning rate to 0.00014703428907961074.
Epoch 192/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0127 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.4703e-04

Epoch 193: LearningRateScheduler setting learning rate to 0.00013406090414221943.
Epoch 193/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.3406e-04

Epoch 194: LearningRateScheduler setting learning rate to 0.00012211248289829325.
Epoch 194/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.2211e-04

Epoch 195: LearningRateScheduler setting learning rate to 0.00011111943637018841.
Epoch 195/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.1112e-04

Epoch 196: LearningRateScheduler setting learning rate to 0.00010101588562002027.
Epoch 196/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.0102e-04

Epoch 197: LearningRateScheduler setting learning rate to 9.173956161771835e-05.
Epoch 197/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 9.1740e-05

Epoch 198: LearningRateScheduler setting learning rate to 8.323166577470412e-05.
Epoch 198/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 8.3232e-05

Epoch 199: LearningRateScheduler setting learning rate to 7.543677716041947e-05.
Epoch 199/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 7.5437e-05

Epoch 200: LearningRateScheduler setting learning rate to 6.830270726935913e-05.
Epoch 200/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 6.8303e-05

Epoch 201: LearningRateScheduler setting learning rate to 6.178038169635723e-05.
Epoch 201/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 6.1780e-05

Epoch 202: LearningRateScheduler setting learning rate to 5.5823715672683846e-05.
Epoch 202/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0031 - loss: 0.0115 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 5.5824e-05

Epoch 203: LearningRateScheduler setting learning rate to 5.038949665635076e-05.
Epoch 203/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 5.0389e-05

Epoch 204: LearningRateScheduler setting learning rate to 4.543725097729416e-05.
Epoch 204/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0031 - loss: 0.0114 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 4.5437e-05

Epoch 205: LearningRateScheduler setting learning rate to 4.0929124160673104e-05.
Epoch 205/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 4.0929e-05

Epoch 206: LearningRateScheduler setting learning rate to 3.682975847646033e-05.
Epoch 206/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0131 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.6830e-05

Epoch 207: LearningRateScheduler setting learning rate to 3.31061677502092e-05.
Epoch 207/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.3106e-05

Epoch 208: LearningRateScheduler setting learning rate to 2.9727622537092672e-05.
Epoch 208/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0117 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.9728e-05

Epoch 209: LearningRateScheduler setting learning rate to 2.6665534176340642e-05.
Epoch 209/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.6666e-05

Epoch 210: LearningRateScheduler setting learning rate to 2.3893339378491008e-05.
Epoch 210/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0115 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 2.3893e-05

Epoch 211: LearningRateScheduler setting learning rate to 2.138639024030536e-05.
Epoch 211/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.1386e-05

Epoch 212: LearningRateScheduler setting learning rate to 1.9121844781739403e-05.
Epoch 212/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0119 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.9122e-05

Epoch 213: LearningRateScheduler setting learning rate to 1.70785645133303e-05.
Epoch 213/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.7079e-05

Epoch 214: LearningRateScheduler setting learning rate to 1.5237012502896017e-05.
Epoch 214/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0031 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.5237e-05

Epoch 215: LearningRateScheduler setting learning rate to 1.357915519287874e-05.
Epoch 215/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.3579e-05

Epoch 216: LearningRateScheduler setting learning rate to 1.2088370381438874e-05.
Epoch 216/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0035 - loss: 0.0127 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.2088e-05

Epoch 217: LearningRateScheduler setting learning rate to 1.0749355670971902e-05.
Epoch 217/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.0749e-05

Epoch 218: LearningRateScheduler setting learning rate to 9.548043047235348e-06.
Epoch 218/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0126 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 9.5480e-06

Epoch 219: LearningRateScheduler setting learning rate to 8.4715155183082e-06.
Epoch 219/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 8.4715e-06

Epoch 220: LearningRateScheduler setting learning rate to 7.507931450634886e-06.
Epoch 220/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0035 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 7.5079e-06

Epoch 221: LearningRateScheduler setting learning rate to 6.646446085543275e-06.
Epoch 221/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0032 - loss: 0.0116 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 6.6464e-06

Epoch 222: LearningRateScheduler setting learning rate to 5.877143136087781e-06.
Epoch 222/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0134 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 5.8771e-06

Epoch 223: LearningRateScheduler setting learning rate to 5.190965951257081e-06.
Epoch 223/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0031 - loss: 0.0113 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 5.1910e-06

Epoch 224: LearningRateScheduler setting learning rate to 4.579655882737102e-06.
Epoch 224/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 4.5797e-06

Epoch 225: LearningRateScheduler setting learning rate to 4.035690191498989e-06.
Epoch 225/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 4.0357e-06

Epoch 226: LearningRateScheduler setting learning rate to 3.5522267110029194e-06.
Epoch 226/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.5522e-06

Epoch 227: LearningRateScheduler setting learning rate to 3.123050022982594e-06.
Epoch 227/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.1230e-06

Epoch 228: LearningRateScheduler setting learning rate to 2.7425225352732546e-06.
Epoch 228/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0037 - loss: 0.0132 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 2.7425e-06

Epoch 229: LearningRateScheduler setting learning rate to 2.4055370383374177e-06.
Epoch 229/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0129 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.4055e-06

Epoch 230: LearningRateScheduler setting learning rate to 2.1074729261271663e-06.
Epoch 230/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0039 - loss: 0.0139 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 2.1075e-06

Epoch 231: LearningRateScheduler setting learning rate to 1.8441558584291099e-06.
Epoch 231/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0123 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.8442e-06

Epoch 232: LearningRateScheduler setting learning rate to 1.611819649663071e-06.
Epoch 232/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0036 - loss: 0.0130 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.6118e-06

Epoch 233: LearningRateScheduler setting learning rate to 1.4070711650071392e-06.
Epoch 233/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0121 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 1.4071e-06

Epoch 234: LearningRateScheduler setting learning rate to 1.2268571134422569e-06.
Epoch 234/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0033 - loss: 0.0120 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.2269e-06

Epoch 235: LearningRateScheduler setting learning rate to 1.0684341126453187e-06.
Epoch 235/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0124 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 1.0684e-06

Epoch 236: LearningRateScheduler setting learning rate to 9.293406181791023e-07.
Epoch 236/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0034 - loss: 0.0125 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 9.2934e-07

Epoch 237: LearningRateScheduler setting learning rate to 8.073707546410956e-07.
Epoch 237/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0028 - loss: 0.0103 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 8.0737e-07

Epoch 238: LearningRateScheduler setting learning rate to 7.005507269301096e-07.
Epoch 238/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 8s 2ms/step - F1Score: 0.0040 - loss: 0.0143 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 7.0055e-07

Epoch 239: LearningRateScheduler setting learning rate to 6.071166600852295e-07.
Epoch 239/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 10s 2ms/step - F1Score: 0.0035 - loss: 0.0128 - val_F1Score: 0.0032 - val_loss: 0.0120 - learning_rate: 6.0712e-07

Epoch 240: LearningRateScheduler setting learning rate to 5.254945474903442e-07.
Epoch 240/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 5.2549e-07

Epoch 241: LearningRateScheduler setting learning rate to 4.542818008736369e-07.
Epoch 241/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0033 - loss: 0.0122 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 4.5428e-07

Epoch 242: LearningRateScheduler setting learning rate to 3.9223019466086514e-07.
Epoch 242/1000
4334/4334 ━━━━━━━━━━━━━━━━━━━━ 7s 2ms/step - F1Score: 0.0032 - loss: 0.0118 - val_F1Score: 0.0032 - val_loss: 0.0121 - learning_rate: 3.9223e-07
Epoch 242: early stopping
* 모델평가
4334/4334 - 3s - 594us/step - F1Score: 0.0034 - loss: 0.0121
2653/2653 - 2s - 584us/step - F1Score: 0.0032 - loss: 0.0121</code></pre>
</div>
</div>
<div id="0d7cb9b8" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 및 F1-Score 시각화</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">4</span>))</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>ax1.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Loss'</span>)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>ax2.plot(history.history[<span class="st">'F1Score'</span>], label<span class="op">=</span><span class="st">'F1-score'</span>)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>ax1.legend(), ax2.legend()</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-41-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="f1score-및-loss-개선-비교-4" class="level4">
<h4 class="anchored" data-anchor-id="f1score-및-loss-개선-비교-4">F1Score 및 Loss 개선 비교</h4>
<ul>
<li>모델평가(기본) <br>
<ul>
<li>4334/4334 - 2s - 531us/step - F1Score: 0.0034 - loss: 0.0114</li>
<li>2653/2653 - 1s - 511us/step - F1Score: 0.0029 - loss: 0.0123</li>
</ul></li>
<li>모델평가(Tuner) <br>
<ul>
<li>4334/4334 - 4s - 860us/step - F1Score: 0.0034 - loss: 0.0175</li>
<li>2653/2653 - 2s - 862us/step - F1Score: 0.0029 - loss: 0.0164</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization) <br>
<ul>
<li>4334/4334 - 6s - 1ms/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 4s - 1ms/step - F1Score: 0.0029 - loss: 0.0109</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization) <br>
<ul>
<li>4334/4334 - 3s - 788us/step - F1Score: 0.0034 - loss: 0.0125</li>
<li>2653/2653 - 2s - 757us/step - F1Score: 0.0029 - loss: 0.0110</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization + Learning rate Scheduling) <br>
<ul>
<li>4334/4334 - 3s - 640us/step - F1Score: 0.0034 - loss: 0.0124</li>
<li>2653/2653 - 2s - 670us/step - F1Score: 0.0032 - loss: 0.0119</li>
</ul></li>
<li>모델평가(Tuner + Kaiming Initialization + Batch Normalization + Learning rate Scheduling + Early Stopping) <br>
<ul>
<li>4334/4334 - 3s - 594us/step - F1Score: 0.0034 - loss: 0.0121</li>
<li>2653/2653 - 2s - 584us/step - F1Score: 0.0032 - loss: 0.0121</li>
</ul></li>
</ul>
</section>
</section>
<section id="결론" class="level3">
<h3 class="anchored" data-anchor-id="결론">결론</h3>
<ul>
<li><p>Loss는 지속적인 개선이 되고 있으나 F1score는 계속 비슷한 수치를 보임</p>
<ul>
<li>Learning rate Scheduling 적용시에만 약간의 개선이 있음</li>
</ul></li>
<li><p>과제 발표 후 관련 내용 질의 및 개선 예정</p></li>
<li><p>과제 진행 중 생긴 궁금한 점들에 대해서도 추가 질의 예정</p>
<ul>
<li>이런 모델은 결국 사용하고자 만드는 것인데, PCA로 만든 모델이면 새로운 거래가 생성된 경우 그대로 넣어도 모델이 판별 가능한지</li>
<li>epoch 수 대비 적절한 Early stopping patience값이 있는지</li>
</ul></li>
</ul>


</section>
</section>
</section>

<p><br><strong>Copyright © 2024 Kibok Park All rights reserved.</strong><br></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kr9268\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="kr9268/giscus_for_blog" data-repo-id="R_kgDOL0Sthw" data-category="General" data-category-id="DIC_kwDOL0Sth84Ce_5h" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<script>
    const baseFontSize = parseFloat(getComputedStyle(document.documentElement).fontSize);
    const watermark = new XWatermark.XWatermark();
    watermark.init("Kibok Park", {
      parentSelector: "body",
      prevent: true,
      observer: true,
      mode: "normal",
      font: "system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', 'Noto Sans', 'Liberation Sans', Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'",
      fontsize: baseFontSize * 1.000000,
      angle: -15.000000,
      color: "#000000",
      alpha: 0.100000,
      cols: 10,
      rows: 50,
      xSpace: baseFontSize * 4.000000,
      ySpace: baseFontSize * 4.000000,
      zIndex: -1
    });
    </script>




</body></html>